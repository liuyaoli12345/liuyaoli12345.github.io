[{"title":"在大陆地区如何进行最基本的开发?","path":"/2024/09/17/在大陆地区如何进行最基本的开发/","content":"没有任何不良引导，坚定支持人类命运共同体 当我们新开了一台国内的服务器，想要进行任何有用的研究，不论是机器学习、还是基本的开发，我们需要能够访问某些人不希望我们访问的各种资源 如果有当前服务器的root安装docker官方的软件源肯定是装不了一点的，我们需要用国内源 https://www.cnblogs.com/lqqgis/p/18276118 同时镜像源也被污染了，所以我们还需要使用自己搭建的镜像源 1234567&lt;&lt;EOF sudo tee /etc/docker/daemon.json&#123; &quot;registry-mirrors&quot;: [ &quot;https://dockerhub.lsmcloud.top&quot; ]&#125;EOF 安装v2rayAhttps://v2raya.org/docs/prologue/installation/docker/ 把服务器的安全组全部去掉，对于我这样的小罗罗，它们的副作用远大于作用 v2rayA的ui有点逆天，记得点select启动，并且记得配置config的host和servername 最后把服务器全局代理一下，注意这些勾八厂商的curl很可能不支持socks5，直接卸了重新装 应对DNS劫持这些厂商返回的google地址都是黑洞和它们的广告 1234567891011vim /etc/systemd/resolved.conf# 没几个有良心的dns了，而且它们还伪装1.1.1.1和8.8.8.8返回的全是黑洞DNS=223.5.5.5# 他们会对网卡eh0再做一层dns劫持，让它有独享的dns，这里链接一下强迫eh0用我们的dnssudo ln -sf /run/systemd/resolve/stub-resolv.conf /etc/resolv.confsudo systemd-resolve --flush-cachessudo systemctl restart systemd-resolved https://www.laozuo.org/25628.html 使用它们的dns是不行的，我们接下来需要配置DoH https://github.com/9bingyin/Fast-DoH 如果githubusercontent也被污染，在自己电脑上解析下然后直接改&#x2F;etc&#x2F;hosts就是了 没有这个服务器的root首先我们要找到一台有root的服务器A，执行上面的操作 然后就可以直接set proxy了，比如socks5:&#x2F;&#x2F;139.159.230.151:20170 但是！这样设置代理，dns解析可能还是通过本机进行，于是dns污染又来了，我们需要把dns解析也交给proxy，那么就配置代理：socks5h:&#x2F;&#x2F;139.159.230.151:20170","tags":["Basics"]},{"title":"微分与导数","path":"/2024/09/11/微分与导数/","content":"函数连续直观地说，函数连续意味着当自变量的变化足够小时，函数值的变化也足够小 连续性的定义对于任意的正实数，存在一个正实数，， 这个定义和函数极限的定义超级像啊 我觉得用朴素的极限来看，就是在描述这个要求，但是这里的极限要是通过邻域来定义的极限，不是那种对跳变做了推广的极限 满足则f(x)在c处连续 连续性的极限定义在c点有定义并且c是的聚点（*为啥啊，每次我看一个概念的定义，他们都要拿一个更复杂的概念来定义我要看的概念…*），并且自变量在定义域内不论通过什么方式逼近c，极限都存在且都是 函数可微微分可以描述当自变量的变化很小时，函数值如何变化 一元微分, 那么一个函数一元可微意味着 其中的被我们记作 套用上面那一套，我们可以说（我猜的）一元微分在描述这样一件事 从这个式子我们就不难看出那句数学谚语“可导一定连续，连续不一定可导了”，要让这个式子成立，显然分子部分要先满足，因为分子部分必须是分母的等价无穷小或是高阶无穷小 微分法则这部分或许我应当试着用自己推下","tags":["Math"],"categories":["Math"]},{"title":"信号量,条件变量与管程","path":"/2024/07/03/信号量-条件变量与管程/","content":"参考文章： 信号量和条件变量的关系是什么？ 信号量信号量的本质是一个计数器加一个被计数器限制而等待访问的队列 一般的实现如下 12345678910111213141516wait(sem* S)&#123; S-&gt;value --; if(S-&gt;value&lt;0)&#123; add this process to S-&gt;list; block(); &#125;&#125; signal(sem* S)&#123; S-&gt;value ++; if(S-&gt;value&lt;=0)&#123; remove a process P from S-&gt;list; wakeup(P); &#125;&#125; 从信号量到条件变量首先条件变量一个目的是摆脱计数器只能以计数形式检查条件是否满足的限制，管理形式就不再是一个计数器，因此我们要改变那种一次只通知一个的方式，而是要在条件满足时一口气通知所有在等待的进程，看谁先抢到了 1234567891011121314151617wait(sem* S)&#123; while(S-&gt;value==0)&#123; // 这里判断条件，注意if变成了while，因为醒过来的进程很可能抢不到机会，因此条件还是成立，于是继续阻塞自己 add this process to S-&gt;list; block(); &#125; S-&gt;value--;&#125; signal(sem* S)&#123; S-&gt;value++; if(S-&gt;list非空)&#123; //这里的条件可以多种多样了 for(auto i in S-&gt;list)&#123; wakeup(i); &#125; &#125;&#125; 接下来我们要拓展条件变量的适应性，让条件变量的条件独立出去，可以由用户自定义 123456789101112131415161718192021222324252627282930313233int value = xx;sem s;Mutex mutex;//消费者mutex.lock();while(value==0)&#123; wait(s.mutex);&#125;value--;mutex.unlock();wait(sem* S，sem* mutex)&#123; add this process to S-&gt;list; mutex.unlock(); block(); mutex.lock();&#125; //生产者mutex.lock();value++;mutex.unlock();signal(s);signal(sem* S)&#123; if(S-&gt;list非空)&#123; for(auto i in S-&gt;list)&#123; wakeup(i); &#125; &#125; &#125; 现在我们可以自由地变更value的条件，特别注意为了能够互斥的操作条件，我们还引入了锁mutex，而这意味着wait进入等待需要释放mutex避免阻塞其他进程获取mutex，而从等待中醒来需要获取mutex以确保互斥 管程（以霍尔管程为例）霍尔管程已经不是目前广泛使用的管程，主流管程实际上是MESA管程 管程进一步地抽象了条件变量部分的管理，被分为了enter(), leave(), wait(), signal()四个步骤 123456789101112131415161718192021222324252627282930313233343536typedef struct InterfaceModule &#123; //InterfaceModule是结构体的名字\tsemaphore mutex; //进程调用管程过程前使用的互斥信号量\tsemaphore next; //发出signal的进程挂起自己的信号量\tint next_count; //在next上等待的进程数&#125;;mutex=1;next=0;next_count=0;//初始化语句void enter(InterfaceModule &amp;IM) &#123;P(IM.mutex); //互斥进入管程&#125;void leave(InterfaceModule &amp;IM) &#123; if(IM.next_count&gt;0) //判有否发出过signal的进程?V(IM.next); //有就释放一个发出过signal的进程else V(IM.mutex); //否则开放管程&#125;void wait(semaphore &amp;x_sem,int &amp;x_count,InterfaceModule &amp;IM) &#123;\tx_count++; //等资源进程个数加1，x_count初始化为0\tif(IM.next_count&gt;0) //判有否发出过signal的进程 V(IM.next); //有就释放一个\telse V(IM.mutex); //否则开放管程 P(x_sem); //等资源进程阻塞自己，x_sem初始化为0x_count--; //等资源进程个数减1 &#125;void signal(semaphore &amp;x_sem,int &amp;x_count,InterfaceModule &amp;IM) &#123;\tif(x_count&gt;0) &#123; //有等资源进程吗? IM.next_count++; //发出signal进程个数加1 V(x_sem); //释放一个等资源的进程 P(IM.next); //发出signal进程阻塞自己 IM.next_count--; //发出signal进程个数减1 &#125;&#125;IM.mutex=1; next=0; next_count=0; self[i]=0; self_count=0; state[i]=thinking; mutex=1;next=0;next_count=0;","tags":["os"],"categories":["os"]},{"title":"概率统计-cookmanual","path":"/2024/07/03/概率统计-cookmanual/","content":"累计分布函数 CDF累计分布函数 F(x) 定义为： 对于离散型随机变量， F(x) 是各个不超过 x 的取值的概率之和： 对于连续型随机变量， F(x) 是从负无穷到 x 的概率密度函数的积分： 概率密度函数 PMF通过 CDF 计算 PDF 如果 F(x) 是已知的，可以通过求导得到 f(x) ： 十一大分布1 均匀分布 离散随机变量的均匀分布：假设 X 有 k 个取值：x1, x2, …, xk 则均匀分布的概率密度函数为： 连续随机变量的均匀分布：假设 X 在 [a, b] 上均匀分布，则其概率密度函数为： 2 伯努利分布 伯努利分布：参数为 θ∈[0,1]，设随机变量 X ∈ {0,1}，则概率分布函数为： 期望： 方差： 3 二项分布 假设试验只有两种结果：成功的概率为 θ，失败的概率为 1-θ. 则二项分布描述了：独立重复地进行 n 次试验中，成功 x 次的概率。 概率密度函数： 期望： 方差： 4 高斯分布 正态分布是很多应用中的合理选择。如果某个随机变量取值范围是实数，且对它的概率分布一无所知，通常会假设它服从正态分布。有两个原因支持这一选择： 建模的任务的真实分布通常都确实接近正态分布。中心极限定理表明，多个独立随机变量的和近似正态分布。 在具有相同方差的所有可能的概率分布中，正态分布的熵最大（即不确定性最大）。 典型的一维正态分布的概率密度函数为 : 累计分布函数 5 拉普拉斯分布在概率论 与统计学 中，拉普拉斯分布 (Laplace distribution) 是以皮埃尔-西蒙·拉普拉斯 的名字命名的一种连续概率分布 。由于它可看作两平移指数分布 背靠背拼接在一起，因此又称双指数分布 (Double exponential distribution)。两个相互独立同概率分布 指数随机变量 之间的差别是按照指数分布的随机时间布朗运动 ，所以它遵循拉普拉斯分布。 概率密度函数： 期望： 方差： 6 泊松分布假设已知事件在单位时间（或者单位面积）内发生的平均次数为 λ，则泊松分布描述了：事件在单位时间（或者单位面积）内发生的具体次数为 k 的概率。 概率密度函数： 期望： 方差： 7 指数分布若事件服从泊松分布，则该事件前后两次发生的时间间隔服从指数分布。由于时间间隔是个浮点数，因此指数分布是连续分布。 概率密度函数：（ t 为时间间隔） 期望： 方差： 8 伽马分布若事件服从泊松分布，则事件第 i 次发生和第 i+k 次发生的时间间隔为伽玛分布。由于时间间隔是个浮点数，因此伽马分布是连续分布。 概率密度函数： ， 其中， t 为时间间隔，k 称为形状参数， λ 称为 尺度参数 期望和方差分别为： 9 贝塔分布贝塔分布是定义在 (0,1) 之间的连续概率分布。 如果随机变量 X 服从贝塔分布，则其概率密度函数为： 记做 期望为： 方差为： 10 狄拉克分布狄拉克分布：假设所有的概率都集中在一点 μ上，则对应的概率密度函数为： 其中 δ(.)为狄拉克函数，其性质为： 狄拉克分布的一个典型用途就是定义连续型随机变量的经验分布函数。假设数据集中有样本 则定义经验分布函数： 它就是对每个样本赋予了一个概率质量 ： 对于离散型随机变量的经验分布，则经验分布函数就是多项式分布，它简单地等于训练集中的经验频率。 经验分布的两个作用： 通过查看训练集样本的经验分布，从而指定该训练集的样本采样的分布（保证采样之后的分布不失真）。 经验分布就是使得训练数据的可能性最大化的概率密度函数。 11 多项式分布与狄里克雷分布多项式分布的质量密度函数： 狄利克雷分布的概率密度函数： 可以看到，多项式分布与狄里克雷分布的概率密度函数非常相似，区别仅仅在于前面的归一化项： 多项式分布是针对离散型随机变量，通过求和获取概率。 狄里克雷分布时针对连续型随机变量，通过求积分来获取概率。 显著性检验三、U检验（Z检验）U检验又称Z检验。 Z检验是一般用于大样本(即样本容量 大于30)平均值差异性检验的方法（总体的方差已知）。它是用标准正态分布 的理论来推断差异发生的概率，从而比较两个平均数 的差异是否显著。 Z检验步骤： 第一步：建立虚无假设 H0:μ1 = μ2 ，即先假定两个平均数之间没有显著差异， 第二步：计算统计量 Z值，对于不同类型的问题选用不同的统计量 计算方法， 1、如果检验一个样本平均数（X）与一个已知的总体平均数(μ0)的差异是否显著。其Z值计算公式为： 其中： X是检验样本的均值； μ0是已知总体的平均数； S是总体的标准差； n是样本容量。 2、如果检验来自两个的两组样本平均数的差异性，从而判断它们各自代表的总体的差异是否显著。其Z值计算公式为： 第三步：比较计算所得Z值与理论Z值，推断发生的概率，依据Z值与差异显著性关系表作出判断。如下表所示： 第四步：根据是以上分析，结合具体情况，作出结论。 例子：一种原件，要求使用寿命不低于1000小时，现从一批这种原件中抽取25件，测得其使用寿命的平均值为950小时，已知该原件服从标准差S=100小时的正太分布，试在显著性水平α=0.05下确定这批原件是否合格 解：使用寿命小于1000小时即为不合格，此题为左单侧检验 拒绝域为：Z&lt;-μα ; 查表得 μ0.05=1.65 已知s2=100*2，X=950，n=25 假设H0：μ=1000；H1&lt;1000 选取统计量 Z=（X - μ）（S/√n）= （950-1000）/（100/√25）=-2.5 因为 Z=-2.5&lt;&lt;-μα =-1.65 ，所以拒绝H0，即认为这批原件不合格 四、T检验亦称student t检验（Student’s t test），主要用于样本含量较小（例如n&lt;30），总体标准差σ未知的正态分布。目的是用来比较样本均数所代表的未知总体均数μ和已知总体均数μ0。 T统计量计算公式： 自由度：v=n - 1 T检验的步骤 第一步：建立虚无假设H0:μ1 = μ2，即先假定两个总体平均数之间没有显著差异； 第二步：计算统计量T值，对于不同类型的问题选用不同的统计量计算方法 1、如果要评断一个总体中的小样本平均数与总体平均值之间的差异程度，其统计量T值的计算公式为： 2、如果要评断两组样本平均数之间的差异程度，其统计量T值的计算公式为： 第三步：根据自由度df=n-1，查T值表，找出规定的T理论值并进行比较。理论值差异的显著水平为0.01级或0.05级。不同自由度的显著水平理论值记为T(df)0.01和T(df)0.05 第四步：比较计算得到的t值和理论T值，推断发生的概率，依据下表给出的T值与差异显著性关系表作出判断。 第五步：根据是以上分析，结合具体情况，作出结论。 实际应用中，T检验可分为三种：单样本T检验、配对样本T检验和双独立样本T检验 单样本T检验 例子：已知某班的一次数学测验成绩复查正态分布，现从全班中抽取16人，测得这些人成绩是[50,44,91,90,74,72,89,81,65,62,68,74,63,61,33,47]，问在α=0.05下，是否可以认为全体考生的平均分是70分？ 12345678910from scipy import statsimport numpy as np rvs = [50,44,91,90,74,72,89,81,65,62,68,74,63,61,33,47]mean = np.mean(rvs)#均值std = np.std(rvs)#标准差print(\"均值：\",mean,\" 标准差:\",std) t_val, p = stats.ttest_1samp(rvs, 70)print(\"t_val:\",t_val,\" p值：\", p) 结论，因为p值=0.42&gt;0.05，所以可以认为全体考生的平均分是70分 配对样本T检验 配对t检验是采用配对设计方法观察以下几种情形： 1.配对的两个受试对象分别接受两种不同的处理； 2.同一受试对象接受两种不同的处理； 3.同一受试对象处理前后的结果进行比较（即自身配对）； 4.同一对象的两个部位给予不同的处理。 例子：在针织品漂白工艺过程中， 要考虑温度对针织品断裂强力（主要质量指标）的影响。为了比较70℃与80℃的影响有无差别，在这两个温度下，分别重复做了8次试验，强力数据如下。问在70℃时的平均断裂强力与80℃时的平均断裂强力间是否有显著差别？ 假定断裂强力服从正态分布(α=0.05) 70℃时的强力:20.5, 18.8, 19.8, 20.9, 21.5, 19.5, 21.0, 21.2 80℃时的强力:17.7, 20.3, 20.0, 18.8, 19.0, 20.1, 20.0, 19.1 12345678from scipy.stats import ttest_relimport pandas as pd x = [20.5, 18.8, 19.8, 20.9, 21.5, 19.5, 21.0, 21.2]y = [17.7, 20.3, 20.0, 18.8, 19.0, 20.1, 20.0, 19.1]# 配对样本t检验t_val, p = ttest_rel(x, y)print('t_val：',t_val,\" p值：\", p) 结论: 因为p值=0.1149&gt;0.05, 故接受原假设, 认为在70℃时的平均断裂强力与80℃时的平均断裂强力间无显著差别 双独立样本T检验 例子：甲乙两台机床加工螺丝帽，螺丝帽的半径都服从正态分布，为验证两台机床加工的螺丝帽半径是否相等，分别取两台机床加工的8、7枚螺丝帽进行测量，分别测得[20.5,19.8,19.7,20.4,20.1,20.0,19.0,19.9][20.7,19.8,19.5,20.8,20.4,19.6,20.2] 问两台机器生产的螺丝帽半径是否有差异（α=0.05） 12345678from scipy.stats import norm,ttest_ind #引入正态分布(norm)，T检验（ttest_ind） n1_samples = [20.5,19.8,19.7,20.4,20.1,20.0,19.0,19.9]n2_samples = [20.7,19.8,19.5,20.8,20.4,19.6,20.2] #独立双样本 t 检验的目的在于判断两组样本之间是否有显著差异：t_val, p = ttest_ind(n1_samples, n2_samples)print('t_val：',t_val,\" p值：\", p) #p值小于0.05时，认为差异显著；大于等于0.05时表示差异不显著 结论：p值=0.408&gt;0.05，接受原假设，甲乙机床制造的螺丝帽半径没有显著性差异 五、卡方检验卡方检验又称X2检验，就是检验两个变量之间有没有关系。 属于非参数检验，主要是比较两个及两个以上样本率（构成比）以及两个分类变量的关联性分析。根本思想在于比较理论频数和实际频数的吻合程度或者拟合优度问题。 X2计算公式为： 例子1：有AB两种药可以治疗某种疾病，问两种药物的疗效是否相同？ 药类 有效 无效 合计 有效率 A药 67 26 93 72.04% B药 44 30 74 59.46% 合计 111 56 167 66.47% 解：建立假设H0，两种药物疗效相同，计算得其理论值为： 药类 有效 无效 合计 A药 61.8 31.2 93 B药 49.2 24.8 74 合计 111 56 167 X2=（67-61.8）2/61.8+（26-31.2）2/31.2+（44-49.2）2/49.2+（30-24.8）2/24.8=2.94 六、F检验F检验法是检验两个正态随机变量的总体方差是否相等的一种假设检验方法。 F统计量计算公式： 例子：存在两组数据，需要验证这两组数据的方差齐性。x = [20.5, 18.8, 19.8, 20.9, 21.5, 19.5, 21.0, 21.2]y = [17.7, 20.3, 20.0, 18.8, 19.0, 20.1, 20.0, 19.1] 123456from scipy.stats import levene x = [20.5, 18.8, 19.8, 20.9, 21.5, 19.5, 21.0, 21.2]y = [17.7, 20.3, 20.0, 18.8, 19.0, 20.1, 20.0, 19.1]f_val, p = levene(x, y)print(f_val, p)","tags":["Math"],"categories":["Math"]},{"title":"离散数学_cookmanual","path":"/2024/07/01/离散数学-cookmanual/","content":"逻辑运算真值表没什么好说的 析取 合取 推导析取就是布尔运算中的或 合取就是布尔运算中的且 推导（蕴含）就是只有10是0，其他是1，等价于 成真赋值 成假赋值意即pqr均为0时为真 亦即pqr均为0时为假 主析取范式DNF 主合取范式CNF找到所有和注意析取范式外面是合取范式外面是 嘶为什么呢？我个人猜测，因为CNF就是要求式子满足时为假，所以再在DNF式子外面套一个非，就变成内或外于了 数论自反、反自反、自反闭包一个上的关系如果对于，有，则自反 反之为反自反 将不自反的关系补充为自反，补充后的关系称为原关系的自反闭包 对称、反对称、对称闭包一个上的关系如果对于,，当，则也有，则对称 反之反对称，但是注意反对称并不排斥自反的情况 传递、非传递、传递闭包一个上的关系如果对于,，当，，则也有，则传递 否则非传递 常见的关系偏序：自反，反对称，传递 实数集上的大于等于关系是偏序，但是大于不是，自然数集上的整除关系也是偏序 等价：自反，对称，传递 实数集上的等于关系 相容：自反，对称 集合A={cat, teacher, cold, desk, knife, by}，定义关系r = {&lt;x, y&gt; | x, y∈A 且 x和y有相同的字母}，那么r是一个相容关系。 关系矩阵不多说了 复合运算把传递关系找出来，头尾相接，看清是左复合还是右复合 哈斯图 极值 最值 上确界 下确界哈斯图的画法要求覆盖性、并且不能有平线、三角性的形成 集合包含关系的哈斯图 极值可以有多个，最值只能有一个 上确界和最大值的关系：如果最大值存在，那上确界就是最大值，如果不存在，比如，那么1是上确界，也就是说确界可以在集合中，也可以不在集合中。 幺元 零元 与逆元幺元：与其他元素操作后，总是得到其他元素的元素（乘法中的1） 零元：与其他元素操作后，总是的到自己的元素（乘法中的0） 逆元： 对于一个元素，与它操作后得到幺元的元素是逆元（乘法中的倒数） 封闭性 结合性 交换性对一个集合做操作，不论怎么操作，结果都还在集合内，比如全体整数的加法操作，则满足封闭性，否则不满足，如全体正整数的减法操作 结合性 a*b*c=a*(b*c) 交换性 a*b = b*a 群一个非空集合，如果定义一个运算满足下面四个性质，则为群 封闭性 结合律 有单位元 每个元都有逆元 证明群也就是证明这四个条件（具体证明得再找个题目）","tags":["Math"],"categories":["Math"]},{"title":"利率风险","path":"/2024/07/01/利率风险/","content":"利率风险 收益是现金流的总和除以利率浮动 债券估值 当利率上升时，从前的债券利率却不变，导致债券估值迅速下降 Eaxmple 硅谷银行 银行的收益方式：将储户的钱拿去放贷，当放贷量不足时，可以通过债券补充 硅谷银行在新冠期间，由于联邦银行大放水，储户存款大幅增加，为了弥补放贷不足的原因，硅谷银行大量持有以房贷为基础的债券。 由于开闸放水导致了通货膨胀，美联储对存款和国债进行加息以抑制。这时硅谷银行发现由于利率的上升和货币的贬值，自己手里的债券开始赶不上新发行的债券，甚至赶不上货币贬值。 走投无路的硅谷银行试图融资，却暴露了自己资不抵债的现实，导致自己遭遇了储户和投资人的挤兑。最后噶了。 Example 日本人寿保险 人寿除了赌客户不会出事以外，还可以与客户签订超长期的（一直到客户死）的定利率存款。 由于日本当时经济突飞猛进，很多人寿和客户签订了高达6%的复利存款（11年就会番一番！），由于日本后期经济崩溃停滞，利率疯狂下跌，人寿公司完全支付不了之前签订的存款，直接倒闭。 尾部利率风险 寿险公司有很多发生概率很小，但是赔付额很大的负债现金流，一般这些负债赔付要在30年以后发生，但是市场上根本没有什么30年期权的债券","categories":["economics"]},{"title":"PCA","path":"/2024/07/01/PCA/","content":"Hiton发明的AutoEncoder架构，迅速的取代了PCA 主成分分析是一种常用的无监督学习方法，利用正交变换将线性相关变量表示的观测数据转换为少数几个由线性无关变量表示的数据，这些线性无关变量被称为主成分，是一种常用的降维方法。 看起来AutoEncoder被更多的用来降维了 直观感受： 对空间中的坐标系进行变换，使得将样本点对变换后的坐标系投影后，方差尽可能的大。 步骤 中心化（目的是令投影后均值为0） 接下来我们要找到一些，使得在方向方差最大 由于投影后均值也为0，我们可以将投影后的方差表示为 于是我们基于这两个约束求解 对求导令导数为0，可以得到条件 此时 基于此我们可以得到 所谓的方差就是协方差矩阵的特征值，而我们要的向量就是对应特征值的特征向量 降维 我们可以抛弃较小的特征值，从而实现降维，降维后的信息含量可以计算为 执行PCA变换 例题pca例题 思考 协方差的大小，经过正则化后，是否能表示相关性？ 答案是可以！也就是相关系数r 为什么PCA逐渐被AutoEncoder取代？PCA和AutoEncoder二者间的专长在哪里？ 考虑这样一个分布 由于PCA只是对坐标系做线性变换，如果强行降维，右上角的聚簇就难以被区分了，而AutoEncoder并不强行做线性变换，也许可以学到再用一个特征来区分右上角的聚簇。","tags":["ML","Transformer"],"categories":["ML"]},{"title":"虚拟内存与Swap分区的区别","path":"/2024/05/29/虚拟内存与Swap分区的区别/","content":"一句话来说，虚拟内存是通过MMU地址转换和懒加载实现的让应用程序以为自己独享一大块内存的机制，Swap分区是一种使用换入换出机制实现的缓解linux内存不足的缓冲机制。 即使一个Linux系统没有启用Swap分区，虚拟内存也是存在的，二者根本就在不同的维度上。 一个应用程序申请内存时，操作系统会为它的页表（当然这里可以有多级机制，段-页目录-页表之类的）新增一个页，但是在程序真正操作这个地址之前，这个页并不会真的映射到物理内存上，只有当程序开始操作这个地址，操作系统才会通过缺页中断映射这个页。 Swap分区的工作层更底层，Swap分区会在操作系统检测到物理内存不足时运作，将不活跃的内存换出至Swap分区，等到再次访问时再换入 下面这部分是我猜的，找了半天也没找到一张好的linux访问内存的流程图 一个没有swap分区的系统，当应用程序要一个地址，只要这个地址是合法里，肯定在内存里，对于有swap分区的系统，如果内存里没有，那就得到磁盘里去找le","tags":["OS"],"categories":["系统方向"]},{"title":"Transformer架构学习","path":"/2024/04/27/Transformer架构学习/","content":"单词向量空间应该是是最直接，最古早的文本编码思想了 基本想法是给定一个文本，用一个向量表示该文本的“语义”，向量的每一维对应一个单词，其数值为该单词在该文本中出现的频数或权值 基本假设是文本中所有单词的出现情况表示了文本的语义内容 我们的基本空间是全体文本和全体文本中的所有单词，它们可以共同组成矩阵 最早常用的权值叫 单词频率-逆文本频率 其中单词频率指这个单词在目标文本中的频率，即 逆文本频率指的是这个单词在全部文本的多少篇文本中出现过的倒数取log 即这个单词越是只在这个文本中出现，就越能代表这个文本，自然重要度也就越高 乘起来就是了 度量两个文本的相似度可以用余弦 word embedding如果我们有10000个单词，我们可能会想用一个长度10000的向量来表示单词，只要是哪个单词对应的编号就位1，其他为全0 但是这样我们无法得到各个单词之间的相关性，我们希望能有一种无监督的方法，自然地帮助我们找到单词之间的关系 两种很棒的无监督方式是 聚类式 生成对抗式 word embedding更类似于后者 我们可以训练一个函数，这个函数用一个中心单词预测周边单词出现的概率 这个结构就好像： 输入是one-hot编码的单词，一个神经网络将one-hot单词编码到隐藏维度，隐藏维度接上softmax就是每个单词出现在下一个的概率 因为one-hot就是只有一个维度为1的向量，所以相当于选出了隐藏层权重矩阵的一行，也就是隐藏层的权重矩阵就是我们的wordvec单词表了！假设我们有十亿个单词，隐藏层的维度是300，我们就相当于将十亿维的one-hot表示压缩成了300词向量表示，而且还获得了语义信息。 position embeddingSelf-Attention的初衷解决当输入是一个确定数量的向量集时使用 输入是向量 E.G NLP中将数据到向量one-hot假设所有词汇之间没有关系，没有任何语义信息 word-embedding见上 输出有三种情况 输出是每个向量打一个标签举例：词性标注 输出就是一个标签举例：感情分析 输出是一个Sequence就是我们最关注的Sequence2Sequence 如何考虑上下文信息？最直接的想法是用滑动窗口，包住一定的上下文，但是输入是无限制的，所以不可能完全考虑 self-attention 输出和输入向量数量相同的向量，但是这些向量是考虑了全局信息的 首先定义参数作为每两个输入之间的相关性，这个相关性目前经常用dot product给出 提供了向量，提供了k向量，q有个名字叫做query，k有个名字叫key，q和每个k点乘就能得到相应的相关度，最后哦我们通过一个softmax归一化即可得到标准化的相关度。 接下来我们需要借此获得上下文相关向量，我们再通过一个与原a相乘得到一个新的向量v，这个v会和每个数乘然后相加得到这个向量的上下文相关表示","tags":["ML","Transformer"],"categories":["ML"]},{"title":"四元数与计算机图形学","path":"/2024/04/25/四元数与计算机图形学/","content":"教材link quaternion 四元数 复数 (Complex Number ) 与矩阵旋转四元数和复数有非常大的相似度 复数的常见运算可以等价为矩阵的常见运算 任何一个复数 可以表示为矩阵 其相应的加法与乘法都可以等价过来 我们知道二维旋转矩阵的公式是 这个矩阵也可以被表示成一个复数，即 那么这时向量也表示成 旋转过程即被表示为 极坐标与复数欧拉公式之前完全就是只听说过名字 对任意实数x，都存在 另x=，得到欧拉恒等式 证明可以使用我们的好朋友泰勒公式，对泰勒展开即可将奇数项和偶数项分别凑出cosx和sinx的泰勒展开式 欧拉公式给出了复平面中对圆的描述 所以我们可以将复数改写为 其中是模长，是xy通过atan2给出的方向角 如此复数就可以被一个缩放因子r和旋转角定义 旋转公式也就被表示为 由于复数乘法满足交换律，因此旋转是可以复合操作的 三维空间的旋转假设我们有一个穿过原点的旋转轴为，现在我们要旋转向量 （如果实际操作中旋转轴不穿过原点，可以先把旋转轴移动到原点，转完再移回去，这就是MVP变换的思想之一了） 任何要对着这个轴旋转的向量都可以被分解到两个方向——垂直方向和平行方向 平行u方向什么都不用做，垂直u方向可以被降维为2D平面中的旋转 2D平面的基向量由在这个2D平面的分量和这个分量与的叉乘给出 从而有 配合平行的分量就是 四元数与旋转我们之前推出过这个公式 四元数的性质告诉我们可以直接将和变成相应的纯四元数 同时我们还可以变换 根据四元数的乘法 可以得到 所以叉乘也能被换成纯四元数（因为它们垂直呢） 𝑣 ′ ⊥ = cos(θ)𝑣⊥ + sin(θ)(𝑢𝑣⊥). 把提出来（四元数满足分配率） 𝑣 ′ ⊥ = cos(θ)𝑣⊥ + sin(θ)(𝑢𝑣⊥) = (cos(θ) + sin(θ)𝑢)𝑣⊥. 就可以发现(cos(θ) + sin(θ)𝑢)也是个四元数 记作 补上平行的分量 𝑣 ′ = 𝑣 ′ ∥ + 𝑣 ′ ⊥ = 𝑣∥ + 𝑞𝑣⊥. 同时还可以直接计算证明两个引理 如此依赖我们可以自定一个四元数 由于pp*（共轭）=1 我们可以把之前的式子变成 𝑣 ′ = 𝑝𝑝∗ 𝑣∥ + 𝑝𝑝𝑣⊥ = 𝑝𝑣∥𝑝 ∗ + 𝑝𝑣⊥𝑝 ∗ = 𝑝(𝑣∥ + 𝑣⊥)𝑝 ∗ . 最后就得到了 看起来这个公式还只是万里征途的第一步，今天就到这里吧","tags":["ML","Computer Graphics"],"categories":["ML"]},{"title":"ML2024:weekly report","path":"/2024/03/07/ML2024-weekly-report/","content":"Week 1 Process Progress Basic Knowledge 了解高斯过程(Gaussian Process)与高斯过程回归 Few-shot learning Reading Literature Review Generalizing from a Few Examples: A Survey on Few-Shot Learning并阅读其中提到的一些论文 Ideas Thesis Research Interest Gaussion Process RegressionGaussion Processsvd分解 协方差矩阵svd分解 Few-shot learning至少这篇综述的作者将few-shot learning的最大问题归结为“无法找到一个可靠的经验风险最小化”，并依据逼近最佳经验风险最小化的方法将few-shot learning的研究分为三大方向：通过利用先验知识丰富数据集的Data方向，通过提供更加精准的先验假设减小假设空间的Model方向，通过训练时使用更有针对性的算法逼近最佳假设的Algorithm方向 2.3.2 Unreliable Empirical Risk Minimizer. In general, Eest(H, I ) can be reduced by having a larger number of examples [17, 18, 41]. Thus, when there is sufficient training data with supervised information (i.e., I is large), the empirical risk minimizer hI can provide a good approximation R(hI ) to the best possible R(h∗) for h’s in H . However, in FSL, the number of available examples I is small. The empirical risk RI (h) may then be far from being a good approximation of the expected risk R(h), and the resultant empirical risk minimizer hI overfits. Indeed, this is the core issue of FSL supervised learning, i.e., the empirical risk minimizer hI is no longer reliable. Therefore, FSL is much harder. A comparison of learning with sufficient and few training samples is shown in Figure 1. DataTransforming Samples from M. G. Miller, N. E. Matsakis, and P. A. Viola, “Learning from one example through shared densities on transforms,” in Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662), Hilton Head Island, SC, USA: IEEE Comput. Soc, 2000, pp. 464–471. doi: 10.1109/CVPR.2000.855856. 通过在讲原训练集里千奇百怪的手写数字进行图像变换求各个类别中的最小熵来提高数据集的质量，最终提升了分类器的水平 @inproceedings{Kwitt16a, author = {R.Kwitt and S.Hegenbart and M.~Niethammer}, title = {One-Shot Learning of Scene Locations via Feature Trajectory Transfer}, booktitle = {CVPR}, year = 2016} 描述了一个数据集不完全的场景：对于一片海滩，绝大多数都是风和日丽的照片，下雨天的图片很少，这会导致机器识别率降低，通过模型学习原有图片库上的特征，得到一个转换器 这篇文章的Methodology部分看不懂， 作者将xi定义为： Each image Ii is assigned to one of C scene locations (categories) with label yi ∈ [C]† and represented by a D-dimensional feature vector xi ∈ X ⊂ RD. 我认为xi是表示第i张图片的D维矩阵，同时作者提到每个图片还有一个人工标注的“瞬态属性”向量，大抵是反应这张图片收到大雾、风雨、黑夜等情况干扰的严重程度？ Additionally, each image is annotated with a vector of transient attribute strengths ai ∈RA+, where AT denotes the set of attributes and A = |AT |. 作者表示他们使用高斯过程回归模型来预测， For a given scene location, we wish to estimate the path γk : R+ → X for every attribute in AT . In our case, we rely on a simple linear model to represent this path. Formally, lets ﬁx the scene location c and let Sc = {i : yi = c} be the index set of the M = |Sc| images from this location. The model, for the k-th attribute, can then be written as xi = wk · ai[k] + bk + ǫk 我这里不是很明白这个式子是通过ai合成xi，还是在用xi，ai求wk，qk？我感觉更像是后种 Week 2 Process Progress Basic Knowledge 学习基本的图像处理，包括霍夫变换，灰度矩阵，Rasterization 光栅化等 Few-shot learning Reading Literature Review Generalizing from a Few Examples: A Survey on Few-Shot Learning并阅读其中提到的一些论文 Ideas Thesis Research SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes（cvpr 2024） Interest Thesis ResearchLAA-Net: Localized Artifact Attention Network for High-Quality Deepfakes Detection （cvpr 2024 source code haven’t been uploaded） 一开始我以为这个方法能够甄别大模型生成的图片，但是看了文章所举的例子好像只能检测一张原图哪里可能被ps过，就失去了兴趣 SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes（cvpr 2024） 3D Gaussian Splatting for Real-Time Radiance Field Rendering （cvpr 2023 best-paper award） 最近关于Gaussian Splatting的文章似乎比较多，我个人有点感兴趣 图形学中的基本变换图形学中的基本变换 MVP变换观察矩阵的推导 齐次坐标 mvp变换 Rasterazation 光栅化光栅化 光栅化 算法流程输入：一组静态图像和通过sfm分析后生成的有关图像的稀疏点阵 structure from motion 由于得到的点阵十分稀疏，所以很难估计法线，因此作者选择了不需要法线的3d gaussians 这个3d状态下的Gussian可以看做一个3d椭球，因此作者采用不是立方体或者锥体的表示形式，而是采用了椭球 椭球需要颜色和透明度信息，这里采用了球谐函数拟合颜色信息 这些椭球会被投影到二维平面，进行光栅化 Week 3 Process Progress Basic Knowledge Few-shot learning Ideas Thesis Research SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes（cvpr 2024）3D Gaussian Splatting for Real-Time Radiance Field Rendering Interest 3D Gaussian Splatting for Real-Time Radiance Field RenderingNaive Thoughts 能否使用更加复杂的网络达到更好的效果？Resnet? 能够使用更加复杂的溅射模型表示更细粒度的3d信息？球谐函数溅射？ 能否使用类似corpas的手段减少模型预测需要的图片样本？ Large model for filling the blank space? (Someone already started, see: dreamgaussian) Gaussian模型渲染的结果太大了，可能难以用于游戏、网页等场景（个人猜测），如何通过一些手段在不怎么降低精度的同时减小大小，比如移除不必要的渲染，尝试用更少的guassian，用更复杂的模型进行溅射，平滑化？ Method使用Gaussian模型表示世界 Our representation has similarities to previous methods that use 2D points [Kopanas et al. 2021; Yifan et al. 2019] and assume each point is a small planar circle with a normal. 作者借鉴2021年发表的一篇文章，这篇文章将每一个点都看做具有法线的小平面圆，但是做法对于极度稀疏的sfm点集不合适，因为预测和优化它们的法线过于困难（我还没详细了解为什么困难），所以作者最后采用了不要法线的几何模型： 3维高斯 可微渲染 Differentiable rendering: 重要性与难点，以及为什么3维高斯是一个很棒的可微渲染基础可微渲染 不论是通过图片获得3d模型，还是通过3d模型渲染2d图像，引入深度神经网络都是十分诱人的，但是要引入神经网络，以3d模型渲染2d图像来说，需要保证能找到这样一个渲染： 其中代表了空间坐标、相机位置、光线、材料等，I是渲染出的图片 如果R是一个函数Loss，我们就通过一个可微的损失函数，通过 进行反向传播和梯度下降操作，从而将这个渲染过程加入到神经网络中 3维高斯、基于点的渲染与可微渲染目前最流行（至少作者这么说）的渲染方式是基于点渲染 「其他的方式还有votex-based（基于体积的），Mesh-based（基于网的）我还没有详细了解这些方法」，输入是点云，输出是渲染的结果 但是基于点的方法最严重的缺陷在于它是严格不连续的，因此想进行可微渲染就十分麻烦，于是就出现了所谓的溅射“splatting”，它是指不再用一个“点”（不知道最原始的点云里面的点有没有大小？）而是用大于一个像素点的基元来代替点，比如圆、椭圆（上面作者引用的Kopanas的论文就采用了使用法线来表示方向的椭圆）、椭球（作者的3D Guassian模型渲染出来就像个椭球）等来表示（我还没想明白为啥溅射能解决点云严格不连续的问题，我能理解这个基元是可微的，但是基元和基元之间怎么办，难道是连续的吗？） Example：NeRF——基于体渲染公式将MLP引入三维重建 模型输入： 一个五维向量：前三维代表世界坐标系下点的坐标，后两维代表球坐标系表示的点的观察角度（代码中实际并不是这样，首先为了刺激模型，作者还引入了由sin和cos函数计算的高维数据，同时观察角度使用的也不是球坐标系） NeRF采用的并不是基于点的渲染，而是基于体积的渲染，采用公式： 这个公式表示对于射线(其中是原点，是射线的方向，每个t唯一对应着射线上的一个点)，代表着t点的密度，代表着t点在空间中在视角下直接观察的颜色，由于射线上有无数多的t点，最后渲染而成的2d图像上的点应当是这些点按某种方式累和成的结果，同时除了透明度和点本身的颜色会影响这个点在累和中的效果外，射线到达此处的光强也是影响因素之一，也即. 从到进行积分，就相当于将从视线距相机最近处到距相机最远处的所有点的效果累和在一起，形成二维图像上的点 其中，和是我们通过神经网络训练得到的函数，NeRF采用的基本神经网络是全连接的，也即kerras.layer.Dense 射线的求取： 123456def get_rays(H, W, focal, c2w): i, j = tf.meshgrid(tf.range(W, dtype=tf.float32), tf.range(H, dtype=tf.float32), indexing='xy') dirs = tf.stack([(i-W*.5)/focal, -(j-H*.5)/focal, -tf.ones_like(i)], -1) rays_d = tf.reduce_sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1) rays_o = tf.broadcast_to(c2w[:3,-1], tf.shape(rays_d)) return rays_o, rays_d 为了让神经网络获得高频信号，NeRF作者发明了Position Encoding，通过一组sin cos函数将低频输入转换为高频信号（这个思想内核我还没有理解清楚） 123456789101112131415161718192021222324252627282930313233343536373839def init_nerf_model(D=8, W=256, input_ch=3, input_ch_views=3, output_ch=4, skips=[4], use_viewdirs=False): relu = tf.keras.layers.ReLU() def dense(W, act=relu): return tf.keras.layers.Dense(W, activation=act) print('MODEL', input_ch, input_ch_views, type( input_ch), type(input_ch_views), use_viewdirs) input_ch = int(input_ch) input_ch_views = int(input_ch_views) inputs = tf.keras.Input(shape=(input_ch + input_ch_views)) inputs_pts, inputs_views = tf.split(inputs, [input_ch, input_ch_views], -1) inputs_pts.set_shape([None, input_ch]) inputs_views.set_shape([None, input_ch_views]) print(inputs.shape, inputs_pts.shape, inputs_views.shape) outputs = inputs_pts for i in range(D): outputs = dense(W)(outputs) if i in skips: outputs = tf.concat([inputs_pts, outputs], -1) if use_viewdirs: alpha_out = dense(1, act=None)(outputs) bottleneck = dense(256, act=None)(outputs) inputs_viewdirs = tf.concat( [bottleneck, inputs_views], -1) # concat viewdirs outputs = inputs_viewdirs # The supplement to the paper states there are 4 hidden layers here, but this is an error since # the experiments were actually run with 1 hidden layer, so we will leave it as 1. for i in range(1): outputs = dense(W//2)(outputs) outputs = dense(3, act=None)(outputs) outputs = tf.concat([outputs, alpha_out], -1) else: outputs = dense(output_ch, act=None)(outputs) model = tf.keras.Model(inputs=inputs, outputs=outputs) return model 具体的训练过程： stateDiagram-v2 相片像素 --&gt; 相机坐标+视角 相机坐标+视角 --&gt; 世界坐标+视角 世界坐标+视角 --&gt; 输入mlp网络 输入mlp网络 --&gt; 预测空间密度与颜色 预测空间密度与颜色 --&gt; 使用体渲染公式得到图像 使用体渲染公式得到图像 --&gt; 与测试图像比较获得loss 与测试图像比较获得loss --&gt; 根据loss进行反向传播 Gaussian Splatting sfm提供的点被初始化，提供一些Gaussian椭球，然后对高斯椭球对特定的方向进行投影得到2D高斯分布（看起来就像一个个椭圆），对这些椭圆进行光栅化，得到2d图像，使用距离和D-SSIM构造一个损失，通过反向传播进行优化，这里的Adaptive Density Control 用于进一步改善3d Gaussian的分布。 对高斯椭球进行投影作者基本参考这篇文章：EWA volume splatting 首先一个中心为，分布为三维的高斯模型可以进行仿射变换、卷积变换，还可以沿着某一方向做积分得到二维高斯分布（投影的关键），投影得到也非常容易，只需要在原来的协防差矩阵中去掉积分的那个变量对应的行和列即可 最后可以得出这个公式(我还没细看数学原理)： 其中W对进行视口变换，J对进行投影变换（为了将投影变换变成仿射型的定义，这里还采用了泰勒展开和雅各布矩阵（还没细看）） Back probackation同时为了更好的适配梯度下降，作者没有采用协方差矩阵的标准定义（因为协方差矩阵必须是半正定的，而半正定矩阵这个条件很容易被梯度下降过程破坏），最后作者还是采用了更像椭球溅射的表示，用一个缩放矩阵和旋转矩阵来表示对高斯椭球的微调。在代码实现中，这两个矩阵被分别存储在一个3维向量s和一个四元数q中，基于此，作者提供了对每个参数的链式梯度下降公式 Adaptive Density Control反向传播可以更新高斯椭球的形状、大小、透明度和颜色，但是高斯椭球的数量、位置等信息无法直接通过反向传播更新，作者额外构建了Adaptive Density Control 机制实现对这些信息的更新 对高斯椭球的移除实现上每100轮做一次，遍历所有的高斯椭球，移除那些值接近0的 对于添加，反向传播的参数能看出一些端倪，比如一个高斯椭球有关位置变量的梯度比较大，这就意味着指向该pos的地方需要一个高斯椭球，这是我们可以clone原来的高斯椭球并直接放到pos梯度指向的位置去 同时一些地方可能存在一个奇大无比的高斯椭球并且出现了过拟合的情况，这时就要在该区域添加高斯椭球，作者采用的方式时将原本的高斯椭球通过一个超参数变小，然后克隆两份 高速光栅化（超越NeRf的关键）Fast Differentiable Rasterizer for Gaussians关键：Tile based, Pre sort Gaussian NeRF需要对每一个像素构建一个射线，每一个射线进行一大堆采样 总体来说，经典的点云可微渲染是这样的： 集合是覆盖在该像素点前的2d高斯云，是颜色是该2d高斯的不透明度，渲染的图像也是通过一系列2d高斯效果的叠加实现，与NeRF最大的区别在于NeRF需要高昂的空间采样成本 ![](/Users/lyl/Desktop/Screenshot 2024-04-02 at 18.55.44.png) tile based rendering 基于图块的渲染 作者将整个屏幕空间分成了1616个tiles，然后对每个tile找到会影响它的那些Gaussian（只取相交置信区间为99%的那些高斯球体） 然后根据每个高斯球体覆盖的tiles实例化它们，同时用一个类似hashtable的结构进行存储，键值记录了空间深度和tile ID 接下来根据键值对guassian椭球进行排序，排序算法使用Radix sort，这种排序算法可以利用GPU进行高速排序 GPU Radix sort ![](/Users/lyl/Desktop/Screenshot 2024-04-02 at 19.29.25.png) 只需要完成这一次排序，后续的渲染都可以依据此进行 完成排序后，对于每个tile都可以构建一个list，记录针对该tile从前往后的guassian list 开始渲染，首先对于每个tile启动一个线程池，将前面构建的高斯椭球表加载到共享内存中，然后针对每一个像素（我在想这里能不能并行？）从前往后遍历每个tile的list，当累积到每个值即可停止（很多搞NeRF的人也是这么优化的） 这个高速渲染的过程不仅加速了渲染，也加速了反向传播的过程(还没细看) Week 5 Task Progress Learning the Basics for Gussian Splatting and Generation Models learning Basic VAE, GANs 3D gaussian splatting reconstructions for Human Body Other interesting works for 3D gaussian DreamGaussian VAEautoencoder最原始的想法是通过Encoder寻找一个将原始图像压缩后的latent，并且确保可以通过一个decoder从这个latent生成相同类型的图像 variational autoencoder但是仅仅得到一个固定的向量latent十分无聊，因为这个latent并不能很好的反应input x之间的关系，例如两个类似的图像，它们得到的latent可能完全不一样，也不能对它进行特征合成之类的操作 variational autoencoder得到的并不是一个直接的latent，而是由参数描述的一个概率分布（一般是高斯分布），相似的图像在这里被映射到相似的概率分布，这些概率分布可以进行合成或者其他操作 (我想这里我还得更加深入的看看，目前只是简单听了下UC Berkeley CS 198-126,还没看论文) vector Quantised-variational autoencoder基于高斯分布latent的vae，Encoder输出的是一个参数化的分布，但是对于一些任务，离散的latent会更加合适（比如NLP方向，不过我还没细想为啥是latent，我能想象到decoder的output应该是离散化的，因为词语没法连续，但是为什么latent也要是离散的？） vq-vae采用了codebook和聚类的想法，将Encoder输出的那些非法的，不在codebook中的向量通过近邻算法聚类到相应的codebook中的类别去 （codebook中的类别要如何安排、损失和反向传播要如何进行这些问题还没有研究） GANArch Cross Entropy熵是用真实分布和真实编码计算平均编码长度，交叉熵是用真实分布（我们需要在具体任务中自行定义什么是真实分布）和预测编码计算平均编码长度 交叉熵与熵的差被叫做KL散度，我们可以利用证明KL散度始终大于0. See here 从而证明交叉熵始终大于等于熵（相等条件：预测分布等于真实分布），基于此可以构造各种各样的损失函数 Gan所采用的损失函数就是交叉熵（的负数），其中生成模型G尝试将这个损失最小化（负数绝对值越大，意味着D模型分类得越糟糕），而D模型则不断尝试将这个损失最大化 Conditional Gan有时候我们可能有更高的生成要求，比如生成特定的数字或者特定的汉字，如果我们只是把一大堆数字图片和标签丢给Generator让Generator学习，而Discriminator又只能拿到图片的话，最后Generator可能会把9学习成6，而Discriminator没有办法阻止这一点 于是我们进一步改进，让Discriminator也能拿到标签，这样当D看到一个G生成的一个非常真是的6但是却打上了9的标签时能够及时识别为fake，这样G就不得不认真的分类学习了 Gan 问题 如果D模型太强，交叉熵接近0，权重在反向传播时也接近0，G模型不知道怎么调整自己来继续和D模型比赛，直接摆烂睡大觉 mode collapse，G发现有一张图片特别能迷惑D，于是为了取胜，G之后越来越倾向于输出这张图片，最后甚至只输出这张图片 损失不收敛，模型D和模型G会不断的竞争，损失也可能不断的摇摆，无法确定什么时候两个模型已经足够好，并且两个模型都有过拟合的风险 Improving GANs我们可以稍微调整损失函数为 这样的损失函数在D模型完全判断正确时给出一个超大的loss，拍着G的屁股让它大踏步的改生成策略 Week 6 Papper Core Idea HUGS: Human Gaussian Splats 使用SMPL模型进行初始化，在训练中的高斯球云可以偏离这个初始化以便于适应衣服、头发等内容，使用三个MLP神经网络分别预测高斯椭球的future triplane中的颜色、透明度、缩放、旋转和LBS权重，从而对人体不同的动作和视角进行合成 Gaussian Shell Maps for Efficient 3D Human Generation 同样采用了SMPL进行初始化，不同的是采用了Multi Shell技术，将人体理解为一层一层向外包裹的Shell，同时通过GANS网络训练一层一层shell，使其与真是图像越来越接近，这种设计可以灵活的更换不同的shell层，从而实现给人体更换发型、服装等特性 HUGS: Human Gaussian SplatsHUGS将人体和环境都基于高斯球云进行表示，并使用SMPL模型初始化人体的高斯球云，为了更好的拟合SMPL模型中没有的头发、服饰等特征，高斯球云可以在后续训练中适当偏离SMPL模型。同时高斯椭球的颜色、不透明度、缩放、旋转、Linear Blend Skinning 权重等特征通过feature triplane（三平面特征）进行表征，通过训练三个MLP模型对feature triplane进行预测，并将预测得到的颜色球谐函数、缩放等属性用于构建人体，LBS权重则用于驱使高斯球云组成不同的人体形态，从而实现新动作的合成。 Gaussian Shell Maps for Efficient 3D Human GenerationGSM结合了3D 高斯和基于CNN的生成式网络，核心思想是将3D高斯锚定到一系列基于SMPL模型生成的壳(Shell)中，并通过生成模型生成对应的shell map，并作为对应Gaussian的颜色、透明度等特征的来源，同时引入GANs网络对渲染结果进行优化，并针对人体专门提供了甄别手足、面部的Discriminator。通过将高斯球体与shell基于重心坐标一一锚定，变化高斯球云可以通过首先变换Shell mesh，再查询高斯球体在变换后的shell mesh中对应的顶点来获取变换后的位置。 GauHuman: Articulated Gaussian Splatting from Monocular Human VideosGauHuman同样基于SMPL模型进行初始化，并且同样引入MLP模型对LBS权重进行预测，与HUGS不同的是，GauHuman并没有使用feature triplane来表示高斯球体的颜色、缩放等特征，（这句我不能确定）而是仍然将这些信息存储直接在高斯球体中，这进一步提高了渲染效率，同时为了避免直接使用MLP模型预测LBS权重带来的时间开销和低质量的渲染效果，GauHuman引入两个针对SMPL LBS权重进行细化的MLP模型，其中用于细化SMPL模型中的pose参数，用于细化LBS权重偏移。同时GauHuman改进了Adaptive Density Control过程，通过引入KL散度将高斯球体间的距离也纳入了Density Control的考虑指标，从而实现更好的训练效果。 GaussianAvatar: Towards Realistic Human Avatar Modeling from a Single Video via Animatable 3D GaussiansGaussianAvatar同样使用了SMPL模型进行初始化，对于输入的单目视频中特定的一帧所对应的SMPL模型，GaussianAvatar首先对该SMPL模型采样得到一个UV positional map I，并传递给一个pose encoder以得到一个Pose Feture，由于单目视频带来的数据偏差，仅仅通过这个Pose Feature进行训练很容易导致模型对某些常见帧的过拟合，GaussianAvatar还引入了一个Optimizable Feature Tensor来学习粗略的动作表征以增强泛化性，二者整合后，由一个训练好的AutoDecoder解码获取高斯球体颜色、缩放等性质，最后将SMPL模型的LBS权重应用到人体模型中，实现动作变换。 Week 7框架 （技术分类，应用分类） 领域意义(Gaussian) 现有工作分类 每类展开 每类文章的特点，参考已有综述 略读，感兴趣的可以精读 综述应当压缩 输入输出，解决的问题，功能；现有方法的问题；怎么做的 摘要（任务），Introduction（现在的问题），Method（实现），（实验部分略过），related work（可以略过），appendix（一般是推导和补充） 这周被软工III的大作业压得喘不过气，主要是之前水得太狠了，只能邻近ddl的时候一通胡赶，所以这周的进展很小… 3DGS目前主要的应用分类Simultaneous Localization and Mapping (SLAM)主要是帮助快速建立一个当前环境的模型表示，对于智能机器人、自动驾驶设备有非常重要的作用 3dgs作为一个新的3d表示形式，其各向异性可以更好的描述场景，通过改进Adaptive density control，有机会实现对于现实环境实现更好的映射，同时3d高斯的计算加速也有助于更高效的场景建立 Dynamic Scene Modeling动态场景建模，反映到我目前在看的人体主要有两个方面，一个是3D人体的重建及对于固定动作的动画化，另一个则是合成能做出全新动作的人体，后者比前者要求更高的泛化性。 AI-Generated Content (AIGC)3dgs为***to 3d提供了新的3d场景表示，相较于NeRF的隐式表示，3D高斯显式的表示场景，更适合作为生成模型的生成目标，同时3dgs作为场景表示也更由于过去基于DreamFusion工作使用的Mesh+Texture的结构，反映到人体，人体模型的3d生成也是一个常见方向 人体一种分类是 身体、头部、头发和手部 对于身体又可以进一步分为full body modeling，同时按训练来源可以分为多角度视频和单目视频， 我目前计划的分类 mindmap root((分类)) 按部位分 人体整体 GSMs 头部 头发和手部 按目标分*有一点点不合适的就是几乎所有重建工作都有提到动画化 人体重建 多目重建： ASH:特色是引入了通过UV参数化，将高斯椭球锚定到可变形的网格上，高斯椭球的参数可以在二维纹理空间中学习，从动作捕捉器获取的骨骼运动信息到动态化参数的高斯椭球的过程就被简化成了2维图像到2维图像的转换任务。 Animatable Gaussians:特色是首先从多角度的图片学习一个从SMPL模型衍生而来的参数化模板，并通过将模板正交投影到正面和背面两个视图来在二维空间中学习高斯椭球的参数化，这两个与姿势相关的参数化视图则通过styleUNet生成模型生成 单目重建： GSMs:特色是引入了multi shell based scaffold, 通过styleGAN2生成shell map获得3DGS的属性，并针对头部、手部、足部提供专门的discrminater提高，同时3DGS提供的显示表征提供了便利的编辑，可以在多个实例之间互换服装 HUGS:特色是使用三平面表征，并通过MLP模型预测高斯椭球的性质和人体的LBS weight GauHuman:（与HUGs比较起来说）特色是引入了两个MLP微调模型为SMPL模型的LBS权重和姿态参数进行微调而非直接使用MLP进行参数预测，同时通过引入KL散度等改进了prune/split/clone过程 GaussianAvatar:特色是通过将姿态动作和特征属性解耦为两个不同的特征向量，通过encoder和decoder架构获得标准空间下人体模型 动态人体*deformation HUGS通过MLP预测LBS权重，再配合提供的Joint Configuration进行LBS变形可以实现全新动作的合成 GSMs通过首先变换shell map并查询高斯椭球在mesh中关联的顶点变换后的位置来完成变形 人体生成 ASH通过给定骨架姿态，变形人体模版，将相应高斯椭球锚定到变形模版的顶点上，并配合可动画化的纹理实现动作合成 我在想要不要把这些文章人体重建的过程大致抽象出来，因为他们都好像，但是又怕写错 :( Week 83D高斯泼溅所带来的高速渲染和显示表征为人体重建、动画化、人体生成任务提供了实时渲染和进一步优化细节和运动控制的机会。使用3D高斯溅射作为3D人体相关任务的基元并学习得到的显示表征的人体相较于使用神经网络辐射场（NeRF）学习得到的隐式表征的人体在渲染速度和泛化性上都有巨大的提升。最近的工作主要聚焦于利用3D高斯泼溅来重建得到可以实时渲染的虚拟人体或头像等，同时实现更精确的动作控制和新动作的合成，此外3D高斯泼溅与生成模型结合，生成高质量的人体模型也取得了一些突破。 对于人体整体的重建，HuGS提出了基于多角度视频利用3D高斯泼溅生成人体的方法，同时提出了一个从粗到细的人体动画化过程，首先使用LBS合成新的人体动作，而对于动作变换中非线性的部分，比如松弛服装在运动中的变换，HuGS提出了一个浅层神经网络进行捕捉和局部的变形改善。 HUGS使用单目视频即可训练，并使用三平面特征来表征高斯，高斯的特征(这里有疑问！)由三个分别负责预测颜色与不透明度、位置和旋转参数、LBS权重的MLP神经网络预测得到，这种方式方式相较于直接参数化单个高斯能够更好的避免过拟合风险，提供了更好的泛化性，能更好的完成全新动作合成的任务。 GauHuman则使用MLP模型对SMPL中的LBS权重偏移进行预测，同时使用另一个MLP模型对姿态进行进一步细化，避免直接使用MLP模型预测LBS权重可能带来的时间开销和低质量渲染。同时GauHuman还通过引入KL散度和改进合并操作来改进3D gaussian splatting原本方法中的分裂、克隆、合并过程。 GaussianAvatar结合了动态外观网络和可优化张量，从给定的SMPL模型帧采样点的位置并据此通过一个姿态编码器获得姿态特征张量，另外提供一个可优化外观特征张量来学习人体的外貌特点，这两个特征向量通过一个高斯参数阶码器得到标准空间下高斯的各个参数。 3DGS-Avatar指出HUGS、GauHuman等方法虽然达成了高速的渲染，但为此牺牲了对服装随着不同姿态产生的非刚性变形的拟合。3DGS-Avatar将变形分为非刚性变形和刚性变形两步来完成，同时通过一个能够考虑到光照效应和局部变形的小型MLP网络解码颜色，从而在渲染速度和渲染质量之间达到较好的平衡。 为了解决直接从3D空间学习高斯参数带来的计算困扰，一些方法尝试将问题空间从3维投影到2维，以降低问题的复杂度，同时便于利用已经相对完善的二维网络进行参数学习。 （我不确定GSMs属不属于这一类，GSMs也是通过生成shell map来参数化高斯的，并且用的也是“适合2维空间的”CNN模型，不过GSMs的作者并没有提到这一点，不过看起来GSMs应该归到生成一类） ASH提出首先通过一个变形网络生成一个与运动关联的模板网格，基于此预测和运动相关的纹理映射，生成的纹理映射通过位置阶码器和外观解码器为高斯提供参数，这样模型可以在纹理空间学习高斯的参数而不是在3D空间中直接学习。 类似的，Animatable Gaussians通过将标准空间当中的模板网格人体投影到人体正面和人体背面两个方向，从而在这两个2D空间中学习高斯参数。同时Animatable Gaussians提出利用主成分分析（PCA）将全新的姿态驱动信号投影到训练过的姿态空间中以获得针对新姿势生成的更好泛化性。 除了人体整体的重建和动画化，3DGS为人体头部的重建与动画化也带来了较大的进展，GaussianAvatars通过将FLAME网格和高斯泼溅结合来取得更好的渲染效果，高斯泼溅的主要用途是对FLAME网格无法精确描绘的细节或没有跟踪的元素进行补偿。初始化时FLAME网格上的每一个三角形都被放置一个高斯，并在训练过程中进行优化，同时为了在自适应密度控制中保持可控性，GaussianAvatars通过独特的继承机制确保每一个高斯都与FLAME网格中的一个三角形相关联，当对FLAME网格进行动画化时，每一个高斯也相应做出变形。 GaussianAvatars虽然取得了很好的重构效果和动画化，但是训练时并没有和照明信息解耦，Relightable Gaussian Codec Avatars（这篇工作感觉涉及到比较晦涩的关于球谐函数和球谐光照的知识，我感觉我一下子搞不定:(）。 Gaussian Head Avatar指出直接使用FLAME网格和LBS进行面部变形这种相对简单的线性操作很难表征精细的面部表情，相对的，Gaussian Head Avatar提出使用一个MLP网络直接通过输入表情相关参数来预测高斯在从中性表情到目标表情之间的位移来实现高达2K分辨率的头部图像渲染。 在人体生成方面， Gaussian Shell Maps(GSMs)则通过壳式结构结合了CNN生成模型和3D高斯泼溅，一系列壳式网格基于SMPL模型适当的膨胀或收缩，CNN生成模型为这些壳式网格生成纹理映射，这些纹理信息进一步确定了锚定到网格上的高斯的属性。这种壳式表征可以更好的表示SMPL模型中不包含的服装、头发等特征。同时高斯泼溅的显式表示和壳式结构层次性的表征为编辑人体提供了很大的便利，可以很方便的交换生成模型之间不同壳的属性，实现为人体模型更换发型和服装的需求。 Week9 Task Achievements 复现3dgs 目前已经跑通，在进行code review，因为我本身pytorch基础很差，所以得边看边学 generative model 学习transformer架构 few-shot reconstruction 综述 补齐另外两篇综述中 单词向量空间应该是是最直接，最古早的文本编码思想了 基本想法是给定一个文本，用一个向量表示该文本的“语义”，向量的每一维对应一个单词，其数值为该单词在该文本中出现的频数或权值 基本假设是文本中所有单词的出现情况表示了文本的语义内容 我们的基本空间是全体文本和全体文本中的所有单词，它们可以共同组成矩阵 最早常用的权值叫 单词频率-逆文本频率 其中单词频率指这个单词在目标文本中的频率，即 逆文本频率指的是这个单词在全部文本的多少篇文本中出现过的倒数取log 即这个单词越是只在这个文本中出现，就越能代表这个文本，自然重要度也就越高 乘起来就是了 度量两个文本的相似度可以用余弦 word embedding如果我们有10000个单词，我们可能会想用一个长度10000的向量来表示单词，只要是哪个单词对应的编号就位1，其他为全0 但是这样我们无法得到各个单词之间的相关性，我们希望能有一种无监督的方法，自然地帮助我们找到单词之间的关系 两种很棒的无监督方式是 聚类式 生成对抗式 word embedding更类似于后者 我们可以训练一个函数，这个函数用一个中心单词预测周边单词出现的概率 这个结构就好像： 输入是one-hot编码的单词，一个神经网络将one-hot单词编码到隐藏维度，隐藏维度接上softmax就是每个单词出现在下一个的概率 因为one-hot就是只有一个维度为1的向量，所以相当于选出了隐藏层权重矩阵的一行，也就是隐藏层的权重矩阵就是我们的wordvec单词表了！假设我们有十亿个单词，隐藏层的维度是300，我们就相当于将十亿维的one-hot表示压缩成了300词向量表示，而且还获得了语义信息。 position embeddingSparse reconstruction (Few-shot) &amp; 3DGSEncoder-Decoder style感觉主要利用Decoder提供的先验知识进行单图重建 一个点云decoder预测basic point cloud，一个triplane decoder预测高斯属性 Predicting Supervise Information感觉主要利用depth model提供的深度先验知识 Generative &amp; GAN style主要利用生成模型来“想象”这个输入在其他视角下是什么样子的，从而实现数据增量 Week 10 Task Achievements 复现3dgs 目前已经跑通，在进行code review，因为我本身pytorch基础很差，所以得边看边学 generative model 学习transformer架构 few-shot reconstruction review cvpr 2020 best paper 综述 整理综述，列出重要方法 Gaussian Shadow Casting for Neural Characters这是我目前看得比较莫名奇妙的文章,这篇文章首先把训练视频经过NeRF得到一张密度分布图，将密度分布图转换成人体高斯集合，并提出一种针对高斯集合的光线追踪法，基于此计算人体的阴影 我不能理解的就是为啥他非要通过nerf输出的密度分布图来重建高斯图呢？用smpl模型初始化然后通过学习一个pose，调整好pose以后将smpl模型转换成高斯不是更爽么，还是因为那个nerf模型能够顺便帮他把法线和反照率预测出来而原本的高斯方法不行所以他才一定要用nerf呢？ cvpr 2020 best paper：Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild这篇工作将“对称性”这个先验用得很妙 重建一个物体，需要深度和反照率， 这篇工作提出了一个pipeline，首先判断一张照片中，有哪些像素可能是3D空间中的对称关系，而这些有对称关系的像素，他们的反照率和深度信息应当是相近的，而非对称像素不受这个约束，于是损失就成为了： 其中和是将图像翻转分别预测的对称置信度，分别是翻转后学习构造的图像，损失函数会基于置信度要求和尽可能相近。 1232 4 0 1 1 11 1 1 0 Week 11这周主要是进一步了解Encoder-Decoder style的泛化性工作，我重点选择了 AGG: Amortized Generative 3D Gaussians for Single Image to 3D和Triplane Meets Gaussian Splatting: Fast and Generalizable Single-View 3D Reconstruction with Transformers这两篇文章 两种方法都使用了混合式的中间表征来对物体的形状和纹理分别表示和重建，triplaneMeetsGaussian额外引入了triplane的隐式表示来增强泛化性，针对triplane再提供一层decoder预测高斯属性，避免直接使用decoder预测高斯属性时导致的问题。 两篇文章都使用transformer进行encoder和decoder的设计，我在想encoder和decoder的训练过程是否有可能改进 文本监督 文本+图像 one-shot 调研风险 MAMBA 目前还没有看到 mamba的引入 效果堪忧 Week 12这周主要在进行综述文章的翻译和补充工作，我之前还没有写过英文论文，因此进度比之前用中文缓了一些，争取周三完成我的部分 关于文本监督引入图像重建的可能性调研上我目前还没有看到关于文本和图像作为联合输入进行重建的文章 学长说这可能是一个应用点，但是最大的问题在于数据集上，很多时候可能需要使用CLIP来标注图片，这样数据的质量就堪忧了 MAMBA的引入和学长进行了交流，学长说他已经就mamba替换transformer做过尝试，发现训练效率有比较大的下降，风险比较大 Week 13按照身体部位来给人体重建的文章分类未免也太蠢了，我打算试试按照技术分类，这样显得更聪明，但也有风险，作为一个菜鸟，我很担心我对这些技术的理解有偏差呢 Research pose-dependent non-rigid deformation novel pose animation fast training high frame rate real-time rendering(&gt;60FPS) monocular input Super-resolution HuGS Yes Yes No No No No *GPS-Gaussian - (No need) No - (Don’t need per-object optimization) Yes No?(虽然是360度拍了照片，但是好像只选了其中相邻的两张？) Yes HUGS No Yes Yes Yes Yes No GaussianAvatar Yes Yes Yes *0.5-6h single 3090 Yes Yes No GauHuman No No Yes Yes Yes No 3DGS-Avatar Yes Yes Yes No Yes No ASH Yes？（“motion-aware appearances” ） Yes 作者没说,我来训一遍 No Yes No Animatable Guassian Yes Yes No No No No *GPS-Gaussian等不使用SMPL模型的方法或许不能在此之列，因为他们行事不必受到SMPL模型的限制 未来可能的方向： 引入关于服装的物理先验知识来辅助完成服装被动画化时的变形 Week 14泛化性生成泛化性网络 2d视频-&gt;6d xyz+t 聚焦泛化性 （gaussian，带有生成性质的不是重点） 同时用服务器复现代码，形成统一认识 泛化性方向gaussian可能没有效果好，泛化性下大家不看时间看精度 dynamic 先不用看，先看泛化性 nerf 4d泛化复现 泛化性高斯+综述 ppt记录 新文章 复现开源文章 任务 进展 泛化性的复现 复现MVSplat 动画化的学习 目前主要的任务我目前聚焦泛化性，主要对MVSplat和pixelSplat进行复现 而这整体的pipeline是相似的，MVSplat使用Multi-view transformer获得基于单目视频上下文相关的feature，通过cost volume存储监督信息，并查询，最后通过Unet获得高斯元的具体参数，这里方法的最大特点是十分依赖初始化，由于gaussian splatting 中的clone和purne过程不是直接可微的，所以往往初始化后点的数量是固定的，实际上很难出现巨大的改变。 +放出来结果 Week 18MonoNerf 论文 目的 Attention is all you need 了解transformer架构 Self-Calibrating 4D Novel View Synthesis from Monocular Videos Using Gaussian Splatting 与目标工作相近 Diffusion4D: Fast Spatial-temporal Consistent 4D Generation via Video Diffusion Models 4d生成 3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting 这里面Non-rigid Module有些没看懂，得问一问 A taxonomy and evaluation of dense two-frame stereo correspondence algorithms 了解cost volume流程 复现结果 明确量化结果 pipeline![Screenshot 2024-06-30 at 17.29.33](/Users/lyl/Library/Application Support/typora-user-images/Screenshot 2024-06-30 at 17.29.33.png) 迁移计划如何使用光流对高斯进行监督 泛化性（学长的意思是不再按照mvsplat的流程来做，主要原因是使用的人太多，并且渲染速度（训练速度？）比较慢） ![Screenshot 2024-06-30 at 17.41.18](/Users/lyl/Library/Application Support/typora-user-images/Screenshot 2024-06-30 at 17.41.18.png) 目前此领域相近的文章Self-Calibrating 4D Novel View Synthesis from Monocular Videos Using Gaussian Splatting ![Screenshot 2024-06-30 at 20.38.46](/Users/lyl/Library/Application Support/typora-user-images/Screenshot 2024-06-30 at 20.38.46.png) 代码 暑期week1 date paper code 7.12 Self-Calibrating 4D Novel View Synthesis from Monocular Videos Using Gaussian Splatting 7.13 再check一遍 按motivation分类 小技术 trick写在中文里面标红 要写得详细一点（一到两句话） 列出比较表格 github列表 123456789101112131415161718192021222324252627\\begin{table*}[ht]\\centering\\begin{tabular}{|m{3cm}|m{4cm}|m{3cm}|m{4cm}|m{5cm}|m{7cm}|m{3cm}|}\\hline\\textbf{Research} &amp; \\textbf{pose-dependent non-rigid deformation} &amp; \\textbf{novel pose animation} &amp; \\textbf{fast training} &amp; \\textbf{high frame rate real-time rendering(&gt;60FPS)} &amp; \\textbf{monocular input} &amp; \\textbf{Super-resolution} \\\\\\hlineHuGS &amp; Yes &amp; Yes &amp; No &amp; No &amp; No &amp; No \\\\\\hline\\textit{GPS-Gaussian} &amp; - (No need) &amp; No &amp; - (Don't need per-object optimization) &amp; Yes &amp; No? &amp; Yes \\\\\\hlineHUGS &amp; No &amp; Yes &amp; Yes &amp; Yes &amp; Yes &amp; No \\\\\\hlineGaussianAvatar &amp; Yes &amp; Yes &amp; Yes *0.5-6h single 3090 &amp; Yes &amp; Yes &amp; No \\\\\\hlineGauHuman &amp; No &amp; No &amp; Yes &amp; Yes &amp; Yes &amp; No \\\\\\hline3DGS-Avatar &amp; Yes &amp; Yes &amp; Yes &amp; No &amp; Yes &amp; No \\\\\\hlineASH &amp; ?motion-aware appearances &amp; Yes &amp; ? &amp; No &amp; Yes &amp; No \\\\\\hlineAnimatable &amp; Yes &amp; Yes &amp; No &amp; No &amp; &amp; \\\\\\hline\\end{tabular}\\caption{Research Comparison}\\end{table*}\\lipsum[1-2] % 这是用来填充两栏内容的示例文本，请根据需要删除或替换 暑期 Week1 date task detail Survey https://github.com/qqqqqqy0227/awesome-3DGS Code resnet Code Mononerf 准备和学长一起搭建baseline Summer Week 2对self-distilation的探索ablation experiement on attention(resnet50) 红色的线是有attention层，蓝色的线是去掉了attention，两条线几乎重合，我觉得至少在resnet50上，attention层的效果似乎不显著 小模型的另一种实现方式 Model QuantizationPaper:AdaRound这篇文章从rounding后模型误差的二阶泰勒展开式出发，在做了一些让我有些看不明白的假设后，得出了非常直观的结论： 假设一：gw=0，因为假定模型已经是收敛的，因此一级梯度确实应该是趋于0 所以问题退化成求公式(4)后边部分期望的最小值 展开海森矩阵 可以写成如下形式 假设二： Loss对zi偏导后，结果不会在包含zj（我感觉就像是传播到zi的损失不会受zj影响），这一步好像也能理解，因为一些常见的层比如卷积层、全连接层，确实zi zj之间一般是通过加减之类的运算传递到结果中去的，导一次就解耦了，但是如果算上其他层的我就有些不理解了，比如： 经过这样的假设，就成了对角矩阵 接下来代入式13 假设三： 假设上面的对角矩阵里面的每一个对角线值，也就是L对z的二阶偏导，都是固定的常数（这个操作已经看不懂了） 最后得到了非常符合直觉的式20——要让式13最小，（经过一系列假设后，）等价于让第l层的输入xl-1和round带来的权重变化之积最小，这个做法很类似resnet要求第l层除了能拟合f(x)，还要能拟合x本身 （这个结果直觉到我在想他到底是推导得到了这个结论，还是从这个结论出发，反补出了一段证明） 有疑惑的一个操作： 假设三的负面影响实在是太大，为了平衡这种影响，他们加了一个激活函数fa，我不理解为什么一个激活函数能平衡掉这种影响。 However, this does not account for the quantization error introduced due to the previous layers. In order to avoid the accumulation of quantization error for deeper networks as well as to account for the activation function, we use the following asymmetric reconstruction formulation,where xˆ is the layer’s input with all preceding layers quantized and fa is the activation function. Summer Week 3self-distillation的后续(因为实在没想法决定骚扰一下作者！ 从回复来看Attention确实应该就是起一个补足adaption layer的作用，我想有它没它似乎影响都不大，也许有能带来一些超参数化的福利吧 了解Transformer之前一直自以为已经了解transformer了，看了一下code发现还差得远，所以开始先从Attention is All You Need的实现开始过一遍Transformer的实现，目前才刚刚实现完Multi-head Attention:( Attention 的思想机理是希望求出一个权重，这个权重昭示着一个序列中的某个元素对于序列中另一个元素的“注意力”，对于每两个元素都做这件事情，我们就得到一个权重矩阵，其中表示元素i对于元素j注意力以AAYN中的实现为例，作为一个翻译模型，模型将输入序列翻译到，即那么输出由输入对于整个序列元素的注意力和序列元素本身的Embedding Value决定，也就是 (嘶真的是这样么，那比如中文翻日语可怎么办啊，两种语言文法不一样，对应的可能是日语中的宾语，但是是中文中的谓语，或许是模型在一层又一层的Attention中自己把这种东西学到了？我感觉我这里还只是理解了一部分encoder，还要看看decoder怎么工作的呢)而像GPT-2这样的模型，其目的在于文字接龙，采用的是Transformer decoder架构，因此它其实是一个递归函数，递归进行直到模型输出一个约定的EOF字符停止或者超出上下文限制导致截断输出推导自前i个元素和他们的注意力，也即上面描述只考虑了Attention 层，实际的实现还加了一些其他的层呢，我慢慢来好咯 Attention Mechanism朴素的Attention我们定义一种最简单的QKV配对机制，简单到QKV就是本身那么我们可以得到权重矩阵（默认元素都是列分布，转置后为行分布）这种表示最大的问题是权重矩阵是不可以被反向传播调整的，如果Embedding Value也被detach的话那整个Attention层就不可训练了，所谓的注意力最后完全仰赖Embedding本身，模型自己不能对Embbeding增加自己的理解，这是不能产生好效果的 QKV参数化为此，我们需要将QKV参数化，方法非常简单，我们把分别乘上一个(embed_length, hid_dim)矩阵Q、K、V就可以了，这样模型可以在反向传播的时候自己学习怎么从embedding value中抽取Query、Key和Value，我觉得可能Q矩阵用来抽这个词希望注意什么样类型的词，K矩阵用来抽取这个词是什么类型的词，V矩阵用于反映这个词（其实我感觉V矩阵好像不是那么重要诶，非要不可么…哦！q和v的维度可能和embed本身不一致，所以至少需要V做一下转换，然后可能还有点超参数化的福利吧），而且这个本身也很容易实现，一个权重矩阵就是个linear层，无非就是分别过了下三个linear 还有一个讨嫌的问题是——为啥要用Multi-Head？首先我们要明确Single-Head和Multi-Head的差别到底在哪里，首先我们假设一个single head，它的QKV矩阵对应的隐层维度为hidden_dim，记作h, 输入维度为embed_dim，记作e，那么一层attention做的事情是这样的，其中QKV大小都是(h, e)，X的大小是(e, seq_len)，Q’K’V’的大小为(h, seq_len):现在我们将它分成m个head，那么每个head的QKV隐层维度为h/m，一层Attention做的事情是这样的$$Q’1 = Q_1X + b{q1},\\ Q’2 = Q_2X + b{q2},\\ …\\ Q’m = Q_nX + b{qn}K’1 = K_1X + b{k1},\\ K’2 = K_2X + b{k2},\\ …\\ K’m = K_nX + b{kn}V’1 = V_1X + b{v1},\\ V’2 = V_2X + b{q2},\\ …\\ V’m = V_nX + b{vn}W_1 = Q’^T_1K’_1,\\ W_2 = Q’^T_2K’_2,\\ …\\ W_m = Q’^T_mK’_mX’^T= W_1V_1^T\\ concat\\ W_2V_2^T\\ concat\\ …\\ W_nV_m^T$$我们会发现其实二者的前三步没有区别，将multi head的每个QKV concat起来就会得到single head的计算结果真正的区别是在计算权重时产生的，single head使用了一整个Q’和一整个K’生成了一个(seq_len, seq_len)大小的权重矩阵，而multi head将Q’和K’沿着hidden_dim分别砍成了m份，每份组合起来分别生成了m个(seq_len, seq_len)大小的权重矩阵，最后分别和(h/m, seq_len)的分别生成(seq_len, h/m)大小的output，全部沿着维度1 concat起来就成了(seq_len, h)的总体output，然后就可以拿着这个进入下一层attention，如此往复…所以最大的差别在于multi-head可以针对V’的每m个维度，分别学习一个独立的权重矩阵，为什么要这么多独立的权重矩阵？？？这个教程给出的解释是，我们希望模型从不同的角度去抽取W，比如对于”This restaurant is not too terrible”这句话，not、too这样的词语对于terrible是一种意义增强或者取反的关系，而restaurant和terrible是一种被形容和形容的关系，这种关系是完全不同的，对于这种关系上的本质区别，我们如果只有一个权重矩阵，很难衡量这三个词对于terrible孰轻孰重，但是如果我们有两个权重矩阵，一个衡量词义强度关系，一个衡量形容与被形容关系，V’也被分成两个部分，前一半维度用来描述词义强度，后一半维度用来描述词性强度，相应的K’Q’也被这样拆分，那么问题就能解决了，当然这只是一个简单的例子，模型真正学到的关系人类是很难看懂，但至少我们给了模型机会来从多个不同的角度形成不同的注意力。 另一种小模型可能的实现方式：Kans带来的参数压缩先试着将目前流行的小模型方案都过一过 这个部分才刚刚开始看，我需要先能弄懂Kolmogorov-Arnold表示定理才行… Summer Week4TransformerMoE在实现Feed-forward的时候知乎推给我“为什么attention机制总是被魔改，FFN却几乎不变？评论区有人反驳MoE就是改变Feed-forward的典范，正好我在思考如何通过简单的门控更改transformer的推理过程，因此对MoE做了一点简单的了解，看了一份sample code，但是还没有看论文，需要了解MoE为什么topk选择多个专家能这么成功” 实现一个MoE Xavier InitializationJust one small problem: Why am I wanting the input variance equal to output variance? You may find answer here: https://zhuanlan.zhihu.com/p/428411878 xavier initialization self-distillation + transformer将self dist迁移到transformer可能有这些问题： scala net占的参数量也太大了，比如我要为每一个encoder layer补齐scala net，除了补齐encoder，每个layer还要我补齐decoder，那也太巨量了 encoder output在AAYN这篇论文里很重要，每个decoder层都要用它，是很重要的输出，那我是直接让每个encoder layer对齐这个encoder output（那这样就省了补齐decoder的巨大开销了），还是非要他们对齐最后的decoder … Naive thoughts: Cycle attention感觉总是ship别人的想法然后做迁移不太好，所以试着自己提出一些想法 想法根基：最近阅读了这样一篇文章Hallucination is Inevitable: An Innate Limitation of Large Language Models，文章的基本想法是，由于大模型本身能提供的计算复杂度和用户提出的问题被解决所需要的复杂度不一致（如用户提出的问题是NP难问题，但是大模型只是尝试用多项式复杂度的计算得出结果 我的理解可能不准确，这篇文章我才读到3.3节，需要继续读完）因此光从复杂度的角度来看，大模型就不可能得出这个问题的解 文章提了一些解决办法，比如更多的数据，大模型就可以进行查找而非计算，让解决问题本身需要的复杂度降低 还有早期流行的chain of thoughts，光从token数量来说，c-of-t就是增加了输出长度，而每输出一个token模型都需要计算，因此从复杂度的角度来看，这也是一种对复杂度的补齐 multi-agent让多个智能体相互协作，也付出了更多的计算代价。 那么可不可以直接让模型补齐这个推理复杂度呢？ 我想设计这样一个模型 在推理时循环利用单个参数较大的A层，中间输出额外通过一个confident模块，这个模块进行简单的门控，决定模型当前有多大的信心可以输出结果，如果模型信心不足，就带着经过一定modify的latent再过一次A层，再进行判断，为了确保模型不会卡死自己，可能还需要一个罚时函数。 但是这个原始的想法可能有很多荒谬的问题比如如果设A层是函数f，而confident带来的扰动又不足，最后可能就成了f(f(f(x)))…，往往会把模型导向一个不动点或者朝着单个方向爆炸 再比如对于f(f(f(f(x))))这样的操作，假设A层就是一个线性层，那么输出就是WWWWWx…这样最后如何更新损失呢？是每次过A都造成一次更新还是只更新一次呢？ 再比如如果一个batch一个batch的training，每个batch的样本confident值都不一样，那有一些样本就要正式输出了，但是还有的样本需要继续过A，也会带来问题… 还需要继续思考…可能有一些实现可以参考，比如DiT模型将transformer应用在diffuse过程里，并在推理过程中不停地复用DiT（只是噪声程度在变），但是这个模型不需要自己决定是否要继续denoise，而且每次denoise都能产生一个可以直接反向传播的损失，所以参考价值可能也不是那么大… KA Algorithm推进比较慢，我需要先把丢掉的代数理论捡起来… 群集合A上满足封闭性，结合律，单位元和逆元素的数学结构 阿贝尔群 交换群满足交换律的群，还不如叫交换群，讨厌这些用人名命名的东西 域在一个集合上有两种运算 : 这个运算在上满足一个交换群，并且我们定义他的单位元为 :这个运算在上满足一个交换群 两个运算之间有交换律Misplaced &a \\times (b+c)=a\\times b + a \\times c \\ &amp;&amp; \\ (b + c) \\times a = a \\times b + a \\times c （令我们可以很快推出来） 那么构成了一个域 域有一些性质还没有弄明白，比如：域F中的所有非零元素的集合（一般记作F×）是一个关于乘法的阿贝尔群。F×的每个有限子群都是循环群。 域的扩张与闭包希尔伯特第十三问：我们能找到高维多项式方程的根式解吗？答：不能，从五次多项式方程开始，总是存在一个该次数的多项式方程，我们能找到它的一个解，而这个解不是根式形式 Proof 伽罗瓦理论阿贝尔-鲁菲尼定理五次及更高次的多项式方程没有一般的求根公式 域扩张理论Summer Week 5Transfomer自己的transformer搓好了，但是在自己的电脑上跑了两天一个epoach还没跑完（希望后面能移到服务器上 要让服务器能访问huggingface真是一件头疼的事… KA Algorithm推进比较慢，我需要先把丢掉的代数理论捡起来… 群集合A上满足封闭性，结合律，单位元和逆元素的数学结构 阿贝尔群 交换群满足交换律的群，还不如叫交换群，讨厌这些用人名命名的东西 域在一个集合上有两种运算 : 这个运算在上满足一个交换群，并且我们定义他的单位元为 :这个运算在上满足一个交换群 两个运算之间有交换律Misplaced &a \\times (b+c)=a\\times b + a \\times c \\ &amp;&amp; \\ (b + c) \\times a = a \\times b + a \\times c （令我们可以很快推出来） 那么构成了一个域 域有一些性质还没有弄明白，比如：域F中的所有非零元素的集合（一般记作F×）是一个关于乘法的阿贝尔群。F×的每个有限子群都是循环群。 域的扩张与闭包希尔伯特第十三问：我们能找到高维多项式方程的根式解吗？答：不能，从五次多项式方程开始，总是存在一个该次数的多项式方程，我们能找到它的一个解，而这个解不是根式形式 Proof 伽罗瓦理论阿贝尔-鲁菲尼定理五次及更高次的多项式方程没有一般的求根公式 域扩张理论Summer Week6Cycled Attention根据之前的探索，现有的模型架构的复杂度是，其中Attention是，输出序列长度如果假设也为n的话就是 那么现有的模型应当不能拟合一个复杂度再之上的问题 所以我们不妨定义这样一个数据集，这个数据集是直接从这个一个函数计算出来的： 定义这样一个运算 定义如下函数： 接下来我们定义这样一个序列生成方式： 即第k+1个元素是前k个元素通过对前k个元素的每一种排列应用函数后取均值（最后可以再取个整）得到的 要计算这个元素我们要花费的复杂度是，其中是生成所有排列的开销，是函数的开销 recursive transformer recurrent transformer cot Week 1相似工作调研我重点关注了相关文章中的下面这些问题 这个工作在循环生成时复用了那部分参数？ 对于被复用的网络，在权重不变的情况下，什么东西影响了被复用网络的行为？ 循环生成的停止条件是什么？ 循环生成的中间产物是什么（也即每次被复用的网络收到的中间输入是什么）？ 工作 复用部分 中间产物 影响复用网络的方式 停止条件 我的想法 [1]SELF-REFINE: Iterative Refinement with Self-Feedback 整个LLM 人类语言 每次复用时，网络被告知对上一轮的输入做出评价，复用时，评价被用于引导新一轮的生成，从而实现refinement 模型自己对每轮生成的结果生成一个评价分数，达到阈值时即停止 这个工作的出发点是认为多次prompt要求模型改进自己的生成结果可以不断提高生成的效果，这是符合直觉的。这个工作的实现方式和我的想法有一些相似，但是主要区别在下面三点：1. 中间产物是人类语言，每次模型都要将信息丰富的latent投影到人类语言再进行refinement，可能浪费了很多信息2. 复用的是整个llm模型，而我希望复用几个特定的attention层3. 这篇工作对于“何时停止循环生成”好像有点避重就轻，只是说可以让模型自己生成一些指标，而我希望可以思考有没有在latent空间借助门控之类的手段来进行控制 [2]Recursive Transformer: A Novel Neural Architecture for Generalizable Mathematical Reasoning 整个Transformer 数学表达式 数学表达式会按照运算优先级被逐轮的简化，每次输入的表达式都有所不同 模型会在输出表达式时同时输出Continue或者stop token，代表目前是否还需要继续循环生成 这个工作的问题域是让LLM预测数学表达式结果这个工作的分析过程和我的想法十分相似，比如一个数学表达式3*4+2*2，对于一个两层的transformer，第一层很可能就生成12+4，第二层再生成16，但是有些表达式非常复杂，这个过程无法完全进行，因此导致Transformer不能正确预测结果这篇工作训练的方式也值得注意，对于数学表达式，构建一步步规约的数据集是相对容易的，因此所有的中间结果都可以得到直接强力的监督。这篇工作随后探索了这样一种可能：能够不提供中间结果的监督，只有最后的答案他们立刻就遇到了我同样遇到的问题：由于不同的问题需要的步数不同，会为batch化的训练带来问题同时如何保证全过程可微也需要仔细考虑在他们终于用一些不太优雅的办法解决这些问题后，他们发现这样的模型相对于有强监督的模型至少有10%的精确度差距，这可能是一个可怕的警示，沿着这样的思路训练的模型可能很难收敛到好的效果上。最后看了这篇文章真是羞愧难当，这不过是人家的一篇technical report就已经几乎把我目前的想法全部cover了，可见我目前的科研创新性还差得远。","tags":["ML"],"categories":["ML"]},{"title":"再习计算机组织结构","path":"/2024/03/06/再习计算机组织结构/","content":"用户程序系统级API操作系统指令集硬件系统高速缓存 Cache原理wiki cache可以被分为set和line，一个cache有多个set，每个set里有多个line，每个line对应一个内存block 直接相联 Direct-mapped cache可以看成每个set只有一个line的cache 每个内存块都注定要被映射到cache中一个确定的位置 一个地址被分为了tag，index，offset三个部分，index就注定了这个字节会被分到哪一个cache line，但是有很多字节会被映射到同一个cache line，这个时候就可以通过tag来区分 优点：查找速度很快，cache对应的index行上的tag是就命中，不是就没命中 缺点：替换策略太直接，一些特定的代码可能连续疯狂替换cache反而导致速度变慢 全相联模型 Associative mapping可以看成只有一个set，这个set包含所有line的cache 一个地址可能被分到任何一个line 一个地址被分为tag和offset，要判断命不命中，就得整个cache搜一遍，挨个看tag是不是一样，如果cache塞满了要用一些算法替换，比如LRU 优点：往往能比较好的捕捉时空局部性 缺点：经常做全表搜索然后发现没命中，比较搞心态 组相连模型 Set Associative mapping每个block都注定会映射到一个特定的set，但在set当中可以随机的放，如果一个set被塞满了，那么就根据一些策略替换某行 中庸之道，中和了二者的优点，也中和了缺点 倾斜相连cache Skewed-associative caches这种cache 的设计利用了哈希散列，比如二路组关联的cache，它的每个组的第一line被用来注定映射内存，即每一个内存都能有自己注定要映射到的line，但是它的第二line，被交给的一个hash函数，hash函数对内存地址进行散列，这样如果一个内存地址注定的地方发生冲突，它可以不着急，而是再进行一次散列，看看能不能找着位置 这里得挖个坑以后来填了，cache，光是wiki上的内容就超级多了，现代架构cache、读写控制、多级控制、与TLB结合… 工艺模型晶体管Notion Collection “如果哪天编译技术发展到程序员只要写串行程序， 计算机能够自动并行化并在成千上万个处理器中运行该程序，那这座桥的评分可以得 “特优”。” 并行化技术可能是一个研究方向 “RISC 指令系统的最本质特征是通过 load&#x2F;store 结构简化了指令间关系，即所有运算指令都是对 寄存器运算，所有访存都通过专用的访存指令（load&#x2F;store）进行。” “页式虚拟存储管理将各进程的虚拟内存空间划分成若干长度相同的页，将虚拟地址和物理地 址的对应关系组织为页表，并通过硬件来实现快速的地址转换。现代通用处理器的存储管理单元 都基于页式虚拟管理，并通过 TLB 进行地址转换加速。” 个人认为，页式存储最大的意义在于向程序隐藏了它的内存地址空间七零八落和可能相当受限的事实，提供了看起来连续统一并且挺大的的虚拟空间，再在硬件级别进行真是地址的映射，至于虚拟内存，缺页中断，那又是请求分页机制所发明的技术了，不过相对于分段机制而言，分页机制主要通过统一大小并且比较小的页解决外部碎片 那为什么还要段页式存储呢？因为页表占用的空间太大了，单张页表也许看起来好，但是每个程序都要有自己的页表，就会产生巨量的空间消耗，同时分段可以提供一些共享和保护机制： A big challenge with single level paging is that if the logical address space is large, then the page table may take up a lot of space in main memory. For instance, consider that logical address is 32 bit and each page is 4 KB, the number of pages will be 2^20 pages. The page table without additional bits will be of the size 20 bits * 220 or 2.5 MB. Since each process has its own page table, a lot of memory will be consumed when single level paging is used. For a system with 64-bit logical address even a page table of single process will not fit in main memory. For a process with a large logical address space, a lot of its page table entries are invalid as a lot of the logical address space goes unused. 我们可以将程序分成四个段，也就是我们一般常说的代码段，数据段，栈区，堆区： 这样我们既可以通过操作系统分配合适大小的段来控制程序分配到的内存，控制的页表的大小，同时还能利用段表的大小与偏移量的检查机制来避免各个区之间相互访问，达到保护程序的目的（比如实现可读可写则不可执行的保护限制） i386 采用二级页表结构，寻址如下图（图片没有体现权限控制的部分）","tags":["计组"],"categories":["系统方向"]},{"title":"凤凰架构笔记","path":"/2023/11/19/凤凰架构笔记/","content":"远程调用 RPC REST 事务处理 事务处理的意义是为了保证系统中所有的数据都是符合期望的 本地事务隔离级别（这个部分看到了太多不同的说法） 写锁：持有写锁的才能写入，其他事务不能再加锁 读锁：不允许其他事务加写锁 范围锁：对于某个范围加锁，这个范围内不能再更改、删除和更新 可串行化：每次读写都加上读锁、写锁和范围锁 可重复读：不加范围锁，所以别的事务虽然不能更改已有的数据，但是可以插入新的数据，导致幻读 读已提交：一旦读操作结束就释放读锁，于是其他事务可以加写锁修改数据，这时候再去读就会发现数据变咯，也就是不可重复读 读未提交： 追求一致性的全局事务单个服务使用多个数据源 XA 准备阶段：协调者询问事务所有参与者（比如不同的数据库）是否准备好提交，准备好的回复一条Prepared 提交阶段：如果所有参与者都准备好了，协调者自己先commit一次，然后向参与者发送commit指令，如果出现了问题，自己先Abort然后发送Abort指令 问题： 协调者寄了，整个就寄了 性能问题，整个过程要持续到参与集群最慢的那个做完 一致性风险：宕机如果不可恢复，那么无法实现一致性，同时在提交阶段，如果协调者已经在日志里写了commit记录，但是网络却断了，指令没有发出去，就会产生不一致的情况 三段式：添加一个让参与者们自检完成事务的可能性，如果自检都通过那么成功的概率大大提高，大家也就不用在准备阶段瞎忙活了 共享事务多个服务使用单个数据源 这往往是一个伪需求 之所以强调理论可行，是因为该方案是与实际生产系统中的压力方向相悖的，一个服务集 群里数据库才是压力最大而又最不容易伸缩拓展的重灾区，所以现实中只有类似ProxySQL 、MaxScale 这样用于对多个数据库实例做负载均衡的数据库代理，而几乎没有反过来代理一个数据库为多个应用提供事务协调的交易服务代理。 这也是说它更有可能是个伪需求的原因，如果你有充足理由让多个微服务去共享数据库， 就必须找到更加站得住脚的理由来向团队解释拆分微服务的目的是什么才行。 除了使用一个代理服务器，还可以用消息队列，多个服务向一个消息队列里添加消息，由消费者来统一处理，但是这仍然与系统抗压设计向悖 分布式事务多个服务同时访问多个数据源 CAP原理在涉及共享数据问题时，Consistency、Availability和Partition Tolerance只能最多满足其二 首先，Patition Tolerance是不可能放弃的，你不能保证系统的任何一部分都是永远可靠的 于是就只剩下两种选择： AP-放弃一致性保可用性：这是目前大多数分布式系统的选择，A 通常是建设分布式的目 的，如果可用性随着节点数量增加反而降低的话，很多分布式系统可能就失去了存在的 价值 CP-放弃可用性保一致性：银行、证券等宁愿中断也不愿意出现不一致的系统，这类系统对一致性的要求很高 既然强一致性已经被AP放弃了，接下来就该讨论如何做到尽可能获得正确的结果，也就是追求弱一致性了 最终一致性如果数据一段时间没有被其他操作所修改，那么它最终会达到与强一致性过程相同的结果，面向最终一致性的算法常常被称作“乐观复制算法” 柔性事务满足ACID的事务被称作刚性事务，而追求最终一致性的事务被称作柔性事务 QUIC与0rtt（zero roundtrip time）0rtt的tls1.3tls1.3的核心思想是，如果客户端和服务端曾经有过tls通讯，那么下一次tls通讯时，两端之间就不用煞费苦心去沟通参数，客户端可以使用pre_shared_key来在第一下clientHello就开始发送加密的数据 我看不懂… tls1.3 透明多级分流系统客户端缓存域名解析传输链路CDN content distribution networkCDN与路由解析加入cdn后，当客户端请求一个域名时，将不再得到源站的ip，而是得到cdn服务器的cname，本地得到cname后，向提供该cname的权威dns查询dns，权威dns根据各种策略选择一个最合适的ip给客户端，这个ip将有能力中转客户端的请求到源站 CDN与内容分发cdn获取源站资源的过程被称为内容分发 主动分发Push：分发由源站主动发起，将内容从源站或者其他资源库推送到用户边 缘的各个 CDN 缓存节点上，这个过程对于源站并不是透明的。 被动回源Pull：当用户访问cdn的边缘服务器并且边缘服务器发现自己没有缓存源站的资源时，会实时从源站中获取 内容更新 对于“CDN 如何管理（更新）资源”这个问题，同样没有统一的标准可言，尽管在 HTTP 协 议中，关于缓存的 Header 定义中确实是有对 CDN 这类共享缓存的一些指引性参数，譬如 Cache-Control的 s-maxage，但是否要遵循，完全取决于 CDN 本身的实现策略。更令人 感到无奈的是，由于大多数网站的开发和运维人员并不十分了解 HTTP 缓存机制，所以导 致如果 CDN 完全照着 HTTP Headers 来控制缓存失效和更新，效果反而会相当的差，还可 能引发其他问题。因此，CDN 缓存的管理就不存在通用的准则。 现在，最常见的做法是超时被动失效与手工主动失效相结合。超时失效是指给予缓存资源 一定的生存期，超过了生存期就在下次请求时重新被动回源一次。而手工失效是指 CDN 服 务商一般会提供给程序调用来失效缓存的接口，在网站更新时，由持续集成的流水线自动 调用该接口来实现缓存更新，譬如“ icyfenix.cn ”就是依靠Travis-CI 的持续集成服务来 触发 CDN 失效和重新预热的。 CDN的作用 加速静态资源的访问：本职工作 安全防御：（在源站的ip没有泄露的基础上）CDN可以防御譬如DDoS攻击（很多针对静态资源的攻击都会打到cdn上） 协议升级：可以实现源站是http协议，对外开放强制https访问，类似的还有http1升级到3，IPv4升级到IPv6 状态缓存 修改资源：可以压缩一些静态资源加速访问，也可以修改CORS头提供跨域共享 访问控制：可以实现IP黑&#x2F;白名单功能 注入功能：可以在不修改源代码的前提下为源站注入各种功能 绕过长城防火墙：CDN隐藏VPS的真实ip，让防火墙只能封CDN ip，CDN监测到异常后，马上为用户换一个可以用的ip 负载均衡 load balancing 如何构建 和调度服务集群这事情，又必须对用户一侧保持足够的透明，即使请求背后是由一千台、 一万台机器来共同响应的，也绝非用户所关心的事情，用户需记住的只有一个域名地址而 已。调度后方的多台机器，以统一的接口对外提供服务，承担此职责的技术组件被称为“负 载均衡”（Load Balancing） 我们这里讨论负载均衡已不再包含CDN和DNS解析等的负载均衡 数据链路层负载均衡这一层的负载均衡的核心原理是修改数据帧中的MAC目标地址，首先所有的数据帧都指向负载均衡器，负载均衡器将请求帧的MAC地址指向真实地址 实现由于只修改了二层数据帧的MAC目标地址，因此IP等内容全部没有改变，这就要求负载均衡器和真实服务器的ip地址是一致的，这里一般采用让真实服务器集群的虚拟ip地址与负载均衡器的虚拟ip相同。 pros这种实现的一大好处是返回的数据不用再经过负载均衡器改为负载均衡器的ip，而是可以由真实服务器直接返回结果给客户端，一定程度上缓解负载均衡器带宽造成的性能瓶颈。 cons 需要感知应用层协议的负载均衡场景无法胜任 由于是在数据链路层工作，所以必须二层可达，要求负载均衡器必须和真实服务器在同一子网内，不能跨VLAN，不能跨子网","tags":["架构"],"categories":["架构"]},{"title":"interview for Baidu","path":"/2023/11/19/interview-for-Baidu/","content":"准备Android 八股初级 什么是ANR，如何避免ANR ANR是Application NotResponding，ANR出现可能的原因包括： 主线程被IO操作阻塞 主线程中存在耗时操作 主线程存在错误操作，比如Thread.sleep() 应用5s内为响应用户的输入事件（按键或触摸） BroadcastReceiver未在10秒内完成相关的处理 Service在特定的时间内无法处理完成 20秒 解决方式 不要把IO塞进主线程，使用AsyncTask 主线程中的耗时操作如访问网络、Socket通信、大量SQL查询、复杂计算放入子线程中 正确设置线程的优先级 使用Handler处理线程工作结果，而不是使用wait和sleep Activity的onCreate和onResume回调中尽量避免耗时的代码。 BroadcastReceiver中onReceive代码也要尽量减少耗时，建议使用IntentService处理。 Activity和Fragment的生命周期 stateDiagram Activity_onCreate() --> Fragment_onAttach() Fragment_onAttach() --> Fragment_onCreateView() Fragment_onCreateView() --> Fragment_onActivityCreate() Activity_onStart() --> Fragment_onStart() Activity_onResume() --> Fragment_onResume() Fragment_onPause() --> Activity_onPause() Fragment_onDestroyView() --> Fragment_onDestroy() Fragment_onDestroy() --> Fragment_onDetach() Fragment_onDetach() --> Activity_onDestroy() 手机切换横竖屏时生命周期的变化 如果没有设置configChanges，那么切屏会把各个生命周期全走一次（从onPause()开始到新Activity的onResume()） 为什么Android APP出现延迟？ APP 经常运行GC，而GC运行时APP无法运行android UI 往往16ms刷新一次，如果GC占用了时间，APP 只能跳过一些UI 帧，看起来就像UI出现了卡顿 主线程中运行耗时的任务 解决 在需要时再实例化对象，不要提前实例化对象，使用懒加载 减少使用封装类如Integer 使用ArrayMap和SparseArray 使用对象池避免内存 将主线程中的耗时任务移到子线程中 什么是Context？ Context提供了关于应用环境全局信息的接口。它允许获取以应用为特征的资源和类型，是一个统领一些资源（应用程序环境变量等）的上下文。就是说，它描述一个应用程序环境的信息（即上下文）； 主要的Context有两种： Application Context 一般建议使用Application Context，不要让生命周期比Activity长的组件持有Activity Context Activity Context AOP技术方案 AspectJ-我们在Spring课程上学到的方法 @Aspect @EnableApsectJProxy @PointCut(“exectution(* …方法)”) @Before&#x2F;After&#x2F;AfterReturned&#x2F;AfterThrow&#x2F;Around 真正意义的AOP，无需硬编码切面，可能存在重复织入、不织入的问题 APT 通过注解减少模板代码，对原工程具有侵入性 ASM 面向字节码编程的切面，一些场景需要硬编码 Javassit 有动态切片能力，上手快 动态代理 运行时扩展代理接口功能 APK打包过程 编译器将您的源代码转换成 DEX（Dalvik Executable) 文件（其中包括运行在 Android 设备上的字节码），将所有其他内容转换成已编译资源。 APK 打包器将 DEX 文件和已编译资源合并成单个 APK。不过，必须先签署 APK，才能将应用安装并部署到 Android 设备上。 APK 打包器使用调试或发布密钥库签署您的 APK： 如果您构建的是调试版本的应用（即专用于测试和分析的应用），打包器会使用调试密钥库签署您的应用。Android Studio 自动使用调试密钥库配置新项目。 如果您构建的是打算向外发布的发布版本应用，打包器会使用发布密钥库签署您的应用。要创建发布密钥库，请阅读在 Android Studio 中签署您的应用 在生成最终 APK 之前，打包器会使用 zipalign 工具对应用进行优化，减少其在设备上运行时的内存占用。 AsyncTask 轻量级的异步任务类，在线程池中执行后台任务，将执行进度和结果传递给主线程 生命周期 即使创建它的Actvity销毁，AsyncTask也会继续执行知道doInBackground执行完毕，如果没有调用cancel方法，他会调用onPostExecute，这时程序很可能会崩溃，因为它想回传结果的Actvity已经不存在了 同时由于AsyncTask作为一个非静态内部类持有了Activity的引用，如果AsyncTask还在执行，Activity就无法被释放，引起内存泄漏 结果丢失 如果Activity自己挂了，比如没有设置onChange的屏幕旋转，会导致AsyncTask将结果传给一个死掉的Activity从而丢失结果 并行与串行 随版本不同，最早直接并行，但是容易爆掉，后改成线程池，还是有问题，于是默认串行，可以用executeOnExecutor()来并行执行 AsyncTask原理 AsyncTask中有两个线程池（SerialExecutor和THREAD_POOL_EXECUTOR）和一个Handler（InternalHandler），其中线程池SerialExecutor用于任务的排队，而线程池THREAD_POOL_EXECUTOR用于真正地执行任务，InternalHandler用于将执行环境从线程池切换到主线程。 sHandler是一个静态的Handler对象，为了能够将执行环境切换到主线程，这就要求sHandler这个对象必须在主线程创建。由于静态成员会在加载类的时候进行初始化，因此这就变相要求AsyncTask的类必须在主线程中加载，否则同一个进程中的AsyncTask都将无法正常工作。 onSaveInstanceState()与onRestoreInstanceState() 首先他们都不属于生命周期方法，当应用遇到意外情况（内存不足、用户按Home时被调用）系统销毁Activity时调用，用户主动销毁时（如按返回键）不会调用 onSaveInstanceState适合保存临时性的状态，而持久性的状态应当放在onPause中保存 Android中进程的优先级 前台进程：正在与用户交互的Activity或是相应的Service，在内存不足时最晚被杀死 可见进程：处于onPause状态的Activity或者绑定在其上的Service，用户可以见，但是失去焦点用户不能交互 服务进程：使用startService方法启动的Service，用户不可见但是用户关心，比如浏览器下载进程，音乐播放器播放的音乐 后台进程：onStop的程序，比如后台的QQ 空进程：系统不会允许你的存在 Bundle传递的对象为什么要序列化？Serializable和Parcelable的区别？ Bundle传递数据时只支持基本数据类型，所以传递对象时需要序列化转换为可存储可传输的字节流，序列化后的对象可以在网络、IPC之间进行传输，也可以存到本地 Serializable java提供 Parcelabel Android提供：将一个完整的对象进行分解，而分解后的每一部分都是Intent所支持的数据类型 动画 View动画：作用对象是View，可用xml定义，建议xml实现，支持平移缩放旋转透明度四种变化 帧动画：通过AnimationDrawable实现，容易OOM 属性动画： 可作用于任何对象、可用xml定义 包括ObjectAnimator、ValueAnimator、AnimatorSet 时间插值器：根据时间的流逝决定属性的改变，预制匀速、加速、减速等插值器 类型估值器：根据当前属改变的百分比计算改变后的属性值，系统预置整型、浮点、色值等类型估值器 尽量避免使用帧动画，界面销毁时停止动画，开启硬件加速（将CPU的一部分工作分摊给GPU，使用GPU完成绘制工作） 补间动画：通过指定View的初末状态和变化方式，对View的内筒完成一系列的图形变换来实现动画效果。Alpha、Scale、Translate、Rotate，补间动画并没有真正改变View的位置，触摸区域并没有真的变化 属性动画原理 计算属性值 计算已完成动画分数：根据选用的Animator得到计算一个0-1的分数 计算插值（动画变化率）：当Animator计算得到动画分数后，它会调用当前设置的TimeInterpolator，去计算得到一个interpolated分数，在计算过程中，已完成动画百分比会被加入到新的插值计算中 计算属性值：当插值分数计算完成后，Animator会根据插值分数调用合适的TypeEvaluator去计算运动中的属性值 为目标对象的属性设置属性值，应用和刷新动画 插值器：根据时间流逝百分比来计算属性变化百分比 估值器：根据插值器的结果计算出属性到底变化了多少数值 属性动画如果设置为无限循环，必须在界面销毁时停止动画，否则引发内存泄漏 Context Activity和Service的Context和Application的Context是不一样的，Activity继承自ContextThemeWraper，其他的继承自ContextWrapper 每一个Context都是一个新的ContextImpl对象 getApplication只能在Activity和Service中用，如果要在别的地方用那么调用getApplicationContext() 创建对话框时不可以用ApplicationContext，应当用ActivityContext Context的数量等于Activity的个数+Service个数+1（Application） 不要给生命周期长于Activity的对象传Activity的Context，否则Activity无法被GC回收引发内存泄漏 Android各版本特性 Android处理Json 使用GSON包进行解析 解析成实体类 12Gson gson = new Gson();Student student = gson.fromJson(json1, Student.class); 解析成数组 12Gson gson = new Gson();int[] ages = gson.fromJson(json2, int[].class); 解析成List 12Gson gson = new Gson();List&lt;Student&gt; students = gson.fromJson(json3, newTypeToke&lt;List&lt;Student&gt;&gt;()&#123;&#125;.getType); Android解析Xml DOM解析 优点: 1.XML树在内存中完整存储,因此可以直接修改其数据结构. 2.可以通过该解析器随时访问XML树中的任何一个节点. 3.DOM解析器的API在使用上也相对比较简单. 缺点: 如果XML文档体积比较大时,将文档读入内存是非消耗系统资源的. SAX解析 优点: SAX 对内存的要求比较低,因为它让开发人员自己来决定所要处理的标签.特别是当开发人员只需要处理文档中包含的部分数据时,SAX 这种扩展能力得到了更好的体现. 缺点: 用SAX方式进行XML解析时,需要顺序执行,所以很难访问同一文档中的不同数据.此外,在基于该方式的解析编码程序也相对复杂. 使用场景: 对于含有数据量十分巨大,而又不用对文档的所有数据行遍历或者分析的时候,使用该方法十分有效.该方法不将整个文档读入内存,而只需读取到程序所需的文档标记处即可. Xmlpull解析 android SDK提供了xmlpullapi,xmlpull和sax类似,是基于流（stream）操作文件,后者根据节点事件回调开发者编写的处理程序.因为是基于流的处理,因此xmlpull和sax都比较节约内存资源,不会像dom那样要把所有节点以对象树的形式展现在内存中.xmpull比sax更简明,而且不需要扫描完整个流. Jar和aar的区别 Jar包里面只有代码，aar里面不光有代码还包括资源文件，比如 drawable 文件，xml资源文件。对于一些不常变动的 Android Library，我们可以直接引用 aar，加快编译速度。 Android为每个应用程序分配的内存大小是多少 老版一开始是16M，后面是24M，现在一般能给100-200M，可以用largeHeap申请更多内存 更新UI的方式 Activity.runOnUiThread(Runnable) View.post(Runnable),View.postDelay(Runnable,long)（在当前操作视图UI线程添加队列） Handler AsyncTask Rxjava（这是什么？） LiveData ContentProvider使用方法 进行跨进程通信，实现进程间的数据交互和共享。通过Context 中 getContentResolver() 获得实例，通过 Uri匹配进行数据的增删改查。ContentProvider使用表的形式来组织数据，无论数据的来源是什么，ConentProvider 都会认为是一种表，然后把数据组织成表格。 Thread、AsyncTask、IntentService的使用场景与特点 Thread独立于Activity，当Activity finish后，如果没有主动停止Thread或者run方法没有执行完，其回一直执行下去 AsyncTask封装了两个线程池和一个Handler，其必须在UI线程中创建，一个任务实例只允许执行一次，执行多次会抛出异常，一般用于网络请求或简单数据处理 IntentService处理异步请求，实现多线程，在onHandleIntent中处理耗时操作，多个耗时任务会依次执行，执行完毕自动结束 Merge和ViewStub的作用 Merge: 减少视图层级，可以删除多余的层级。 merge：merge是一个特殊的标签，用于在布局文件中优化视图层次结构。通常，在编写布局文件时，我们需要使用一些容器布局（如LinearLayout、RelativeLayout等）来组织和嵌套视图。然而，这些容器布局本身不会渲染任何视图，仅用于组织和定位子视图。这样一来，在视图层次结构中添加了额外的布局容器，会导致层次结构变得复杂，影响性能。 为了解决这个问题，可以使用merge标签，它会告诉布局解析器将其子视图直接添加到父视图中，而不会创建额外的布局容器。这样可以减少视图层次结构的深度，提高布局文件的加载和渲染效率。 ViewStub: 按需加载，减少内存使用量、加快渲染速度、不支持 merge 标签。 ViewStub：ViewStub是一个轻量级的视图占位符，用于在布局中延迟加载视图。它允许我们在布局文件中定义一个占位符视图，实际的视图内容可以在需要时进行延迟加载。 使用ViewStub可以在布局中预留一个位置，当需要显示相应的视图时，可以通过调用ViewStub.inflate()方法来动态加载视图并替换占位符。 Activity的startActivity和其他context的startActivity区别是什么？ (1)、从Activity中启动新的Activity时可以直接mContext.startActivity(intent)就好 12345678public class MainActivity extends Activity &#123; // ... public void startNewActivity() &#123; Intent intent = new Intent(MainActivity.this, NewActivity.class); startActivity(intent); &#125;&#125; (2)、如果从其他Context（Service，BroadCastReceiver）中启动Activity则必须给intent设置Flag: Intent.FLAG_ACTIVITY_NEW_TASK：将新Activity放入一个新的任务栈中。 Intent.FLAG_ACTIVITY_CLEAR_TASK：在启动新Activity之前清除任务栈中的所有Activity。 Intent.FLAG_ACTIVITY_CLEAR_TOP：如果目标Activity已经在任务栈中存在，则将其上方的Activity全部移除。 Intent.FLAG_ACTIVITY_SINGLE_TOP：如果目标Activity已经在栈顶，不会重新创建实例，而是调用其onNewIntent()方法。 123456789public class MyService extends Service &#123; // ... public void startNewActivity() &#123; Intent intent = new Intent(getApplicationContext(), NewActivity.class); intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK); startActivity(intent); &#125;&#125; 怎么在Service中创建Dialog对话框 1.在我们取得Dialog对象后，需给它设置类型，即： dialog.getWindow().setType(WindowManager.LayoutParams.TYPE_SYSTEM_ALERT) 2.在Manifest中加上权限: &lt;uses-permission android:name=&quot;android.permission.SYSTEM_ALERT_WINOW&quot; /&gt; Asset目录与res目录的区别 assets：不会在 R 文件中生成相应标记，存放到这里的资源在打包时会打包到程序安装包中。（通过 AssetManager 类访问这些文件） res：会在 R 文件中生成 id 标记，资源在打包时如果使用到则打包到安装包中，未用到不会打入安装包中。 res&#x2F;anim：存放动画资源。 res&#x2F;raw：和 asset 下文件一样，打包时直接打入程序安装包中（会映射到 R 文件中） 如何提升Activity启动速度？ 避免在OnCreate中执行耗时操作 渲染页面时，将View细分，放在AsyncTask中逐步显示，用Handler更好，这样用户可以看到界面的逐步渲染，而不是黑屏到界面突然出现，如果有动画更好 合理使用多线程 提高Adapter和AdapterView的效率 优化布局文件 Handler机制 message：消息 MessageQueue：消息队列，looper有一个消息队列，物理结构上是一个单链表，消息不断被加入和读取 Looper：消息循环器，负责关联线程以及消息的分发，在该线城下从MessageQueue获取Message获取Message，分发给Handler，调用Looper.loop()即启动Looper，并且不断执行next()方法，直到调用Looper.quit() 整个消息的循环流程还是比较清晰的，具体说来： 1、Handler通过sendMessage()发送消息Message到消息队列MessageQueue。 2、Looper通过loop()不断提取触发条件的Message，并将Message交给对应的target handler来处理。 3、target handler调用自身的handleMessage()方法来处理Message。 有很多事情都是通过C++完成的，MessageQueue是Java层和C++层沟通的桥梁，MessageQueue的核心功能实际上是使用Native C++完成的 Handler可能引发内存泄漏 Handler允许发送延时消息，在延时期间如果用户关闭了Activity，那么该Activity将会泄露，因为这个延迟消息持有Handler，而Handler又持有Activity 解决：将 Handler 定义成静态的内部类，在内部持有 Activity 的弱引用，并在Acitivity的onDestroy()中调用handler.removeCallbacksAndMessages(null)及时移除所有消息。 为什么我们可以直接在主线程里面使用Handler，而不需要创建Looper？ 在Android中，主线程（也称为UI线程）已经预先创建了一个Looper对象，并在应用启动时自动初始化了消息循环。因此，在主线程中可以直接使用Handler对象，而无需显式地创建Looper。 当应用启动时，Android系统会在主线程上自动调用Looper.prepareMainLooper()方法创建主线程的Looper对象，并将其存储在ThreadLocal中。随后，调用Looper.loop()方法启动主线程的消息循环。 （主线程的Looper不允许退出，如果退出，那么App就要挂） Handler 里藏着的 Callback 能干什么？Handler.Callback 有优先处理消息的权利 ，当一条消息被 Callback 处理并拦截（返回 true），那么 Handler 的 handleMessage(msg) 方法就不会被调用了；如果 Callback 处理了消息，但是并没有拦截，那么就意味着一个消息可以同时被 Callback 以及 Handler 处理。 创建 Message 实例的最佳方式为了节省开销，Android 给 Message 设计了回收机制，所以我们在使用的时候尽量复用 Message ，减少内存消耗： 通过 Message 的静态方法 Message.obtain()； 通过 Handler 的公有方法 handler.obtainMessage()。（本质上还是调用的Message.obtain()） 子线程里弹 Toast 的正确姿势 创建一个Runnable对象，通过主线程的Handler发送到主线程，由主线程来显示Toast 在子线程中先preperLoop并且启动，并且创建Handler，直接在子线程中显示 妙用Looper 子线程做耗时的操作，最后更新UI则通过主线程的Handler Post到主线程 利用 Looper 判断当前线程是否是主线程：有时候我们需要根据当前线程是主线程还是子线程来做一些不同的处理。通过 Looper 的 getMainLooper() 方法可以获取到主线程的 Looper 对象。我们可以利用这个特性来判断当前线程是否是主线程。 12345if (Looper.myLooper() == Looper.getMainLooper()) &#123; // 当前线程是主线程&#125; else &#123; // 当前线程是子线程&#125; 主线程的死循环一直运行是不是特别消耗CPU资源呢？并不是，这里就涉及到Linux pipe&#x2F;epoll机制，简单说就是在主线程的MessageQueue没有消息时，便阻塞在loop的queue.next()中的nativePollOnce()方法里，此时主线程会释放CPU资源进入休眠状态，直到下个消息到达或者有事务发生，通过往pipe管道写端写入数据来唤醒主线程工作。这里采用的epoll机制，是一种IO多路复用机制，可以同时监控多个描述符，当某个描述符就绪(读或写就绪)，则立刻通知相应程序进行读或写操作，本质是同步I&#x2F;O，即读写是阻塞的。所以说，主线程大多数时候都是处于休眠状态，并不会消耗大量CPU资源。 Handler postDelay这个延迟是怎么实现的？ Handler并不是等到延迟时间结束再将消息发送给Queue，而是直接发送，只不过附带了一个时间戳，MessageQueue会根据时间戳将消息进行排序，顺序唤醒 程序A能否接受到程序B的广播？ 能，使用全局的BroadCastRecevier能进行跨进程通信，但是注意它只能被动接收广播。此外，LocalBroadCastRecevier只限于本进程的广播间通信。 分页加载数据 分页加载就是一页一页加载数据，当滑动到底部、没有更多数据加载的时候，我们可以手动调用接口，重新刷新RecyclerView。 Gson解析json时javabean的定义规则 类的字段名需要与JSON中的键名保持一致。Gson通过反射来匹配字段名和键名进行数据绑定。如果字段名和键名不一致，可以使用注解@SerializedName(&quot;json_key&quot;)来显式指定JSON中的键名。 类需要提供一个无参构造函数。Gson在解析JSON时会使用无参构造函数来创建JavaBean对象，并通过反射设置字段的值。如果没有提供无参构造函数，可以自定义带参数的构造函数，但同时也需要提供无参构造函数。 类的字段需要为私有（private）访问权限，并提供公共的 getter 和 setter 方法。Gson通过调用getter和setter方法来获取和设置字段的值。 类可以使用注解@Expose来标记需要进行JSON序列化和反序列化的字段。如果没有使用@Expose注解，Gson默认会处理所有的字段。 123456789101112131415161718192021222324252627282930313233343536373839404142import com.google.gson.Gson;import com.google.gson.annotations.SerializedName;public class Person &#123; @SerializedName(&quot;name&quot;) private String name; @SerializedName(&quot;age&quot;) private int age; public Person() &#123; // 无参构造函数 &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; String json = &quot;&#123;\\&quot;name\\&quot;:\\&quot;John Doe\\&quot;,\\&quot;age\\&quot;:30,\\&quot;email\\&quot;:\\&quot;johndoe@example.com\\&quot;&#125;&quot;; Gson gson = new Gson(); Person person = gson.fromJson(json, Person.class); System.out.println(&quot;Name: &quot; + person.getName()); System.out.println(&quot;Age: &quot; + person.getAge()); &#125;&#125; json解析方式的两种区别？ SDK提供JsonObject和JsonArray的解析方式 Gson通过fromJson()实现对象的反序列化（即将json串转换为对象类型）通过toJson()实现对象的序列化 Gson提供通过javaBean的方式进行解析，总体上更加灵活多样 线程池 Android中线程池是通过配置ThreadPoolExecutor来实现的，最常见的四类线程池是FixedThreadPool、CacheThreadPool、SingleThreadPool和ScheduledThreadPool FixedThreadPool：固定线程池，线程数是固定的，所有线程都处于活动状态，也不会被回收，相应较快 CacheThreadPool：有很大的最大线程数，有空闲线程的概念，空闲时间过长会被线程池回收，适合处理大量执行时间短的任务 ScheduledThreadPool：核心线程数固定，非核心线程空闲时会被回收，适合于执行有固定周期的重复任务 SingleThreadPool：只有一个核心线程，不用考虑多线程的问题，适合需要顺序执行的任务 什么是内存泄漏？内存泄漏是如何产生的？如何查找和分析内存泄漏？ 内存泄漏（Memory Leak）指的是在程序中分配的内存空间无法被回收和释放，导致内存资源的浪费和耗尽。当内存泄漏发生时，程序会持续占用内存，导致系统性能下降，甚至可能导致应用崩溃。 内存泄漏发生的原因： 资源对象没有关闭或者没有正确关闭：资源型对象往往使用了一些缓冲，这种缓冲不仅存在JVM之内，还存在于JVM之外，因此简单的将他们的引用置为null并不能正确的释放资源，当资源对象不再使用时，应当调用它们提供的销毁接口 构造Adapter时，没有使用缓存的convertView：这个没有看懂 Bitmap对象不再使用时调用recycle()释放内存 Activity无法释放导致内存泄漏：如果一个对象的生命周期长于一个Activity，那么就不要将Activity的Context，改传Application的Context 注册没有取消造成内存泄漏：一些Android程序可能引用我们的Android程序，即使我们的Android程序已经结束，但是别的引用程序仍然还对我们的Android程序的某个对象的引用，这将导致无法进行垃圾回收，比如调用RegisterReceiver后未调用UnregisterReceiver 集合中对象没清理造成内存泄露：我们通常把一些对象的引用加入到了集合中，当我们不需要该对象时，并没有把它的引用从集合中清理掉，这样这个集合就会越来越大。如果这个集合是static的话，那情况就更严重了。 查找内存泄漏 使用MemoryProfiler，运行程序后如果收到内存泄漏报警则点击查看HeapDump MemoryAnalyzer Tool（MAT），运行程序然后退出，手动触发GC，然后使用adb shell dumpsys meminfo packagename -d命令查看退出界面后Objects下的Views和Activities数目是否为0，如果不是则通过Leakcanary检查可能存在内存泄露的地方，最后通过MAT分析，如此反复，改善满意为止。 对比hprof文件，检测出复杂情况下的内存泄露 类初始化的顺序 静态成员变量初始化 静态代码块 实例成员变量初始化 构造代码块 构造函数 1234567891011121314151617181920212223242526272829303132333435363738public class InitializationExample &#123; // 静态成员变量 private static int staticVariable = initializeStaticVariable(); // 静态代码块 static &#123; System.out.println(&quot;静态代码块被执行了&quot;); &#125; // 实例成员变量 private int instanceVariable = initializeInstanceVariable(); // 构造代码块 &#123; System.out.println(&quot;构造代码块被执行了&quot;); &#125; // 构造函数 public InitializationExample() &#123; System.out.println(&quot;构造函数被执行了&quot;); &#125; // 静态成员变量初始化方法 private static int initializeStaticVariable() &#123; System.out.println(&quot;静态成员变量初始化&quot;); return 10; &#125; // 实例成员变量初始化方法 private int initializeInstanceVariable() &#123; System.out.println(&quot;实例成员变量初始化&quot;); return 20; &#125; public static void main(String[] args) &#123; InitializationExample example = new InitializationExample(); &#125;&#125; JSON的结构？ json是一种轻量级的数据交换格式， json简单说就是对象和数组，所以这两种结构就是对象和数组两种结构，通过这两种结构可以表示各种复杂的结构 1、对象：对象表示为“{}”扩起来的内容，数据结构为 {key：value,key：value,…}的键值对的结构，在面向对象的语言中，key为对象的属性，value为对应的属性值，所以很容易理解，取值方法为 对象.key 获取属性值，这个属性值的类型可以是 数字、字符串、数组、对象几种。 2、数组：数组在json中是中括号“[]”扩起来的内容，数据结构为 [“java”,”javascript”,”vb”,…]，取值方式和所有语言中一样，使用索引获取，字段值的类型可以是 数字、字符串、数组、对象几种。 经过对象、数组2种结构就可以组合成复杂的数据结构了。 Android为什么引入parcelabel？ 在Android开发中，我们经常需要在不同组件（如Activity、Fragment、Service）之间传递数据对象。最常见的方式是使用Intent来传递数据，但是Intent使用Java的序列化（Serializable）机制来实现对象的传递。虽然Serializable是一种简单易用的方式，但是在性能方面存在一些问题： 序列化和反序列化的过程需要大量的I&#x2F;O操作，会对性能产生负面影响。 序列化的结果是一个字节数组，会占用较大的内存空间。 序列化和反序列化过程中会产生大量的临时对象，增加了垃圾回收的压力。 为了解决这些问题，Android引入了Parcelable接口。Parcelable接口提供了一种高效的序列化机制，能够更快速地将对象序列化为字节流，并在需要时进行反序列化。相对于Serializable，Parcelable具有以下优势： 性能更好：Parcelable使用了更高效的序列化和反序列化机制，避免了大量的I&#x2F;O操作和临时对象的创建，因此比Serializable更快速和高效。 内存占用更少：Parcelable序列化的结果是一个较小的字节数组，相比Serializable占用的内存更少，减轻了内存压力。 更精确地控制序列化过程：Parcelable允许开发人员对序列化的过程进行更精确地控制，可以选择序列化和反序列化对象的哪些部分，从而提高效率。 ViewPager使用细节，如何设置成每次只初始化当前的Fragment，其他的不初始化（提示：Fragment懒加载）？ 自定义一个 LazyLoadFragment 基类，利用 setUserVisibleHint 和 生命周期方法，通过对 Fragment 状态判断，进行数据加载，并将数据加载的接口提供开放出去，供子类使用。然后在子类 Fragment 中实现 requestData 方法即可。这里添加了一个 isDataLoaded 变量，目的是避免重复加载数据。考虑到有时候需要刷新数据的问题，便提供了一个用于强制刷新的参数判断。（这个方法已经过时了） 在使用ViewPager时，可以通过使用FragmentPagerAdapter或是FragmentStatePagerAdapter来控制Fragment的初始化行为。以下是一种设置ViewPager每次只初始化当前Fragment的方法： 创建一个自定义的PagerAdapter类，继承自FragmentPagerAdapter或是FragmentStatePagerAdapter。 12345678910111213141516171819202122232425262728293031323334353637383940public class CustomPagerAdapter extends FragmentPagerAdapter &#123; private List&lt;Fragment&gt; fragments; public CustomPagerAdapter(FragmentManager fragmentManager, List&lt;Fragment&gt; fragments) &#123; super(fragmentManager); this.fragments = fragments; &#125; @Override public Fragment getItem(int position) &#123; return fragments.get(position); &#125; @Override public int getCount() &#123; return fragments.size(); &#125; @Override public CharSequence getPageTitle(int position) &#123; // 返回每个Fragment对应的标题（可选） return &quot;Fragment &quot; + (position + 1); &#125; @Override public Object instantiateItem(ViewGroup container, int position) &#123; // 在这里通过position判断当前显示的Fragment，只初始化当前Fragment if (position == getCurrentFragmentPosition()) &#123; return super.instantiateItem(container, position); &#125; else &#123; // 返回一个空的Fragment作为占位符 return new Fragment(); &#125; &#125; private int getCurrentFragmentPosition() &#123; // 根据自己的逻辑获取当前显示的Fragment的位置 return 0; &#125;&#125; 在创建ViewPager时，使用自定义的PagerAdapter。 12345678ViewPager viewPager = findViewById(R.id.viewPager);List&lt;Fragment&gt; fragments = new ArrayList&lt;&gt;();fragments.add(new Fragment1());fragments.add(new Fragment2());fragments.add(new Fragment3());CustomPagerAdapter pagerAdapter = new CustomPagerAdapter(getSupportFragmentManager(), fragments);viewPager.setAdapter(pagerAdapter); 上述代码中，自定义的PagerAdapter类重写了instantiateItem()方法。在该方法中，通过判断当前显示的Fragment的位置，只对当前Fragment进行初始化，而对其他Fragment返回一个空的Fragment作为占位符。你可以根据自己的逻辑来确定当前显示的Fragment的位置。 这样设置后，ViewPager每次只会初始化当前显示的Fragment，其他的Fragment将不会被初始化，从而提高了性能和效率。 注意：使用FragmentStatePagerAdapter时，系统会销毁不再需要的Fragment，因此在instantiateItem()方法中，可以返回一个空的Fragment作为占位符。而对于FragmentPagerAdapter，可以通过重写destroyItem()方法来实现类似的效果。 希望这个答案对你有所帮助！如果你有其他问题，请随时提问。 如何简化Parcelabel的使用？ kotlin可以使用Parcelize注解简化Parcelable的书写 Android扩展插件现在包含一个实现了Parcelable的自动生成器。在主构造函数中声明序列化的属性并添加一个@Parcelize注解，生成器就会自动创建writeToParcel（）&#x2F; createFromParcel（）方法 12@Parcelizedata class Student(val id: String, val name: String, val grade: String) : Parcelable 使用bitmap时应当注意什么？ 选择合适的图片规格 降低采样率 可以通过比较要显示的大小和图片的实际大小选择一个合适的采样率，降低图片的内存占用 复用内存 即，通过软引用(内存不够的时候才会回收掉)，复用内存块，不需要再重新给这个bitmap申请一块新的内存，避免了一次内存的分配和回收，从而改善了运行效率。 使用recycle()方法回收内存 压缩图片：Jpeg,Png,Webp OOM是否可以Try Catch？ 有一种情况可以： Try语句块中声明了巨大的对象，比如位图，导致OOM，在catch语句中，可以尝试释放这些大的对象，解决OOM 但是我们推荐使用软引用、弱引用、硬盘缓存来处理这种问题 如果OOM的原因不是这些大对象，那么Catch语句将继续抛出OOM 多进程 一般来说，Android应用多进程有三个好处。 1）我们知道Android系统对每个应用进程的内存占用是有限制的，而且占用内存越大的进程，通常被系统杀死的可能性越大。让一个组件运行在单独的进程中，可以减少主进程所占用的内存，降低被系统杀死的概率. 2）如果子进程因为某种原因崩溃了，不会直接导致主程序的崩溃，可以降低我们程序的崩溃率。 3）即使主进程退出了，我们的子进程仍然可以继续工作，假设子进程是推送服务，在主进程退出的情况下，仍然能够保证用户可以收到推送消息。 使用：在配置文件中设置process，但是注意一旦使用多进程会有多种问题，比如Application重复创建的问题、静态变量失效的问题、多个进程资源共享困难的问题 Canvas.save()与Canvas.restore()的调用时机 save：用来保存Canvas的状态。save之后，可以调用Canvas的平移、放缩、旋转、错切、裁剪等操作。 restore：用来恢复Canvas之前保存的状态。防止save后对Canvas执行的操作对后续的绘制有影响。 save和restore要配对使用（restore可以比save少，但不能多），如果restore调用次数比save多，会引发Error。save和restore操作执行的时机不同，就能造成绘制的图形不同。 android数据库迁移（修改表，增加表和删除表不用改version） SQLite SQLiteHelper中有一个onCreate()和onUpgrade()函数，当用户尝试访问数据库时，如果数据库版本更新了，就会跑去调用onUpgrade() 在onUpgrade中，判断老版本，然后升级到新版本，升级的过程是 将现在的表重命名位临时表 创建新的表 临时表的数据导入到新表 删除临时表 升级过程应该包裹在 db.beginTransaction(); 和 db.setTransactionSuccessful(); 之间，这样过程中出错数据库可以自动回滚 12345678910111213141516@Override public void onUpgrade(SQLiteDatabase db, int oldVersion, int newVersion) &#123; switch (newVersion) &#123; case 2: db.beginTransaction(); db.execSQL(CREATE_TEMP_BOOK); db.execSQL(CREATE_BOOK); db.execSQL(INSERT_DATA); db.execSQL(DROP_BOOK); db.setTransactionSuccessful(); db.endTransaction(); break; &#125; 跨版本升级既可以给每种版本之间的升级写逻辑（要写死），也可以直接链式升级（如果用户版本比较低会让用户等比较久） Room的数据库迁移 较高版本的Room支持自动迁移，但是比较复杂的情况仍然需要手动迁移 1234567891011121314151617181920// Database class before the version update.@Database( version = 1, entities = [User::class])abstract class AppDatabase : RoomDatabase() &#123; ...&#125;// Database class after the version update.@Database( version = 2, entities = [User::class], autoMigrations = [ AutoMigration (from = 1, to = 2) ])abstract class AppDatabase : RoomDatabase() &#123; ...&#125; 删除或重命名表等架构更改不明确的操作需要通过AutoMigrationSpec为Room指出数据库迁移时的配置 Spec有四种注解： @DeleteTable(tableName) @RenameTable(fromTableName, toTableName) @DeleteColumn(tableName, columnName) @RenameColumn(tableName, fromColumnName, toColumnName) 12345678910111213/* Copyright 2020 Google LLC. SPDX-License-Identifier: Apache-2.0 */@Database(- version = 2,+ version = 3, entities = [ Doggos.class ], autoMigrations = [ AutoMigration (from = 1, to = 2),+ AutoMigration (from = 2, to = 3) ] )abstract class DoggosDatabase : RoomDatabase &#123; &#125; 注意exportSchema一定要是true 12345678910111213141516171819202122@Database( version = 3, entities = [GoodDoggos::class], autoMigrations = [ AutoMigration ( from = 1, to = 2, spec = DoggosDatabase.DoggosAutoMigration1::class ), AutoMigration( from = 2, to = 3, spec = DoggosDatabase.DoggosAutoMigration2::class ) ])abstract class DoggosDatabase : RoomDatabase() &#123; @RenameTable(fromTableName = &quot;Doggos&quot;, toTableName = &quot;GoodDoggos&quot;) class DoggosAutoMigration1: AutoMigrationSpec &#123; &#125; @RenameTable(fromTableName = &quot;GoodDoggos&quot;, toTableName = &quot;SuperDoggos&quot;) class DoggosAutoMigration2 : AutoMigrationSpec &#123;&#125;&#125; 手动迁移：如果怎么搞都搞不好，就用手动迁移 123456789101112131415val MIGRATION_1_2 = object : Migration(1, 2) &#123; override fun migrate(database: SupportSQLiteDatabase) &#123; database.execSQL(&quot;CREATE TABLE `Fruit` (`id` INTEGER, `name` TEXT, &quot; + &quot;PRIMARY KEY(`id`))&quot;) &#125;&#125;val MIGRATION_2_3 = object : Migration(2, 3) &#123; override fun migrate(database: SupportSQLiteDatabase) &#123; database.execSQL(&quot;ALTER TABLE Book ADD COLUMN pub_year INTEGER&quot;) &#125;&#125;Room.databaseBuilder(applicationContext, MyDb::class.java, &quot;database-name&quot;) .addMigrations(MIGRATION_1_2, MIGRATION_2_3).build() 编译期注解与运行期注解（这个好难） 运行期注解利用反射获取信息，比较消耗性能，对应@Retention（RetentionPolicy.RUNTIME）这个反射是一个循环类型的，时间开销很大，所以一般都喜欢写编译期注解 编译期注解使用APT和Javapoet实现，对应@Retention(RetentionPolicy.CLASS) bitmap和recycler() 2.3.3即以下应该在不使用位图时调用recycle方法，释放位图占用的内存，避免OOM，这个时代，bitmap本身放在栈中，引用放在堆中，因此需要手动调用recycle()，在3.0以上后整个bitmap都被放到了堆里面，于是整个创建和回收都被交给了GC，并且引入了inbitmap，位图删除后还会持有一个软引用，后面要用如果位图还没有被释放就能直接用位图了 Android官方推荐使用Glide库加载和处理位图，Glide提供许多复杂操作的抽象 强引用置为null会不会立刻被回收？ 不会，GC试运行在后台线程中的，只有当用户线程运行到安全点或是安全区域时才会启动对象引用关系的扫描，扫描完成也不会立刻释放，因为有一些对象的引用是可以恢复的，只有确定对象的引用无法恢复后才会正式回收对象 Bundle传递对象为什么要序列化 序列化表示将一个对象转换成可存储或可传输的状态，序列化的原因基本都是三种情况： 永久性保存对象，保存对象的字节序列到本地文件中 对象在网络中传递 对象在IPC（不同进程间）传递 广播传递数据是否有限制 Intent在传递数据时是有大小限制的，大约限制在1MB之内，你用Intent传递数据，实际上走的是跨进程通信（IPC），跨进程通信需要把数据从内核copy到进程中，每一个进程有一个接收内核数据的缓冲区，默认是1M；如果一次传递的数据超过限制，就会出现异常。 不同厂商表现不一样有可能是厂商修改了此限制的大小，也可能同样的对象在不同的机器上大小不一样。 传递大数据，不应该用Intent；考虑使用ContentProvider或者直接匿名共享内存。简单情况下可以考虑分段传输。 硬件加速 硬件加速就是运用GPU优秀的运算能力来加快渲染的速度，而通常的基于软件的绘制渲染模式是完全利用CPU来完成渲染。 android api 11开始支持硬件加速，14开始默认开启硬件加速 对于自定义View可能会出现硬件加速不兼容的情况，这是需要手动关闭硬件加速 关闭或开启硬件加速可以在应用、Activity、窗口、视图四个层面进行控制 应用级别 12&lt;application android:hardwareAccelerated=&quot;true&quot; ...&gt; Activity级别 12345&lt;application android:hardwareAccelerated=&quot;true&quot;&gt; &lt;activity ... /&gt; &lt;activity android:hardwareAccelerated=&quot;false&quot; /&gt;&lt;/application&gt; 窗口级别 启用（官方文档说现在不行了） 12345window.setFlags( WindowManager.LayoutParams.FLAG_HARDWARE_ACCELERATED, WindowManager.LayoutParams.FLAG_HARDWARE_ACCELERATED) 视图级别 SOFTWARE停用加速 HARDWARE启用加速 12myView.setLayerType(View.LAYER_TYPE_SOFTWARE, null) 硬件加速也有内存开销：硬件加速的消耗问题，因为是使用OpenGL，需要把系统中OpenGL加载到内存中，OpenGL API调用就会占用8MB，而实际上会占用更多内存，并且使用了硬件必然增加耗电量了 硬件加速的优势还有display list的设计，使用这个我们不需要每次重绘都执行大量的代码，基于软件的绘制模式会重绘脏区域内的所有控件，而display只会更新列表，然后绘制列表内的控件。 CPU更擅长复杂逻辑控制，而GPU得益于大量ALU和并行结构设计，更擅长数学运算。 ContentProvider权限管理，似懂非懂 Fragment状态保存 1、Activity的状态保存, 在Activity的onSaveInstanceState()里, 调用了FragmentManger的saveAllState()方法, 其中会对mActive中各个Fragment的实例状态和View状态分别进行保存. 2、FragmentManager还提供了public方法: saveFragmentInstanceState(), 可以对单个Fragment进行状态保存, 这是提供给我们用的。 3、FragmentManager的moveToState()方法中, 当状态回退到ACTIVITY_CREATED, 会调用saveFragmentViewState()方法, 保存View的状态. 在Activity中创建一个Thread和在Service中创建一个Thread的区别 在Activity中被创建：该Thread的就是为这个Activity服务的，完成这个特定的Activity交代的任务，主动通知该Activity一些消息和事件，Activity销毁后，该Thread也没有存活的意义了。 在Service中被创建：这是保证最长生命周期的Thread的唯一方式，只要整个Service不退出，Thread就可以一直在后台执行，一般在Service的onCreate()中创建，在onDestroy()中销毁。所以，在Service中创建的Thread，适合长期执行一些独立于APP的后台任务，比较常见的就是：在Service中保持与服务器端的长连接 计算bitmap内存大小，如何避免bitmap产生内存溢出 Bitamp 占用内存大小 &#x3D; 宽度像素 x （inTargetDensity &#x2F; inDensity） x 高度像素 x （inTargetDensity &#x2F; inDensity）x 一个像素所占的内存 注：这里inDensity表示目标图片的dpi（放在哪个资源文件夹下），inTargetDensity表示目标屏幕的dpi，所以你可以发现inDensity和inTargetDensity会对Bitmap的宽高进行拉伸，进而改变Bitmap占用内存的大小。 在Bitmap里有两个获取内存占用大小的方法。 getByteCount()：API12 加入，代表存储 Bitmap 的像素需要的最少内存。 getAllocationByteCount()：API19 加入，代表在内存中为 Bitmap 分配的内存大小，代替了 getByteCount() 方法。 在不复用 Bitmap 时，getByteCount() 和 getAllocationByteCount 返回的结果是一样的。在通过复用 Bitmap 来解码图片时，那么 getByteCount() 表示新解码图片占用内存的大 小，getAllocationByteCount() 表示被复用 Bitmap 真实占用的内存大小（即 mBuffer 的长度）。 避免内存溢出： bitmapFactory 图片压缩 改变像素类型 inPurgeable 让系统可以回收bitmap的内存 如何向用户推送应用更新？ 通过接口获取最新版本号 和本地版本比较 显示更新提示 下载APK并安装 全量发布：直接把新版本推给全部用户，有bug测试组切腹自尽 灰度发布：发一点点，有bug打补丁（AB test策略） 为什么Android要引入签名机制？ 验证身份：开放商可能用相同的package name来混淆替换已经安装的程序，签名机制可以保证签名不同的包不会被替换 避免被替换：签名利用摘要算法避免应用程序包被修改 系统权限控制：Android的权限模型依赖于应用的签名。系统会根据应用的签名来确定应用所具有的权限。如果应用的签名与系统中预先分发的权限声明相匹配，应用将被授予相应的权限。这样可以防止未经授权的应用获取敏感权限。 应用更新验证：当应用程序更新时，系统会验证新版本的应用是否使用相同的签名。只有相同签名的应用才能被视为同一个应用的更新版本。这样可以防止恶意开发者发布伪装成合法应用的恶意更新。 通过Gradle配置多渠道包 12345678android &#123; productFlavors &#123; xiaomi &#123;&#125; baidu &#123;&#125; wandoujia &#123;&#125; _360 &#123;&#125; // 或“&quot;360&quot;&#123;&#125;”，数字需下划线开头或加上双引号 &#125;&#125; 执行.&#x2F;gradlew assembleRelease ，将会打出所有渠道的release包； 执行.&#x2F;gradlew assembleWandoujia，将会打出豌豆荚渠道的release和debug版的包； 执行.&#x2F;gradlew assembleWandoujiaRelease将生成豌豆荚的release包。 因此，可以结合buildType和productFlavor生成不同的Build Variants，即类型与渠道不同的组合。 activity和Fragment之间怎么通信，Fragment和Fragment怎么通信？ Handler 广播 事件总线 接口回调 bundle和setArguments(bundle) Kotlin协程 MotionLayout 12345678var isOnSearch = false // 监听搜索按钮点击事件 searchBar.setOnClickListener &#123; // 当搜索按钮被点击时，触发上升动画 homeMotion.transitionToState(R.id.end) isOnSearch = true// Log.i(&quot;gggg&quot;, &quot;搜索框被点击&quot;) &#125; 计算机网络HTTP协议 什么是HTTP协议？ 从三个方面理解：协议、传输、超文本 HTTP 是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（两个以上的参与者），以及相关的各种控制和错误处理方式（行为约定和规范）。 HTTP 协议是一个双向协议。数据虽然是在 A 和 B 之间传输，但允许中间有中转或接力。中间人遵从 HTTP 协议，只要不打扰基本的数据传输，就可以添加任意额外的东西。 「超文本」，它就是超越了普通文本的文本，它是文字、图片、视频等的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本。HTML 就是最常见的超文本了，它本身只是纯文字文件，但内部用很多标签定义了图片、视频等的链接，再经过浏览器的解释，呈现给我们的就是一个文字、有画面的网页了。 HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。 HTTP常见的状态码 1xx：中间状态 2xx：OK 200 OK 204 OK，只是没有返回的Body 206 OK，返回了一部分数据 3xx：重定向 301 永久重定向，会将浏览器重定向 302 临时重定向，同上 304 重定向到缓存 4xx：存在错误 400 笼统的错误码 403 禁止访问 404 资源未找到 5xx：服务器出错 500 笼统的错误码 501 尚未实现的功能 502 网关错误，访问后端异常 503 服务器太忙无法响应请求 Http缓存原理 双方约定什么时候要重新请求：强制缓存 Cache-Control 通过请求时间和服务器给出的时间，为资源计算一个过期时间 Expire 服务器直接规定什么时候过期 如果需要重新请求，但是服务器觉得还可依据需用缓存：协商缓存 Etag：服务器为资源文件生成一个唯一标识，提供给客户端，客户端请求时加上if-none-match，如果资源文件的etag没变，那么直接304 Label-Modified：服务器告诉客户端资源文件请求时的最近一次修改时间，重新请求时带上if-modified-since，如果资源文件更新时间没有发生变化，那么304 Etag比Label-Modified好用，因为 没修改文件，修改时间也会变，客户端就莫名其妙的重新请求了 label-modified只能精确到秒级，一些文件的修改可能发生在秒内，导致无法被检测到 一些服务器不能很好地获取文件最后修改时间 Get与Post 按照Http标准设置的Get请求是安全且幂等的（不会修改服务器本身并且多次操作获得的结果一样），POST请求则不是 Http&#x2F;1.1的特性 简单：报文header+body，header也是key-value形式，结构很简单 灵活且易于扩展：各种请求方法、URI&#x2F;URL、状态码、头字段都可以由开发者自定义和扩充，http作为应用层协议，允许下层协议进行变化，比如添加TLS&#x2F;SSL层、TCP改UDP 应用广泛和跨平台 Http&#x2F;1.1的缺点 Http本身无状态：这意味着Http协议本身不能持续识别用户，也无法识别相互关联的请求，一种可能的解决方案是使用cookie 数据裸奔：Http本身没有加密，所有信息都在互联网上裸奔 不安全：信息不加密、不验证对方的身份、不检查数据是否被中间人修改 Http&#x2F;1.1性能及解决方案 关键：TCP&#x2F;IP协议的耗时 长连接避免反复建立连接的时间开销 管道网络传输，客户端没收到回应就接着发请求，解决请求队头阻塞的问题（但是这个功能几乎没有被使用过） 队头阻塞：即使用了管道网络传输解决请求对头阻塞，响应对头阻塞也是无法解决的 HTTP与HTTPS的区别 HTTP TCP连接建立后直接开始传输，HTTPS在TCP请求建立后还要经历SSL&#x2F;TLS握手过程，才会正式开始传输 HTTP信息裸奔，HTTPS采用混合加密技术，保证数据安全 HTTP默认端口为80，HTTPS默认端口443 HTTPS协议要想CA请求证书，验证对方的身份 HTTPS如何保证安全 信息加密：采用混合加密技术保证信息安全 混合加密 在通信建立前采用非对称加密方式传递生成一个会话密钥 通信过程中使用会话密钥进行对称加密 身份校验：摘要算法+数字签名 摘要算法 发送方通过摘要算法（一种hash算法）计算出一个通信数据的指纹，一起发送给对方，对方收到后，也算出通信数据的一个指纹，然后与发过来的比较，如果不一样那就说明信息被篡改了 数字证书 为了避免hash值也被篡改，服务器向客户端颁发公钥，然后用自己的私钥给hash值加密，客户端收到后如果能用自己的密钥解开，就能证明是服务端发送的，然后再验证指纹，如果指纹也是一样的，就能证明内容没有被篡改 但是客户端得到的公钥也可能是中间人伪造的，因此我们需要一个CA来帮助我们验证 服务器会将自己的公钥注册到CA，而CA会颁发一个数字证书给服务器，这个数字证书中有一个CA计算得到并且通过CA私钥加密的hash值，可以被CA的公钥解密，而CA的公钥已经提前内置到浏览器或操作系统里（所以不要用来路不明的浏览器，里面可能有来路不明的CA公钥），当建立HTTPS连接时，服务器将自己的数字证书发给客户端，客户端使用内置的公钥解密，如果能解密得到的hash值与获得的证书算出的hash值相同·，说明数字证书没被篡改，从而获得服务器的公钥，然后客户端可以使用这个公钥加密并发送数据到服务端 完整的基于RSA算法的TLS握手与HTTPS建立过程 客户端索要服务器数字证书，验证后获得的公钥 双方协商生产会话密钥 双方采用会话秘钥加密通信 完整过程： ClientHello 客户端向服务器发起加密请求，发送的信息包括： 客户端支持的TLS版本（如果服务器不支持直接拜拜） 客户端生产的随机数 客户端支持的密码套件列表，如RSA加密算法（如果加密算法不支持也拜拜） ServerHello 服务器收到请求后发出响应 确认TLS协议版本 服务器生产的随机数 确认密码套件列表 服务器的数字证书 客户端回应 首先客户端会验证服务器发来的数字证书，没问题就取出解密后的公钥 一个被服务器公钥加密的随机数 加密算法改变通知：接下来所有的通信都将使用会话密钥 握手结束通知：将之前所有通信的数据做一个摘要，供服务端检验 服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。 服务器最后的回应 加密算法改变通知 前面所有通信的摘要，供客户端校验 缺点：RSA算法的HTTPS存在“前向安全问题”，即一旦服务端的私钥泄露，客户端通过公钥加密的随机数就会泄露，从而导致会话秘钥泄露，最终导致整个通讯裸奔 为了解决这一问题，便有了ECDHE密钥协商算法 CA颁发证书的过程 CA 签发证书的过程，如上图左边部分： 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值； 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名； 最后将 Certificate Signature 添加在文件证书上，形成数字证书； 客户端校验服务端的数字证书的过程，如上图右边部分： 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1； 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ； 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。 证书信任链问题： 总括来说，由于用户信任 GlobalSign，所以由 GlobalSign 所担保的 baidu.com 可以被信任，另外由于用户信任操作系统或浏览器的软件商，所以由软件商预载了根证书的 GlobalSign 都可被信任。 为什么需要这么多层证书？为什么不直接都由root颁发？ 这是为了安全问题，如果直接由root颁发，一旦root失守，整个CA机制都会瘫痪，边缘CA失守则不会那么严重 TLS记录协议 TLS 记录协议主要负责消息（HTTP 数据）的压缩，加密及数据的认证，过程如下图 将消息分割为短片段，每个片段分别压缩 为每个压缩后的片段添加MAC值，可以通过MAC识别篡改和重放攻击（TLS记录维持了一个递增的序号，可以发现重传和重排，同时有一个不重数Nonce，可以防止重放整个TCP传输） 经过压缩的消息片段会和消息认证码一起通过对称密码进行加密 最后加上数据类型、版本、压缩后长度组成报头 HTTP&#x2F;2的进步 头部压缩：一样或相似的头会被HTTP2干掉，通过一个HPACK算法，客户端和浏览器一起维护一张头部信息表，生成一个索引号，以后就不用发同样字段了，只发索引号 二进制格式，HTTP2的头和数据体都是二进制，并且统称为头信息帧和数据帧 并发传输：HTTP2可以复用一个TCP连接，每个TCP连接拥有多个Stream，Stream里面可以包含一个或多个Message，Message对应HTTP&#x2F;1中的请求或响应，不同的HTTP请求用独一无二的Stream ID来区分，接受端可以通过Stream ID组装信息 服务器推送：服务端不再被动的响应，还可以主动地推送信息，客户端发出的Stream必须是奇数，服务器发出的stream必须是偶数 Http2的瓶颈：因为TCP协议 一旦丢包，就会触发TCP的重传机制，而后续的报文，即使已经缓存到了内核中，也只能等待丢失的包重传，因为TCP要求字节数据完整且连续 HTTP&#x2F;3的进步 既然HTTP&#x2F;2在TCP层性能有瓶颈，那就扔了TCP！用UDP！ 但是传输又得是可靠的，于是使用了基于UDP的QUIC协议，实现类似TCP的可靠性传输 QUIC没有队头阻塞、连接建立更快、连接迁移 连接迁移：QUIC协议通过连接ID来标记通信的两个端点，客户端和服务器可以各自选择一组ID标记自己，这样即使网络发生变化，比如wifi换5G，只要上下文信息不变，就可以直接复用连接，不用像TCP那样还要重连，避免了卡顿 HTTP3普及速度非常缓慢，很多设备不知道什么是QUIC，会把它当做UDP，有的看到UDP包就直接丢 TCP协议 为什么需要TCP协议？TCP协议工作在那一层？ IP 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。 TCP工作在传输层 数据库基础·SQLite·Room MySQL有哪些数据类型 整数（Int，还有大中小） 浮点数（Float，Double，Decimal） 字符串（Char，Varchat，Text（不区分大小写），Blob（区分大小写），Binary，也有大中小） 日期（Date，Year…） Enum（映射到数字，最多65536，MySQL留了一个0来表示错误）（多个选项选一个，如果出错写空值） Set（最多64个项，多个选项选多个，如果有错，把错的扔了只留有效的） 数据库范式 1NF 现在的数据库写不出来的 2NF 所有的非主属性都要完全依赖于码 ABCD，如果AB是码，那么CD都应该由AB联合推出，而不是A或B单独就能推出 3NF，在2NF的基础上不允许传递依赖 ABCD，如果A$\\Rightarrow$B,B$\\Rightarrow$CD,就不行，(学号) → (所在学院) → (学院地点, 学院电话) BCNF,2NF和3NF都只针对非主属性，BCNF进一步将限制推广到所有属性：且每个属性都不传递依赖于R的候选键 比如AB$\\Rightarrow$D,BC$\\Rightarrow$D，那么AB，BC都是码，从而ABC都是主属性，而这时如果A$\\Rightarrow$C，就会让D有传递依赖，3NF是不会拒绝这种设计的，但是BCNF会拒绝 事务隔离级别 事务遵循ACID（要么不做，要么全做、事务执行前后，数据库都保持一致性状态、隔离性保证事务并发、事务结束后对数据库的修改是持久的） 读未提交：读了一个未提交事务修改过的数据，又叫脏读 不可重复读（Oracle默认的事务隔离级别）：事务执行过程中如果多次读取数据，可能出现读到的结果不一样的情况，因为其他事务可能在事务处理过程中操纵了数据 可重复读（MySQL默认的事务隔离级别）：事务多次读取得到的数据是一样的，但是仍然可能出现幻读 可串行化：事务可以被理解成一个个执行的，效率最低 幻读与不可重复度的区别 (1) 不可重复读是读取了其他事务更改的数据，针对update操作 解决：使用行级锁，锁定该行，事务A多次读取操作完成后才释放该锁，这个时候才允许其他事务更改刚才的数据。 (2) 幻读是读取了其他事务新增的数据，针对insert和delete操作 解决：使用表级锁，锁定整张表，事务A多次读取数据总量之后才释放该锁，这个时候才允许其他事务新增数据。 这时候再理解事务隔离级别就简单多了呢。 索引 按照数据结构分，有B+索引，Hash索引，Full-Text索引 设计模式与软件架构 设计模式原则 单一职责原则：一个类只应当有一个引起它发生变化的原因 开放封闭原则：一个实体应该对外扩展开放，对内修改关闭，即每次发生变化应当是添加代码，而不是修改代码 李氏替换原则：凡是父类出现的地方，子类应当都可以使用 依赖倒置原则：实现应当依赖于抽象，抽象不应当依赖于实现 接口隔离原则：一个接口不应当承担过多职责 合成复用原则：尽量采用聚合&#x2F;组合，而不是继承，新的类可以委托已经实现的类来完成某些功能来实现复用 最少知识原则（迪米特法则）：之和你最好的朋友通信，减少和其他人交互 MVC Model-View-Controller View传指令到Controller，Controller在业务逻辑完成后通知Model发生变更，Model变更后将数据发送到View，完成视图的更新 交互 用户与View交互，比如操纵DOM，View接受指令，并传递给controller 用户直接将指令给Controller，比如直接更改URL BackBone：MVC改进 Controller几乎只保留的Router的作用，而View则变得很厚 MVP Model-View-Presenter 将Controller改为Presenter，View不再与Model交互，而是改为Presenter与View双向交互，这种设计下View变得很薄，各种事情都交给Presenter来做 MVVM Model-View-ViewModel 和MVP很像，但是将Presenter改为ViewModel，ViewModel和View之间采用双向绑定 Android中的MVVM MVVM的本质是数据驱动，将解耦做得更加彻底 在Android中，Activity和Fragment扮演View的角色，ViewModel是VM，Repository类则集成Model的功能，提供对于外存、内存、网络数据的访问 实现： 首先我们需要一个MyViewModel类继承自ViewModel 这个VM持有View需要的Data，它们被MutableLiveData（可以被更改的LiveData）包裹，同时VM应当开发接口让View获取这些MutableLiveData，但是注意提供的类型应当是LiveData，避免View直接将LiveData修改，不过有时候View就是需要修改Data，这时我们应该单独建立专门的Setter接口，而不是直接将MutableLiveData交给View，这将造成数据修改的不可控 12345678910111213141516171819public class UserListViewModel extends ViewModel &#123; //用户信息 private MutableLiveData&lt;List&lt;User&gt;&gt; userListLiveData; //进条度的显示 private MutableLiveData&lt;Boolean&gt; loadingLiveData; public UserListViewModel() &#123; userListLiveData = new MutableLiveData&lt;&gt;(); loadingLiveData = new MutableLiveData&lt;&gt;(); &#125; public LiveData&lt;List&lt;User&gt;&gt; getUserListLiveData() &#123; return userListLiveData; &#125; public LiveData&lt;Boolean&gt; getLoadingLiveData() &#123; return loadingLiveData; &#125; ...&#125; 在Activity中获取LiveData并通过Observe方法监听LiveData的更改，这样View和ViewModel就被绑定起来了 123456789101112131415161718192021222324//UserListActivity.java...//观察ViewModel的数据，且此数据 是 View 直接需要的，不需要再做逻辑处理private void observeLivaData() &#123; mUserListViewModel.getUserListLiveData().observe(this, new Observer&lt;List&lt;User&gt;&gt;() &#123; @Override public void onChanged(List&lt;User&gt; users) &#123; if (users == null) &#123; Toast.makeText(UserListActivity.this, &quot;获取user失败！&quot;, Toast.LENGTH_SHORT).show(); return; &#125; //刷新列表 mUserAdapter.setNewInstance(users); &#125; &#125;); mUserListViewModel.getLoadingLiveData().observe(this, new Observer&lt;Boolean&gt;() &#123; @Override public void onChanged(Boolean aBoolean) &#123; //显示/隐藏加载进度条 mProgressBar.setVisibility(aBoolean? View.VISIBLE:View.GONE); &#125; &#125;);&#125; 为了让App获取数据，我们单独创建一个Repository，这个类将代理所有数据获取过程，并开放简单一致的接口让ViewModel获取数据，这样ViewModel无需关系数据具体的获取 123456789101112131415161718192021222324252627282930313233343536public class UserRepository &#123;private static UserRepository mUserRepository;public static UserRepository getUserRepository()&#123; if (mUserRepository == null) &#123; mUserRepository = new UserRepository(); &#125; return mUserRepository;&#125;//(假装)从服务端获取public void getUsersFromServer(Callback&lt;List&lt;User&gt;&gt; callback)&#123; new AsyncTask&lt;Void, Void, List&lt;User&gt;&gt;() &#123; @Override protected void onPostExecute(List&lt;User&gt; users) &#123; callback.onSuccess(users); //存本地数据库 saveUsersToLocal(users); &#125; @Override protected List&lt;User&gt; doInBackground(Void... voids) &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //假装从服务端获取的 List&lt;User&gt; users = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 20; i++) &#123; User user = new User(&quot;user&quot;+i, i); users.add(user); &#125; return users; &#125; &#125;.execute();&#125; 将ViewModel和Repository连接起来 123456789101112131415161718192021222324252627282930313233343536373839404142public class UserListViewModel extends ViewModel &#123; //用户信息 private MutableLiveData&lt;List&lt;User&gt;&gt; userListLiveData; //进条度的显示 private MutableLiveData&lt;Boolean&gt; loadingLiveData; public UserListViewModel() &#123; userListLiveData = new MutableLiveData&lt;&gt;(); loadingLiveData = new MutableLiveData&lt;&gt;(); &#125; /** * 获取用户列表信息 * 假装网络请求 2s后 返回用户信息 */ public void getUserInfo() &#123; loadingLiveData.setValue(true); UserRepository.getUserRepository().getUsersFromServer(new Callback&lt;List&lt;User&gt;&gt;() &#123; @Override public void onSuccess(List&lt;User&gt; users) &#123; loadingLiveData.setValue(false); userListLiveData.setValue(users); &#125; @Override public void onFailed(String msg) &#123; loadingLiveData.setValue(false); userListLiveData.setValue(null); &#125; &#125;); &#125; //返回LiveData类型 public LiveData&lt;List&lt;User&gt;&gt; getUserListLiveData() &#123; return userListLiveData; &#125; public LiveData&lt;Boolean&gt; getLoadingLiveData() &#123; return loadingLiveData; &#125;&#125; 在View中初始化时调用getData()方法，让ViewModel获取数据 1234567891011121314151617181920212223242526272829303132//UserListActivity.javapublic class UserListActivity extends AppCompatActivity &#123;private UserListViewModel mUserListViewModel;private ProgressBar mProgressBar;private RecyclerView mRvUserList;private UserAdapter mUserAdapter;@Overrideprotected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_user_list); initView(); initViewModel(); getData(); observeLivaData();&#125;private void initView() &#123;...&#125;private void initViewModel() &#123; ViewModelProvider viewModelProvider = new ViewModelProvider(this); mUserListViewModel = viewModelProvider.get(UserListViewModel.class);&#125;/** * 获取数据，调用ViewModel的方法获取 */private void getData() &#123; mUserListViewModel.getUserInfo();&#125;private void observeLivaData() &#123;...&#125; 更加高级的单向绑定与双向绑定（个人感觉更像语法糖） 单向绑定： 在Xml中添加这段 12345&lt;data&gt; &lt;variable name=&quot;user&quot; type=&quot;com.llw.mvvm.User&quot; /&gt; data&gt; 需要绑定的组件这样写 1234567891011&lt;TextView android:id=&quot;@+id/tv_account&quot; android:text=&quot;@&#123;user.account&#125;&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot;/&gt; &lt;TextView android:id=&quot;@+id/tv_pwd&quot; android:text=&quot;@&#123;user.pwd&#125;&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot;/&gt; 使用DataBindingUtil生成DataBinding类 1ActivityMainBinding dataBing = DataBindingUtil.setContentView(this,R.layout....); DataBinging会在编译时为我们生成对应组件快速访问的字段，就不用findViewById了 手动刷新数据，数据绑定的组件也会刷新 1user.setPwd(dataBinding.etPwd.getText().toString().Trim()); 双向绑定： 双向绑定将Xml中的data改成ViewModel 12345&lt;data&gt; &lt;variable name=&quot;viewModel&quot; type=&quot;com.llw.mvvm.viewmodels.MainViewModel&quot; /&gt; data&gt; 要绑定的组件 123456789101112&lt;TextView android:id=&quot;@+id/tv_account&quot; android:text=&quot;@&#123;viewModel.user.account&#125;&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot;/&gt; &lt;TextView android:layout_marginBottom=&quot;24dp&quot; android:id=&quot;@+id/tv_pwd&quot; android:text=&quot;@&#123;viewModel.user.pwd&#125;&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot;/&gt; 这种写法可以吧ViewModel里面的MutableLiveData数据一起改了 触发更新 1user1.observe(this, user2 -&gt; dataBinding.setViewModel(mainViewModel));","tags":["又失业了"],"categories":["失业"]},{"title":"学习LLVM","path":"/2023/10/23/学习LLVM/","content":"项目结构 llvm&#x2F;cmake 生成系统构建文件 llvm&#x2F;examples 一些例子 llvm&#x2F;include llvm项目使用的头文件 llvm&#x2F;include&#x2F;llvm:llvm特有的头文件 llvm&#x2F;include&#x2F;llvm&#x2F;Surpport:一些不是llvm特有的头文件 llvm&#x2F;include&#x2F;llvm.Config:cmake配置的头文件 llvm&#x2F;lib llvm&#x2F;lib&#x2F;IR:核心的llvm文件，包括一些核心的类比如指令(Instruction)和基本块(Basicblock) AsmParser:asm代码处理库 Bitcode:bitcode处理库 Analysis:分析类，比如调用图、诱导变量（什么东东？），循环识别等 Transforms:IR-2-IR级别的转换，是编译优化的主攻方向 Target:描述代码生成目标架构 Codegen:代码生成核心类，包括指令选取、指令调度和寄存器选取 MC:在机器码层面操作的库 ExecutionEngine:直接执行字节码的库 Surpport:不是llvm特有的支持库 llvm&#x2F;binding 为不是c&#x2F;c++编写的程序提供使用llvm的便利（LLVM官方提供了针对OCaml和Python的） llvm&#x2F;projects 随llvm一起发布的项目 llvm&#x2F;test 项目测试 llvm&#x2F;tools 由上述库构建的可执行文件，是用户接口的主要组成 llvm&#x2F;utils 针对llvm源代码的实用程序 -5 -5 -4 0 0 3 3 4 5","tags":["编译原理","LLVM"],"categories":["LLVM"]},{"title":"nextjs前端开发环境解决跨域访问","path":"/2023/09/21/nextjs前端开发环境解决跨域访问/","content":"nextjs前端开发环境解决跨域访问 在做人只因交互的时候需要向nivo组件提供一个比较大的features数组来渲染地图，一开始想要直接本地加一个文件去读取，结果发现浏览器读取文件还比较麻烦，于是转而扔到云上希望直接fetch，结果就遇到了跨域访问限制 什么是跨域访问，问什么浏览器中要限制跨域访问？跨域访问是指请求一个与自身资源不同源（不同的域名、协议或端口）的资源。 不同源可以是不同的域名、协议或端口。 浏览器出于安全考虑设置了同源策略，限制了从脚本内发起跨域请求。 但在实际应用中，经常会发生跨域访问。 跨域访问限制主要是为了应对跨站点脚本攻击（Cross-Site Scripting, XSS）和跨站请求伪造（Cross-Site Request Forgery, CSRF）这两类安全隐患。 跨站点脚本攻击（XSS）：XSS 攻击是指攻击者向网页注入恶意脚本代码，当用户访问包含这些恶意脚本的网页时，攻击者可以利用这些脚本获取用户的敏感信息、篡改页面内容或进行其他恶意行为。跨域访问限制可以防止恶意脚本从一个域名加载到另一个域名，并阻止该脚本对其他域名的操作。 跨站请求伪造（CSRF）：CSRF 攻击是指攻击者利用用户已经通过身份验证的会话执行非预期的操作，通过欺骗用户的浏览器发送恶意请求，从而执行攻击者指定的操作，如更改密码、发表评论等。跨域访问限制可以防止第三方网站在用户不知情的情况下发送请求到目标网站，从而减少 CSRF 攻击的风险。 在开发中解决无法进行跨域访问在开发环境中，前端运行在localhost:3000上，但是资源在网络上，这时进行请求往往会得到跨域错误 为了避免跨域错误，我们可以配置一个转发规则，让localhost为我们转发到目标网站 在next.config中配置 123456789101112131415const nextConfig = &#123; reactStrictMode: true, transpilePackages: [&quot;@nivo&quot;], experimental: &#123; esmExternals: &quot;loose&quot;, &#125;, async rewrites() &#123; return [ &#123; source: &#x27;/files/:path*&#x27;, // 匹配所有以 /files 开头的路径 destination: &#x27;https://files.lsmcloud.top/:path*&#x27;, // 代理到的目标地址 &#125;, ]; &#125;,&#125;module.exports = nextConfig 这样当我们的项目运行时，电脑就会为我们起一个代理，具体使用的时候只需要 1fetch(/files/目标文件) localhost就会帮助我们转发到files.lsmcloud.top了 值得注意的是之前我写成http://files.lsmcloud.top/:path*没有成功，会返回521代码，我的站点是cloudflare代理并且配置了强制使用https协议，浏览器这样是可以正常访问的，但是不知道为啥在转发的时候就521了","tags":["前端开发","next.js"],"categories":["前端开发"]},{"title":"leetcode题目记录","path":"/2023/09/11/leetcode题目记录/","content":"Leetcode替换元素：从后往前的双指针法在a-b-c中将每一个-替换成任意一个字符串(比如aj)，空间开销为O(1)的做法： 首先计算-的数目，算出替换结束后最终字符串会有多大，按新的大小resize字符串 双指针，一个指针指向新字符串的末尾，另一个指向旧字符串的末尾 从后往前遍历 1234567if(s[oldPtr]!='-'){\ts[newPtr--]=s[oldPtr--];} else { oldPtr--; s[newPtr--]='j'; s[newPtr--]='a';} 删除元素：快慢指针法在-abc—bbbb-ccc–中删除- 空间开销为O(1)的做法： 快指针往后走，发现不是’-‘的字符，就让慢指针复制这个元素并往后走一步 但是这样会把-完全删掉，如果题目要求每两个单词之间至少要保留一个-，那么让快指针每次从’-‘走到有意义的字符时提醒慢指针添加一个’-‘即可 12345678910111213// 版本二 void removeExtraSpaces(string&amp; s) {//去除所有空格并在相邻单词之间添加空格, 快慢指针。 int slow = 0; //整体思想参考https://programmercarl.com/0027.移除元素.html for (int i = 0; i &lt; s.size(); ++i) { // if (s[i] != ' ') { //遇到非空格就处理，即删除所有空格。 if (slow != 0) s[slow++] = ' '; //手动控制空格，给单词之间添加空格。slow != 0说明不是第一个单词，需要在单词前添加空格。 while (i &lt; s.size() &amp;&amp; s[i] != ' ') { //补上该单词，遇到空格说明单词结束。 s[slow++] = s[i++]; } } } s.resize(slow); //slow的大小即为去除多余空格后的大小。} 翻转句子中的单词He is a handsome boy. 首先完全翻转 yob emosdnah a si eH. 然后将每个单词又翻转回来即可 boy handsome a is He. K!M!P!首先我想到的是快慢指针法 快指针和慢指针一开始都指向开头，快指针先顺次遍历，直到匹配不上 这个时候将慢指针移到快指针不匹配的地方，快指针开始从头匹配直到有一天快指针终于匹配上，慢指针在的位置就是要找的位置。 然而这样是错的！ 问题的关键在于如果快指针所经历的后缀真子串（我发明的叫法）包含了模式串的前缀真子串，这时候慢指针一跳就把这部分忽略了： 当到达下面的状态时 慢指针直接跳到b从b开始匹配，就把模式串的前缀真子串给略过了 所以我们要用前缀表 使用前缀表，在不匹配的时候在模式串中回退，这种回退必须是考虑到模式串子前缀的，而前缀表可以实现这一点，当模式串匹配失败时，可以检查前缀表考察前面一个子串有没有公共前后缀，如果有的话，那么应该从公共前缀处继续尝试匹配或回退直到退无可退为止(j==0) 详解:实现strstr() 构造前缀表本身就很难 构造前缀表也要用到已经构造好的前缀表，我们用j表示已经匹配到的前缀，当匹配不上时也是一遍回退一遍继续尝试 复杂度 KMP可以将复杂度从暴力算法的O(MN)变成O(M+N) 完整代码 12345678910111213141516171819202122232425262728293031323334353637class Solution {public: void getNext(int* next, const string&amp; s) { int j = -1; next[0] = j; for(int i = 1; i &lt; s.size(); i++) { // 注意i从1开始 while (j &gt;= 0 &amp;&amp; s[i] != s[j + 1]) { // 前后缀不相同了 j = next[j]; // 向前回退 } if (s[i] == s[j + 1]) { // 找到相同的前后缀 j++; } next[i] = j; // 将j（前缀的长度）赋给next[i] } } int strStr(string haystack, string needle) { if (needle.size() == 0) { return 0; } int next[needle.size()]; getNext(next, needle); int j = -1; // // 因为next数组里记录的起始位置为-1 for (int i = 0; i &lt; haystack.size(); i++) { // 注意i就从0开始 while(j &gt;= 0 &amp;&amp; haystack[i] != needle[j + 1]) { // 不匹配 j = next[j]; // j 寻找之前匹配的位置 } if (haystack[i] == needle[j + 1]) { // 匹配，j和i同时向后移动 j++; // i的增加在for循环里 } if (j == (needle.size() - 1) ) { // 文本串s里出现了模式串t return (i - needle.size() + 1); } } return -1; }}; 检测链表环并找到环入口在一个单链表中可能存在一个环，找到这个环的入口 检测一个环是很简单的（虽然我还是没想出来），只要一个慢指针一个快指针，慢指针每次走一格，快指针每次走两格，只要有换，快慢指针肯定会碰上 环有了，入口在哪里？ 首先要明确一点，fast和slow相遇时，slow还没有在环里走环一圈 可以这样理解： 如果fast和slow同时从环入口出发，那么他们下次相遇也是环入口，这个时候fast走了两圈，slow走了一圈 现在的情况是因为有了X，因此slow进来的时候，fast已经在环的某个位置了，那fast就不用超过slow一圈就能追上了，所以slow是走不满一圈的 那么，相遇时，slow走的距离就是，那么fast呢？fast在相遇时，比slow在环里多走了一圈或多圈，我们设为n，又因为fast的速度是slow的两倍，于是有 这个式子意味着如果我们让一个指针从头出发，一个指针从相遇处出发，那么他们相遇的地方就是入口节点 1234567891011121314151617public class Solution { public ListNode detectCycle(ListNode head) { ListNode fast = head, slow = head; while (true) { if (fast == null || fast.next == null) return null; fast = fast.next.next; slow = slow.next; if (fast == slow) break; } fast = head; while (slow != fast) { slow = slow.next; fast = fast.next; } return fast; }} 三数之和为0给定一个数组，找到其三数之和为0的所有组合，不能重复 排序 一个i从左向右遍历数组，压缩区间，left right分别在区间的两边，按双指针向中间靠拢，不断寻找令nums[left]+nums[right]==-nums[i]的组合即可 去重 i的去重很简单，如果遍历到和上一个一样的i直接继续下一个i即可 left和right应该在找到一个三元组后去重，参考：-3 -1 -1 4 4 注意应该直接在针对这个三元组的结果上去重，而不是傻乎乎的先加减left和right之后再去重 分析这两种写法 1234567ans.add(arr);do{ left++;}while(left&lt;right &amp;&amp; nums[left]==nums[left+1]);do{ right--;}while(left&lt;right &amp;&amp; nums[right]==nums[right-1]); 12345ans.add(arr);while(left&lt;right &amp;&amp; nums[left]==nums[left+1]){left++;}while(left&lt;right &amp;&amp; nums[right]==nums[right-1]){right--;}left++;right--; 对于输入[-2,0,1,1,2] 第一种写法在找到-2，0,2后直接++–，然后去重，导致-2,1，1被当做重复去掉了 第二种写法不会有这种情况 第一种写法（也就是我的想法）以为可以直接去取重复序列的最后一个值，殊不知这样会挤压另一个指针取到这个重复序列值的可能 第二种方法则总是取重复序列的第一个值，然后去重，这样不会挤压另一个指针的生存空间 想要把第一种方法改对？只需要将nums[left+1]和nums[right-1]改成nums[left-1]和nums[right+1]就能够总是取重复序列的第一个值了 1234567ans.add(arr);do{ left++;}while(left&lt;right &amp;&amp; nums[left]==nums[left-1]);do{ right--;}while(left&lt;right &amp;&amp; nums[right]==nums[right+1]); 翻转单链表（面试百度的时候问到了这个） 最基本的双指针用法，但是要把代码写得优雅精巧是一件很困难的事 1234567891011121314class Solution{ public ListNode reverse(ListNode head){ ListNode cur=head; ListNode prev=null; ListNode tmp=null; while(cur!=null){ tmp=cur.next; cur.next=prev; prev=cur; cur=tmp; } return prev; }}","tags":["leecode"],"categories":["算法"]},{"title":"移动互联网软件工程","path":"/2023/09/08/移动互联网软件工程/","content":"移动互联网软件工程Android开源 IOS闭源 HarmonyOSOpen Harmony Harmony 鸿蒙提供了Stage，其中WindowStage类似Activity，AbilityStage类似Service还提供了分布式软总线，相当于将不同的终端连接起来 系统采用分布式数据管理 一次开发多端部署，方舟编译器 Stage模型 UI ability 生命周期 UIAbility启动模式 单实例模式 标准实例模式 指定实例模式 Want类型 显示Want 隐式Want Stage多应用组件在运行时共享同一个虚拟机引擎 多HAP机制拆分成不同的HAP，供不同型号的设备下载 静态共享包 HAR 动态共享包 HSP语言渊源Js 由Mozilla创造 前端框架： React Vue Ts 由微软创造 ArkTs 由华为创造，增加了 基本UI描述 状态管理 动态构建UI元素 渲染控制 使用限制与扩展 测试用例改造stateDiagram 用例编写 --> 用例评审 用例评审 --> 用例执行 用例执行 --> 用例编写 用例执行 --> 人工测试 用例执行 --> 自动化测试 鸿蒙开发：案例讲解TO-DO List状态管理 ViewUI: UI渲染，一般指自定义组件的build方法和@Builder装饰的方法 需求 理想汽车：贴近场景的设计 Apple：一致性体验 符合战略的需求 涉众分析常见的问题 没有选定用户 选中所有用户 优先级评估 power interest 如果已经有人在领域做了，那就找垂直领域，找小的切入点 在领域内还可以细分市场 ArkTs运行时RN 前端javascrip Android bridge&#x2F;ios bridge 抛弃浏览器渲染，通过自己的DSL生成中间格式 Flutter自渲染，前面的都是对原生组件做映射 现代UI框架 widgets Render tree Layer tree Bitmap 云原生循环依赖循环依赖引发的核心问题在于一旦依赖环中的一个包对外宣告进行了修改，依赖它的包也得修改，这种修改通知会在依赖环上持续的传递 从单体到微服务 通过服务组件化 组件是一个独立可替换和独立升级的软件单元 。 You build it, you run it 去中心化治理 去中心化数据管理 每个服务可以基于自己的数据库 基础构建管道 为失效设计 应用程序要被设计为能够容忍服务失效 DevOps设计模式讲解经典组合、实现与集成classDiagram shop o-- taxCaculator pizzaShop --|> shop burgerShop --|> shop sameTax ..|> taxCaculator increaseTax ..|> taxCaculator 优点 动态配置Caculator 实现不同的shop 缺点 需要能抽象出taxCaculator caculator可能需要获得复杂的数据才能实现功能 抽象工厂核心思想：希望将对象的创建委托给工厂 优点： 客户端不需要了解工厂，他只需要持有一个抽象工厂的引用，在启动时正确的初始化抽象工厂为具体的工厂，然后把创建都交给工厂就行了，而不是不停地去指定不同的工厂 如果想要新增一套产品，只需要增加一个新的具体工厂和一组新的具体产品 缺点： 如果想要增加产品，需要修改包括抽象工厂的所有工厂，非常痛苦 桥接模式可以将这个类和那个类的功能通过桥接联系起来，灵活实现 架构应用架构 稳定性原则 一切以稳定为中心 架构尽可能简单清晰 不过度设计 解耦&#x2F;拆分 稳定部分与易变部分分离 核心业务与非核心业务分离 主流层与辅流程分离 应用与数据分离 服务与实现细节分离 抽象化 应用只依赖服务的抽象 数据库抽象化 服务器抽象化 松耦合 跨域调用异步化 非核心业务异步化 必须同步调用时，需要设置超时时间和任务队列长度 容错设计 服务自治 集群分布 机房灾配 服务设计 无状态 可复用 松耦合 可治理 远程访问服务RPC远程方法调用最初是希望就像调用本地方法一样调用远程服务器上的方法 进程间通信 管道 消息队列 socket 三个基本问题 如何表示数据 如何传递数据 如何表示方法 数据架构 统一数据视图 数据、应用分离：应用不直接访问数据库，而是通过服务访问 数据异构 读写分离 合理使用缓存 系统运行时原则 可监控 应用可回滚，功能可降级 系统部署原则 N+1：为确保故障多搭建一套系统 D-I-D：设计20倍容量，实现3倍容量，部署1.5倍的容量 支持灰度发布 虚拟化部署 业务子网 大型网站架构演化历程 一个服务器 服务器分离 使用缓存改善网站性能 CDN和反向代理","tags":["课程笔记"],"categories":["课程笔记","移动互联网软件工程"]},{"title":"服务端开发","path":"/2023/09/07/服务端开发/","content":"服务端开发Spring boot 开发框架 可以创建独立的Spring应用程序，并且基于其Maven或Gradle插件，可以创建可执行的JARs和WARs（不需要其他依赖直接就能跑） 内嵌Tomcat或Jetty等Serverlet容器（Web容器） 提供自动配置的starter项目对象模型以简化Maven配置（依赖集成） 尽可能自动配置Spring容器 提供准备好的特性 绝对没有代码生成 ObjectBeanComponentComponent更加面向业务 Bean更加抽象一点，是spring管理的一个基本单元 object面向对象语言中的对象 Jar 和 War 的区别Jar比较大，因为它能直接跑，War里面没有Tomcat，不能直接跑 Thymeleaf 模版解析器，用于生成动态的HTML页面 没有特别指定的版本号都用parent里面对应的版本号 @SpringBootApplication这个注解至少包括了三个注解类： @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan：Spring boot按照参数中给出的路径，针对特定的type，扫描类定义，在看到@Component注解时进行实例化 开发框架的分层Spring的衍生Springboot springcloud Junit测试用例 使用@Test 使用void进行修饰 assert，对预期结果的断定 开发期工具：Spring boot DevTools依赖注入Bean的生命周期应用上下文 AnnotationConfigApplicationContext AnnotationConfigWebApplicationContext ClassPathXmlApplicationContext（基于xml文件建立的应用上下文） 注解配置(Recommended)@Component但是有的类需要初始化属性，所以可以使用@Autowired(命令spring去上下文中寻找符合类型要求的对象，如果找到了并且只找到一个，那么直接注入，没找到直接失败，如果找到了多个对象也会报错 可以使用@Primary让Spring优先注入某类实例，也可以通过@Qualifier(cd【Bean的id】，这个id默认是当前类的名字，也可以通过@Component(Bean的id)来指定)来要求spring只寻找cd来注入) 这个注解可以加到属性上，也可以加到构造函数上 配置类 @Configuration 说明这是一个配置类 @ComponentScan 命令Spring去扫描当前类所在的包及自报加了@Component注解的类并实例化，也可以使用@ComponentScan(basePackages &#x3D; {“soudsystem”,”abc”,…})指定想扫描的包路径（这是类型不安全的，因为都是字符串）或是@ComponentScan(basePackageClasses&#x3D;CDplayer.class)让spring去指定的类所在的包下去搜索（这是类型安全的，但是面对代码重构是error pone的，为了处理，我们可以干脆在要指定的包下建立一个空接口） 通过注解配置建立上下文 123ApplicationContext ctx = new AnnotationConfigApplicationContent(CDplayerConfig.class);MediaPlayer player = ctx.getBean(Mediaplayer.class);player.play(); 在测试中使用 @ContextConfiguration(classes &#x3D; CDplayerConfig) System.getProperty(“line.separator”)可以获得当前系统的换行符 XML配置1234567891011121314&lt;beans xml:c=&quot;spring/schema/c&quot;&gt; &lt;bean id=&quot;compactDisc&quot; class =&quot;SoundSystem.Compact&quot; c:_0=&quot;使用c命名空间为第一个参数指定值&quot; c:_1-ref=&quot;compactDisc&quot;/&gt; &lt;bean id=&quot;cdPlayer&quot; class=&quot;soundsystem.CDPlayer&quot;&gt; &lt;constructor-arg ref=&quot;compactDisc&quot;/&gt; &lt;constructor-arg value=&quot;use value to assgin args&quot;/&gt; &lt;consttuctor-arg&gt; &lt;list&gt; &lt;value&gt;1&lt;/value&gt; &lt;value&gt;2&lt;/value&gt; &lt;/list&gt; &lt;/consttuctor-arg&gt; &lt;/bean&gt; &lt;bean id=&quot;compactDisc&quot; class =&quot;SoundSystem.Compact&quot; p:compactDisc-ref=&quot;通过p命名空间&quot;/&gt;&lt;/beans&gt; @ContextCOnfiguration(locations&#x3D;) javaconfig配置(实例化第三方库的时候用得到)1234567891011121314151617@Configurationpublic class CDPlayerConfig&#123; @Bean public CompactDisc compactDisc()&#123; return new SgtPeppers(); &#125; @Bean(name = &quot;player1&quot;) //这玩意儿效果和@Autowired一样 //当spring发现这里有一个参数时，它会像注解配置那样去找可能的实例 public CDplayer cdPlayer(CompactDisc cd)&#123; return new CDPlayer(cd); &#125; @Bean // 不指定默认name为方法的名字 public CDplayer cdPlayer2(CompactDisc cd)&#123; return new CDPlayer(compactDisc()); // spring并不会乖乖去调用compactDisc()，当它注意到上文的compactDisc()已经被@Bean实例化，它会拦截后面所有的的compactDisc()，并直接使用上下文中已有的compactDisc()实例填入 &#125;&#125; 混合配制123456@Configuration@Import(CDPlayerConfig.class)//这是configuration的根@ImportResource(一个xml文件)public class SoundSystemConfig()&#123; &#125; Bean的生命周期BeanNameAware要实现setBeanName 类似的还有ApplicationContextAware，可以在它的set方法里面获得丰富的信息 Java Faker一个专门构建测试假信息的工具 其他方法@Profiles根据指定的profile选择性的创建 @Conditional根据条件选择是否创建 @ScopedBeans@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE) 让spring不再拦截多实例创建 制定作用域Session 会话 为每个会话创建一个实例 Request 请求 为每个请求创建一个实例 面向切面的编程AOP目标是解决什么问题？ 分离横切关注点，将业务代码分离出来，避免对代码的侵入 减少耦合 AOP aspect Oreiented Programming 关注点 日志 安全 事务 缓存 可选 继承 委托 黑话 通知 advice：切面做什么以及何时（方法前？方法后？异常时） 切点pointcut：何处 切面aspect：通知和切点的结合 连接点join point:所有可以切的点：方法、字段修改、构造方法 引入introduction：引入新的行为和状态，但是不是新建子类，而是动态地新增方法 织入 weaving：将切面应用到目标对象 通知类型 @Before 将逻辑切入到方法调用前 @After …方法执行后 @AfterReturning @AfterThrowing @Around 四合一 1234567@Aspectpublic class Audience&#123; @Before(&quot;execution(* concert.Performance.perform(..))&quot;) //..意味着参数不限 public void silenceCellPhones()&#123; System.out.println(&quot;Silencing cell phone.&quot;) &#125;&#125; 配置类 @EnableAspectJAutoProxy 是否允许被切的对象创建代理 同时要实例化切片 可以这样定义一个pointCut来简化切面 1234567@PointCut(&quot;execution(* concert.Performance.perform(..))&quot;)public void performance()&#123;&#125;@Before(&quot;performance()&quot;)public void silence()&#123; ...&#125; around的使用 1234567891011@Around(&quot;performance()&quot;) public void watchPerformance(ProceedingJoinPoint joinPoint) &#123; try &#123; System.out.println(&quot;.Silencing cell phones&quot;); System.out.println(&quot;.Taking seats&quot;); joinPoint.proceed(); //around方法有更强的控制能力，比如让方法不被调用，多次被调用 System.out.println(&quot;.CLAP CLAP CLAP!!!&quot;); &#125; catch (Throwable e) &#123; System.out.println(&quot;.Demanding a refund&quot;); &#125; &#125; 12345@Around(&quot;@annotation(appendAnnotation)&quot;) //括号里是注解类这个参数的名字public String process(ProceedingJoinPoint joinPoint, Append appendAnnotation) throws Throwable &#123; String res = appendAnnotation.word() + &quot; &quot; + joinPoint.proceed() + &quot; &quot; + appendAnnotation.word(); return res;&#125; 切片是如何实现的？Spring通过将目标对象和切面一同打包实现一个代理对象，首先处理切面，再处理目标对象 AspectJ 切点指示器1@Pointcut(&quot;execution(* soundsystem.CompactDisc.playTrack(int))&quot;+&quot;&amp;&amp;args(trackNumber)&amp;&amp;within(soundsystem.*)$$bean(sgtPeppers)&quot;)//指定方法、获取参数（捕获目标方法的参数）、限定包路径、限定bean名称 通过切片扩展类的行为123456@Aspectpublic class EncoreableIntroducer &#123; @DeclareParents(value = &quot;concert.Performance+&quot;,//后面的+表示应用到所有实现了该接口的Bean defaultImpl = DefaultEncoreable.class) public static Encoreable encoreable;&#125; 1234@Beanpublic EncoreableIntroducer encoreableIntroducer() &#123; return new EncoreableIntroducer();&#125; 12345package concert;public interface Encoreable &#123; void performEncore();&#125; 12345678910111213package concert;public class DefaultEncoreable implements Encoreable &#123; public void performEncore() &#123; System.out.println(&quot;perform the encore!&quot;); &#125; @Override public String toString() &#123; return &quot;============DefaultEncoreable============&quot;; &#125;&#125; 12Encoreable concert2 = ctx.getBean(&quot;concert2&quot;, Encoreable.class);concert2.performEncore(); 横切关注点 日志 安全：比如用户权限的控制 事务：比如数据库事务 缓存：提升性能 在没有切片之前…委托（持有一个引用）、继承 织入时机运行期：使用代理对象，只支持方法级别的切入 MVC架构Web开发框架分层，请求是如何被处理的基本的层为 控制器层、业务逻辑层、数据访问层 请求发到基本单元Severlet Mapping组件根据url，将请求交给对应的控制器，同时解析参数 Controller拿到参数，校验后交给业务层 业务层进行业务处理，可能与数据访问层发生交互 业务层将处理结果交给Controller Controller将结果交给Serverlet Severlet寻找第三方渲染库，将数据和逻辑视图名交给之 第三方库渲染逻辑视图 model-view-controller 模型：存储内容 控制器：处理 视图：显示内容 适用于前后端不分离的开发场景 @Data注解没有data注解时，我们要为每个属性写get方法和set方法 加了data，lombok会帮助我们生成这些方法 lombok仅在编译时生效，我们可以在pom中设置exclude，发行版中不加入lombok包 Controller@RequestMapping(“&#x2F;design”)让控制器处理以design为前缀的url @Controller告诉spring这是controller，效果上和@component一样 @GetMappingget请求到这里处理 请求的类别 Get 获得资源 Post 创建资源 Put 更新资源 Delete 删除资源 Patch 1return &quot;design&quot;; 这里返回的字符串是一个逻辑视图名，spring在resource&#x2F;template中找到模版，塞入数据后（渲染）出页面 @SessionAttributes(“Taco”)指定Taco是一个Session级别的属性，一次会话包含多次请求 12345@PostMappingpublic String processTaco(@ModleAttribute TacoOrder tacoOrder)&#123; //让这个方法获得Model里的数据 return &quot;redirect:/orders/current&quot;;//返回一个重定向请求到浏览器&#125; @Slf4j定义一个log对象，让你打印log @Valid添加校验 校验表单输入 领域类添加校验规则 属性上方添加一些注解 123@NotNull@Size(min=1, message=&quot;You must choose at least 1 ingredient&quot;)private List&lt;Ingredient&gt; ingredients; 添加@Valid注解 1234@PostMapping public String processTaco( @Valid Taco taco, Errors errors, @ModelAttribute TacoOrder tacoOrder) 修改表单视图展示错误 WebConfig123456789@Configurationpublic class WebConfig implements WebMvcConfigurer &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(&quot;/&quot;).setViewName(&quot;home&quot;); &#125;&#125; Spring MVC获取参数的几种方式 form参数转成model，成员类型可能会用到Converter进行类型转换 路径参数 @Pathvariable 请求参数（查询参数）， json请求体，@RequestBody，会用到HttpMessageConverter消息转换器，RestAPI Spring MVC的请求映射注解可以放在类上，也可以放在方法上 @RequestMapping 可以再这个注解后面详细解释，是通用的 @GetMapping @PostMapping @PutMapping @DeleteMapping @PatchMapping Model和View的关系Model提供View的输入 Model属性会复制到Servlet Request属性中，给视图用于渲染页面 thymeleaf和spring mvc是解耦的 Spring MVC发现了thymeleaf，会自己帮你创建支持thymeleaf的bean 处理表单提交校验表单输入 javaBean Validation API spring-boot-starter-validation（Hibernate针对javaBean Validation API的实现） 领域类加校验规则 控制器中声明校验 修改表单视图展现校验错误 WebMVConfigurer可以做很多事 服务端数据库开发使用几大springboot数据库开发框架的基本流程JdbcTemplate 配置依赖 配置数据源 注入JdbcTemplate 为查询创建相应的Mapper 使用jdbcTemplate.update,query等执行操作 Spring dataJPA，比如Hibernate 配置依赖 配置Entity实体类 创建继承或实现CurdRepository接口的数据库接口 注入这个数据库 使用默认提供的方法就可以做到增删改查了 三种实现方式的区别和相同点 template和spring data都需要提供schema脚本，jpa不需要，根据java对象生成表结构 从实现来看，template需要我们自行实现接口，spring data和jpa在大多数情况下不用再实现 从领域对象来看，template领域对象不用加注解，而后两种需要 后两者都提供了Query，但JPA可以通过DSL语言实现灵活的query 关于id字段的处理，template需要主动获取新生成的id，第二种和第三种不用 spring data的持久化注解来自spring自行定义，JPA来自javax 数据库初始化的基本方式 schema.sql表创建,data.sql数据初始化 程序预加载：commandlinerunner接口，applicationrunner 基本继承的接口curdRepository 数据库开发中基于接口交互的好处 便于对数据库访问层和业务逻辑层的测试，可以使用Mock工具提供接口的实现 可以灵活的替换数据库的实现，而不用更改业务层代码 Spring为数据库访问提供了抽象的简化 1private JdbcTemplate jdbcTemplate; 这个类会被spring框架自动注入 SQLException 数据库连接中断 表不存在 SQL语法错误 … JdbcTemplate xml中添加jdbc依赖 在xml中指定数据库类型（MySQL、H2、Postgresql…） （H2）在resources里面写.sql文件 写@Repository 在业务层访问RepositoryJdbcOperations是JdbcTemplate实现的接口访问H2控制台1/h2-console 添加devtools访问 data-jdbcSpring Data项目 只是定义而不需实现接口(spring 来实现) 12345678import org.springframework.data.repository.CurdRepository;public interface IngredientRepository extends CrudRepository&lt;Ingredient, String&gt; &#123; //指明操作的对象和ID的类型 // 如果我想要添加一个新的查询方法,动作+By+字段，这是“领域特定语言” // 如果要更具体 @Query(&quot;Order o where o.deliveryCity = &#x27;New York&#x27;&quot;) //方法名就叫叭叭叭ba~ List&lt;TacoOrder&gt; findByDeliveryZip(String DeliveryZip);&#125; 定义数据类 1234567891011121314import lombok.Data;import lombok.;@Data@Table@AllArgsConstructor@NoArgsConstructor(access=AccessLevel.PRIVATE,force=true)public class Ingredient implements Persistable&lt;String&gt; &#123; @Id private String id; @NotNull private String name;&#125; 注意命名规范！java驼峰与建库脚本下划线对应 根路径下添加创建表的脚本 接口注入到业务层或控制器 如果你需要启动时插入数据… 在Application入口类中建立一个内部类 1234567@Beanpublic CommandLineRunner dataLoader(BoyRepository repo)&#123; return args -&gt; &#123; repo.deleteAll(); repo.save(new Boy()) &#125;&#125; 此方法调用的时机是所有Bean创建完成后，Application最后启动前 Spring Data JPA JPA：Java Persistence API 宗旨是为POJO提供持久化标准规范 JPQL是一种面向对象的查询语言（类似SQL） 依赖是data-jpa 步骤 接口和上面的是一模一样嘟 对应关系 123456789101112131415@Data@Entity //比table更厉害的注解，不要你写表结构，来自javax.persistense@AllArgsConstructor@NoArgsConstructorpublic class Ingredient&#123; @Id private String id; @Column(&quot;wow&quot;) @Size(min=5, message=&quot;lalala&quot;) private String cao; @OneToMany(cascade=CascadeType.ALL) //告诉spring表之间有关联,cascade意味着一旦order被删除，对应的Taco一起删除 private List&lt;Taco&gt; tacos = new ArrayList&lt;&gt;();&#125; 数据库初始化有三种方式 Data.sql schema.sql文本文件初始化 CommandLineRunner接口或ApplicationRunner接口 使用非关系型数据库添加依赖 1 使用mongoDB client（不推荐） 1234567891011try&#123; //创建时如果不提供url默认访问27017 MongoClinet mongoClient = MongoClient.create(); MongoDatabase mongoDatabase = mongoClient.getDatabase(&quot;test&quot;); MongoCollection&lt;Document&gt; collection = mongoDatabase.getCollection(&quot;mytable&quot;); collection.deleteMany(Filtrs.eq(&quot;name&quot;,&quot;lyl&quot;)); Document document = new Document(&quot;name&quot;,&quot;lyl&quot;).append(&quot;age&quot;,18).append(...); collection.insertOne(document); FindIterable&lt;Document&gt; collection = mongoDatabase.find(); MongoCursor&lt;Document&gt; mongoCurosr = &#125; JPA自动配置 （推荐） propertie 1spring.data.mongodb.uri=mongodb://localhost:27017/test 1public interface 12345678@Data@Documentpublic class TacaOrder&#123; @Id private String id; private List&lt;Taco&gt; Tacos; //Taco没有独立放在一个Collection里面，所以不用@Document，也不用@Id&#125; Nosql倾向于把能关联的数据都塞进去，这会造成严重的重复存储问题，这就引出一堆去除重复方法 MongoDB性能 10000条数据插入大概是10s Java Faker1234public void fack()&#123; Faker faker = new Facker(Locale.CHINA); String address = faker.addtess.streetAddress();&#125; 使用RedisRedis的主要用途是缓存，我们不那么关心它是否能持久化 存储的基本单位是key-value redis-server redis配置，redis.conf 默认端口号6379 redis-cli，客户端程序 redis启动后默认开16个数据库 插入key-value 12345678set myname lylget mynameset counter 100incr counterincrby counter 50exists counter //查询是否有这个keydel mynamekeys * //查看所有的key redis中可以给key设置生命时长 1expire counter 15 //15s后counter就寄了 key-value中value可以有不同类型，包括String（注意 前面的counter也是String，不过你还是可以加加减减的）, List 123rpush mylist 15 //往mylist里面（不存在新建）从右边加一个15lrange mylist 0 -1 //获得所有的元素rtop mylist //从右边弹出一个元素 Hash类型 123hmset user name lyl age 10hgetall userhget user name set 12sadd myset 1 2 3smembers myset 删除数据库 12flushdb //删掉当前数据库flushall //删掉所有数据库 Jedis(早期)与Lettuce(现在) 它们都是供spring连接到redis的客户端 RedisConnectionFactory接口，JedisConnectionFactory Application 1234567@Bean// String对应key，Product可以简单理解为value（但严格并不是）public RedisTemplate&lt;String,Product&gt; redisTemplate(RedisConnectFactory cf)&#123; RedisTemplate&lt;String, Product&gt; redis = new RedisTemplate&lt;&gt;(); redis.setConnectionFactory(cf); return redis;&#125; properties 12spring.redis.host=localhostspring.redis.port=... 1234567Product product = new Product();product.setName(&quot;bababa&quot;);product.setSku(&quot;978888&quot;)redisTemplate.opsForVlaue().set(product.getSku(),product); //这最后存的是String类型，相当于做了序列化，也就是java提供的Serializable，字节化也就能持久化了//这个时候去redis里面看key的内容，只会看到一坨意义不明的东西，这是序列化后的字节序列，这是JDK自己的方式//通过private static final long serialVersionUID = 1L; 1234567891011121314151617redisTemplate.opsForList().rightPush(&quot;cart&quot;,product1);redisTemplate.opsForList().rightPush(&quot;cart&quot;,product2);Product first = redisTemplate.leftPop(&quot;cart&quot;);List&lt;Product&gt; products = redisTemplate.opForList().range(&quot;cart&quot;,2,12);redisTemplate.opForSet();//如果懒得老是指定&quot;cart&quot;这样的keyBoudListOperations&lt;String,Product&gt; cart = redisTemplate.boundListOps(&quot;cart&quot;);//其实大家都喜欢用json格式串而不是jdk序列化redis.setKeySerializer(new StringRedisSerializer());redis.setValueSerializer(new Jackson2JsonRedisSerializer&lt;Product&gt;(Product.class));//如果你想让redis忠实地返回数据库里的东西stringRedisTemplate = new StringRedisTemplate(cf); 目前用到的依赖Spring Security权限控制原理 filter请求处理之前会由一系列filter进行拦截处理 开发实际操作中的步骤 实现一个接口：UserDetailService 提供密码加解器 提供一个登录页面 使用y继承自HttpSecurity的SecurityFilterChain或WebSecurityAdapter进行权限处理 框架帮我做的 登录控制器的实现(Get,Post) 请求重定向到用户登录页面 通过Filter对设定的权限进行控制 用户信息的存储 内存用户存储 JDBC数据库 LDAP目录数据库 权限分类创建自定义登录页 Basic认证方法级的权限控制@PreAuthorize(“hasRolr(‘USER’)”) 实现就是基于AOP jaas：jdk用户授权框架 添加依赖:spring-boot-starter-security 在代码中获得当前登录的用户 注入principle对象 或通过@AuthenticationPrincipal获取 通过安全上下文获取 密码转换器 NoPasswordEncoder CSDN倾情奉献 BCryptPasswordEncoder … 1 配置spring-security 使用filter-chain 123456789101112131415161718192021@Beanpublic SecurityFilterChain filterChain(HttpSecurity http) throws Exception&#123; // 用户必须归属于USER角色才能访问design和orders，定义角色在User.java的覆写的getAuthorites中 return http.authorizedRequest() .mvmatchers(&quot;/design&quot;,&quot;/orders&quot;).hasRole(&quot;USER&quot;) .anyRequest().permitAll() //注意这一条一定要放在最后，就像ACL的定义一样 .and() .formLogin() .loginPage(&quot;/login&quot;) .userNameParameter(&quot;user&quot;) .passwordParameter(&quot;pwd&quot;) .and() .logout() .logoutSuccessfulUrl(&quot;/&quot;) .and() .csrf() // 配置csrf（跨站请求伪造） &#125; 使用webSecurityConfigAdapter 123456public auth.inMemoryAuthentation() .withUser(&quot;lyl&quot;) .password(&quot;***&quot;) . 还可以对于业务层代码进行控制 1234@PreAuthorize(&quot;hasRole(&#x27;ADMIN&#x27;)&quot;) //执行前检查public void deleteAllOrders()&#123; orderRepository.deleteAll();&#125; 背后的实现原理：就是面向切面编程，使用AOP技术 CSRF 跨站请求伪造攻击者利用用户通过验证的session id或cookie对服务器进行攻击，譬如site B提供一个表单并让浏览器提交以攻击 site A，为了避免这种情况，site A提供一个csrf字段进行校验，如果一个表单无法提供_csrf字段，那么就认为不满足csrf 为用户定义角色 12345// 在声明实现UserDetails的数据类中覆写@Override public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() &#123; return Arrays.asList(new SimpleGrantedAuthority(&quot;ROLE_USER&quot;)); &#125; 与视图连接 1234567891011121314&lt;form method=&quot;POST&quot; th:action=&quot;@&#123;/login&#125;&quot; id=&quot;loginForm&quot;&gt;&lt;!-- end::thAction[] --&gt; &lt;label for=&quot;username&quot;&gt;Username: &lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;username&quot; id=&quot;username&quot; /&gt;&lt;br/&gt; &lt;label for=&quot;password&quot;&gt;Password: &lt;/label&gt; &lt;input type=&quot;password&quot; name=&quot;password&quot; id=&quot;password&quot; /&gt;&lt;br/&gt; &lt;input type=&quot;submit&quot; value=&quot;Login&quot;/&gt;&lt;/form&gt;&lt;form method=&quot;POST&quot; th:action=&quot;@&#123;/logout&#125;&quot; id=&quot;logoutForm&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;Logout&quot;/&gt;&lt;/form&gt; 小寄巧：调整日志级别application.properties里面 1loggin.level.org.springframework.security=debug 解决csrf问题记得在前端里面加上相应前端处理csrf的功能，比如thymeleaf就是th:action&#x3D;”@{&#x2F;add}” 1&lt;form method=&quot;POST&quot; th:action=&quot;@&#123;/add&#125;&quot; th:object=&quot;$&#123;contact&#125;&quot;&gt; 用户认证Security框架利用cookie验证用户,首次登录后服务端将提供set-cookie字段，这个字段将让浏览器在之后的请求时提供cookie，cookie中有session id，服务端用cookie和后端匹配后就可以保证登陆了 用户授权在开发中使用spring security 实现一个接口：UserDetailService 提供PasswordEncoder 提供一个登录页面（如果不实现就会得到一个丑陋的页面） 调用HttpSecurity进行权限测试（可以通过继承webSecurityConfigurerAdapter，也可以通过bean FilterChain） spring security帮我们做了什么？ 实现用户登录控制器 请求重定向到用户登录页面 通过Filter对设定的权限进行控制 用户信息存储 内存用户存储 JDBC用户存储 LDAP用户存储（轻量级目录数据库） HTTP Basic认证，提交请求的同时同步提供用户名密码，测试的时候很方便可以让客户端在请求时带上一个Authorization请求头，带上加密的base64密码和用户名，这样服务端就不会重定向到登录页面了 启用basic 12.and() .httpBasic() basic64不能用来加密，它很容易就会被破解，采用basic64为了将特殊字符转换成固定的64个字符，保证浏览器和后端可以兼容 如果想要获得当前用户信息通过注入principle对象获取 12345@ModelAttribute(name=&quot;user&quot;)public User user(Principal principal)&#123; String username=principal.getName(); User user=userRepo.findByUsername(username);&#125; 想获得当前登录的用户对象 1234@GetMapping(&quot;/current&quot;)pubblic ...(@AuthentationPrincipal User user)&#123; &#125; 上下文获取 12SecurityContextHolder.getContext().getAuthentication();User user = (User)authentication.getPrincipal(); 配置属性属性来源途径一：application.yml application.properties1server.port=8090 yaml 对象、键值对，使用冒号 123456animal: petshash: &#123;name: steve, foo: bar&#125;animal: [Dog, cat]- Cat- Dog- Goldfish 途径二：命令行参数1java -jar ... --server.port=8090 途径三：java虚拟机参数1java -Dserver.port=8081 -jar ... 途径四：操作系统环境变量12set SERVER_PORT=8082 #windowsexport SERVER_PORT=8082 #Linux 环境变量不支持’.’，所以用’_’，这样比较适合不同环境不同配置 配置数据源123456spring:\tdatasource: driverClassName: &quot;org.h2.Driver&quot; url: &quot;jdbc:h2:mem:pornhub&quot; username: sakiary password: 1788 Keytool keytool是jdk自带的密钥库管理工具，位于%JAVA_HOME%\\bin... 1keytool -genkey -alias lyl -keyalg RSA -storetype PKCS12 -storepass letmein -keystore mykeys.p12 数字签名根据文档内容生成指纹，这个指纹在不考虑极小概率的碰撞下可以标识这个文档，可以用于防止篡改和验证身份 配置日志1234logging:\tlevel: root: WARN org.springframework.security: DEBUG 自定义属性的使用四个方案： 通过@ConfigurerationPorperties(prefix&#x3D;’’) 通过@Value @Value(“${com.sam.desc}”) 通过环境变量 通过程序参数 12345678//记得注入props@GetMappingpublic String ordersForUser( @Authentication User user, Model model)&#123; Pageable pageable = Pageable.of(0,props.getPageSize()); //将数据分成n页，获得第0页的数据&#125; yaml中定义 12taco:\torders: 22 12345678910@Component@ConfigurationProperties(prefix=&quot;toca.orders&quot;)@Data@Validatedpublic class OrderProps&#123; @Min(value=5, message=&quot;must be between 5 and 25&quot;) @Max(value=25, message=&quot;...&quot;) private int pageSize = 20;&#125; 在属性文件中定义相对复杂的数据结构 key-value结构 12345678910111213discount:\tcodes: a: 10 b: 10 c: 10 boys:\tnames: - Joy - Bob - Harry - Peter - Jim 激活哪一个application.yml呢？ 激活profile假设有两个 application-ut.yml application-st.yml profile名分别是ut、st 环境变量激活：spring_profiles_active&#x3D;st 命令行参数：java -jar … –spring.profile.active&#x3D;st JVM系统属性：java -Dspring.profiles.active&#x3D;prod -jar … 使用注解创建@Profile 123456@Profile(&quot;!st&quot;) //不是st才生效,也可以对Bean生效@Configurationpublic class DevelopmentConfig &#123; @Bean public commandLineRunner&#125; Actuator暴露各种各样的端点（RESTapi url），要暴露多一些的话要include: “*” 提供获取当前程序信息的丰富的REASTapi 常用的一些端点 &#x2F;actuator &#x2F;actuator&#x2F;configprops &#x2F;actuator&#x2F;health &#x2F;actuator&#x2F;beans 分布式系统的配置数据来源REST API开发ReST原则 Representation State Transfer 资源 网络上的一个实体，一般用url标识 表现层 Json Xml Html 状态转移 服务端-客户端 四个常用方法Get Post Put Delete @RestController（以及produces参数） @ResponeBody @RequestBody状态码 1xx：继续发啊 2xx：成功 3xx：重定向 4xx：非法 5xx：服务端寄了 接口设计 使用合适的Http动词 使用url来传达意义 使用json作为请求和返回的格式 使用状态码来传达结果含义 前端开发基础 HTML,CSS,JavaScript Node.js是一个Javascript运行环境，让javascript可以开发后端 NPM 包管理工具 最著名的框架：Vue与React 前端开发常用架构MVVM 单文件组件：.vue 模版、逻辑、样式 RESTRepresentation State Transfer 表现层状态转移，资源从服务端到客户端是一种转移，从客户端到服务端也是一种转移 如果一个架构符合Rest原则，则成为RESTful架构 spring多模块开发 根模块应当依赖子模块，构建时，spring从根模块开始分析模块间的依赖，最终从最基础的模块向根模块自下向上构建 开发一个RestController 123456789101112131415161718192021222324252627282930313233343536@RestController //将通过ResponseBody将返回值作为json格式串返回给客户端@RequestMapping(path=&quot;/api/tacos&quot;,produces=&#123;&quot;application/json&quot;&#125;)//告诉spring可以接受accept值为*/json的请求头@CrossOrigin(origins=&quot;http://tacacloud:8080&quot;)public class TacaController&#123; private TacoRepository tacoRepo; public TacoController(TacoRepository tocaRepo)&#123; this.tacoRepo = tacoRepo; &#125; @GetMapping(params=&quot;recent&quot;) //当请求中有recent参数时落到这个方法 //spring借助了第三方包进行了java对象到json的转换 //也可以用recentTacos(@RequestParam(value=&quot;recent&quot;) int recent) //路径参数可以用@PathVariable public Iterable&lt;Taco&gt; recentTacos()&#123; PageRuquest page=PageRequest.of( 0,12,sort.by(...)); return tacoRepo.findAll(page).getContent(); &#125; @PostMapping(comsumes=&quot;applications/json&quot;) @ResponseStatus(HttpStatus.CREATED) // RequestBody 告诉spring将请求体转为 Taco对象 public Taco postTaco(@RequestBody Taco taco)&#123; return tocaRepo.save(taco); &#125; @PutMapping(path=&quot;/&#123;orderId&#125;&quot;, comsumes=&quot;application/json&quot;) public TacoOrder putOrder(@PathVariable(&quot;orderId&quot;) Long orderId, @RequestBody TacoOrder order)&#123; oder.setId(); tacoRepo.save(); &#125; @PatchOrder() @DeletMapping()&#125; Http接口设计（必考）看ppt Spring Starter Rest添加依赖 1 设置路径 1234spring:\tdata: rest: base-path: /data-api 还可以指定资源的名字 1@RestResource(rel=&quot;tacos&quot;, path=&quot;tacos&quot;) 请求 http://tacacloud:8080/data-api/tacos?size=15&amp;page=2&amp;sort=createdAtdesc 客户端如何调用RestApi 使用restTemplate 12345678public Ingredient getIngredientById(String ingredient)&#123; return rest.getForObject(&quot;http&quot;,Ingredient.class, IngredientId);&#125;public Ingredient getIngredientById2(String ingredient)&#123; ResponseEntity&lt;Ingredient&gt; resEntity = rest.getForEntity(&quot;http&quot;,Ingredient.class, IngredientId); //可以获得请求头部 logo.info(resEntity.getHead().getAccpt());&#125; 使用Feign调用REST API 123&lt;dependency&gt; &lt;/dependency&gt; 123456789@FeignClient(&quot;organizationservice&quot;)public interface OrganizationFeginClient&#123;\t@RequestMapping( methed = RequestMethod.GET, value = &quot;/home&quot;, consumes = &quot;application/json&quot; ) ...&#125; @RequestMapping用于请求映射 响应头和响应体 状态行 状态码：1已接收 2成功 3重定向 4有非法 5服务寄 分布式环境下RESTapi的权限控制-OAuth2OAuth2的过程 OAuth2的图很可能考为什么客户端要先拿到code，再用code去请求token？添加依赖 另外三种授权模式 隐式授权：授权服务器返回的不是Code，而是Token 用户凭证授权：直接用用户凭证向授权服务器索要令牌，而不是要用户登录 客户端授权：基于客户端特定的令牌授权 Auth服务器auth服务器和客户端都会有相同的redirect url配置，auth服务器的url是用来校验的，如果不一样，auth服务器会认为客户端要求的redirect url是恶意地址 资源服务器客户端Security配置 1 在获得一个token后，客户端通过拦截器在每个请求上加上token 消息中间件 ActiveMQ、RabbitMQ同步与异步消息中间件 消息代理，作为消息接收的第三方，在生产者和消费者之间，这样两边都不必关心对方了 实现生产者和消费者的解耦 常见的消息中间件 ActiveMQ RabbitMQ kafka Postman &#x3D;&gt; Taco Cloud &#x3D;&gt; 消息中间件 &#x3D;&gt; Kitchen JMSjava消息服务，定义了java使用消息代理的通用API spring有支持JMS的模版JmsTemplate 重要概念 connectionfactory：到消息服务器的连接池 connection session destination message 消息的序列化和反序列化：消息转换器jackson2转为json最常用 两种接受消息的模式：拉取和推送Pull模式：消费者主动向消息中间件拉取消息 (TacoOrder) JmsTemplate.receiveAndConvert(&quot;tacocloud.order.queue&quot;); Push消息中间件主动将消息推送给消费者 @JmsListener(destination = &quot;tacocloud.order.queue&quot;) public void receiveOrder(TacoOrder order) &#123; ui.displayOrder(order); &#125; RabbitMQ创建交换机和队列 重要概念 ConnectionFactory Connection Channel Exchange Queue Routing Key Binding Key ActiveMQ Artemis支持协议 JMS AMQP 也是RabbitMQ支持的协议 MQTT（物联网常用） 支持Native内存模式 与 JVM模式 分布式架构，消息持久化 生产端 123public static void main(String[] args)&#123; &#125; 消费端 1234public static void main(String[] args)&#123; ConnectionFactory connectionFactory = new ActiveMQConnectionFavtory(BROKE_URL,USERNAME); &#125; Taco Cloud应用添加发消息功能生产侧1public interface 获取第三方jar包源码：mvn dependency:sources 想把代码文档翻译的话就用Translation 插件 1234567891011@Servicepublic class JmsOrderMessaging&#123; @AutoWired public JmsOrderMessaging(JmsTemplate jms)&#123; this.jms=jms; &#125; @Override public void sendOrder(TacoOrder order)&#123; jms.convertAndSend(&quot;tacocloud.order.queue&quot;, order, this::addOrderSource); &#125;&#125; converter 1234567891011@Beanpublic MappingJakson2MessageConverter messageCoverter()&#123; MappingJakson2MessageConveter messageConverter = new MappingJacksonConverter(); // 告诉消费者把数据转成哪个类 messageConverter.setTypeIdPropertyName(); messageConverter.setTypeIdProperty(&quot;_typeid&quot;); Map&lt;String,Class&lt;?&gt;&gt; typeIdMappings = new HashMap(String, Class&lt;?&gt;); ...&#125; 消费侧取消息有两种方式：主动去哪或者artemis推送给你 12345678910@Componentpublic class JmsOrderReceiver(JmsTemplate jms)&#123; private JmsTemplate jmsTemplate; @AutoWired public JmsOrderReceiver(JmsTemplate jms)&#123; this.jmsTemplate=jms; &#125; @Override public receiveMessage&#125; RabbitMQ ConnectionFactory Connection Channel Exchange: Default Direct Topic Fanout Headers DeadLetter Exchange根据Routing Key和Binding Key将消息分发到不同的Queue Direct exchange根据key发送 Fanout exchange直接将消息广播给所有连接到它的Queue Queue Routing Key Sender给消息指定Routing key Binding Key 每个Queue有Binding key Binding key是可以用通配符的 依赖 1&lt;artifactid&gt;spring-boot-starter-amqp&lt;/artifactid&gt; 发送 12345public void sendOrder(TacaOrder order)&#123; rabbit.convertAndSend(&quot;tacocloud.order.queue&quot;,order,); @Override public sendOrder()&#125; 消费方只需要关心队列的名字，什么key，exchange都是发送方才关心的事 AMQP是一个消息协议Spring Integration集成流 integration flow集成流组件要重点了解 网关集成流配置 XML配置 转换器进来的内容可以和出来的内容不一样 路由器Adapter切分器一个消息分成多个消息 服务激活器消息进来后调用一个服务进行处理 使用MessageHandler会将消息消费掉 使用GenericHandler处理完消息后还会把消息丢到目标channel去 转换器和服务激活器的区别？处理过程上二者没有区别，但是从业务上说，Transformer是为了对消息进行转换，服务激活器则是为了激活另一个服务（比如做一次存储，掉一个外部服务等等） 网关除了单向还有双向网关 12@Component@MessagingGateway(defaultRequestChannel) 通道适配器反应式编程反应式编程解决的问题反应式编程面向IO密集型场景， IO非常明显的一个特点就是会出现等待，当IO密集时，往往线程也很多，线程之间的切换需要比较大的开销，如果CPU要管理大量的线程，自然速度就会很慢，因为大量的时间都被用于线程的切换 为了解决这种问题，我们引入事件轮询机制，将原来的为每一个客户端提供服务的线程释放，现在客户端都统一通过发送request请求来加入一个事件队列，一个线程轮询事件队列来不断地处理 反应式编程是消费方驱动的，没有收到request，publisher是不会没事找事的 两种编程模式 命令式 反应式 Reactor和java默认stream的区别默认的是同步的，其实只是一种用函数来迭代处理集合的方式 webflux启用基于响应式编程的web应用程序的开发，提供类似Spring MVC的编程模型 反应式流规范规定的四个接口这里非常重要 publisher：发布消息 processor：加工传递消息 subscriber：订阅消息 subscription：协调publisher和subscriber Subscriber注意b.subscribe(a)是a订阅b 123456789101112@Override public void onSubscribe(Flow.Subscription subscription)&#123; this.subscription=subscribtion; this.subscription.request(1);&#125;// 收到一条消息以后做什么@Overridepublic void onNext(T item)&#123; consumedElements.add(item); this.subscription.request(1);&#125; PublisherSubscription回压 四类操作：创建、组合、 reactor反应式流图Flux：包含0到N个元素的异步序列 Mono：包含0或者1个元素的异步序列正常的包含元素的 消息：序列结束的消息嗯序列出错的消息 操作符：对流上元素的操作 Flux的合并 merge zip（默认合并成元组，也可以合并成指定类型） first 只取首先产生消息的流 flatMap可以将一个流又转换成一个新的流，比如从一个Flux转为一个Mono（这样做可以让Mono跑在不同的线程里，形成多线程），可以用.subscribeOn(Schedulers.parallel())让流并行的跑 flatmap可以扁平化流 schedulers还有 immediate single parallel map和flatmap的区别：（很重要） Spring WebFlux启用基于响应式编程的Web应用程序的开发，提供类似于Spring MVC的编程模型 目前讲的三类消息： 反应式编程和Integration中的消息：在java虚拟机内，所以不用序列化 RabbitMQ等消息中间件的消息要在外部传输，需要序列化 Spring MVC和Spring WebFlux共性与不同 MVC底层是Servlet，基于Servlet API WebFlux底层是Netty，基于Reactive HTTP WebFlux通过Router Function实现请求处理 block和blocklast会阻塞调用它们的线程直到拿到结果，用subscribe的话结果可能就拿不到了 Repositoryreactive.ReactiveCrudRepositoy 基于函数式编程的请求处理 使用函数式编程风格定义endpoints 两个基本组件HandlerFunction RouterFunction webclient: 对应resTemplate 12345@Beanpublic RouterFunction&lt;?&gt;()&#123; return route(GET(&quot;/hello&quot;), request -&gt; ok().body(just(&quot;Hello World&quot;), String.class)) .andRoute(GET(&quot;/bye&quot;).and(accept(MediaType.APPLICATION_JSON)), greetingHandler::hello);&#125; 反应式编程测试webTestClient 1webTestClient.get().uri(...).accept(MediaType.APPLICATION_JSON).exchange().expectStatus().isOk().expectHeader().contentType(MediaType.APPLICATION_JSON).expectBody(Greeting.Class) docker常用命令docker镜像构建与服务编排Dockerfile1docker build -t mysite:latest . 其中.是构建上下文 编写dockerfile之最佳实践.dockerignore: 拷贝文件时不要拷贝这些文件 容器只运行单个应用 多个run指令合并为一个，不然你会整出一堆层来 基础镜像标签不要用latest，不然可能出现兼容问题 每个run指令执行后立刻删除多余文件，不然即使下一层删除也仅仅只是本层不可见而已 采用精简版本的镜像，比如Buster、Alpine 设置WORKDIR和CMD，不然它会重用基础镜像的CMD，还可以采用EntryPoint结合CMD来灵活的决定运行哪一个分支 合理的调整指令的顺序，改动少的要放到前面，这样可以充分利用缓存 添加HEALTHCHECK，比使用–restart always更厉害，可以让docker daemon在一些条件下重启容器 12HEALTHCHECK CMD curl --fail http://localhost:$APP_PORT || exit 1# 让daemon定时访问指定url，如果失败返回1，此时daemon会重启容器 Docker Composedocker-compose.yml 希望指定部署哪些服务 使用缩进表示层级关系","tags":["课程笔记"],"categories":["课程笔记","服务端开发"]},{"title":"软件测试","path":"/2023/09/07/软件测试/","content":"软件测试 源代码 移动应用 智能软件 方向survey 20% 另一个方向实现工具 30% 期末考试 40% 课堂报告 5% 课堂小测试 5% 课后小测试 5% 自动化是软件测试的一个梦想 什么是bugFault：静态的，就是写错了 Error：跑的时候出错了，或者跑的时候产生的不正确状态 Failure：跑出来的结果是错的 测试用例 execution：运行到出错的代码 infection：触发出错误 propagation：错误传播到输出 bug有空间聚集的趋势 测试的局限性 输入空间庞大 实现逻辑复杂 测试预言未知 随机测试 测试执行次数够多 测试数据随机生成 概率低的偶然现象发生 常见bug 断言失败 异常崩溃 无效输入 错误输出 模糊测试本质上就是带反馈的随机测试，基于bug的聚集性 经典测试技术 变异测试 把程序改错，然后拿测试用例来试，如果程序出错了，那么说明测试用例是有错误检测能力的，如果用例仍然被通过了，这意味着测试用例是很弱的 执行代价非常高，如何高效执行编译测试是企业面临的一大问题 蜕变测试 多次执行目标程序时，输入输出之间期望遵循的关系，比如sin函数应该呈现出2π周期性 差分测试 将同一测试用例1运行到一系列相似功能的应用中观察执行差异来检测bug 自动化测试自动化测试脚本修复程序修复mindmap id(自动化测试) 自动化测试脚本修复 程序修复 测试用例推荐 基于互联网群体智能的软件测试 自动化测试发展路线stateDiagram 确定步骤的自动化 --&gt; 非确定步骤的自动化 非确定步骤的自动化 --&gt; 具有学习能力的自动化 发展热点之智能软件测试有时候删除神经网络的一部分反而会提高了系统的准确度 常用测试方式边界值测试训练数据的偏见会带来模型的偏见变异测试变异测试背景正向使用：修复程序的错误，产生新的测试用例 反向使用：产生错误的程序片段（变异测试的主要部分），生成恶意测试用例 方向控制：引导&amp;反馈 关心的问题 如何编写能够暴露缺陷的测试用例如何引导测试 如何评估测试套件的质量如何评估测试 变异测试的产生 模拟缺陷，量化缺陷检测能力，扮演测试有效性的指示器 模拟：变异产生错误版本 量化 研究现状广泛关注（赢赢赢） 变异分析黑话： 自动化生成人工缺陷：自动化变异源程序进行分析 变异体：语义变体，语法上语义上与源程序都不相同 变异算子：变异：程序变换规则 变异得分：变异测试对测试套件错误能力检测的量化 变异体的杀死与存活 缺陷传播模型：PIE（Execution，Infection，Propagation），RIPR（Reachability，Infection，Propagation，Revealability） 杀死条件： weak firm strong 变异体的分类 有效变异体 无效变异体 夭折变异体 等价变异体：和源程序语义相同 重复变异体：两个变异体语义相同 蕴含变异体：所有能杀死A的，都能杀死B 变异算子： 一系列语法变换规则 变异的依据 基本形式： 源代码变换 字节码变换 元变异 变异测试为什么有效？ 假设1：缺陷是简单的，可模拟的 假设2：缺陷可叠加 假设3：缺陷检测有效性 变异测试过程stateDiagram 变异体筛选、创建 --&gt; 去除重复和等价的变异体 去除重复和等价的变异体 --&gt; 生成测试输入 生成测试输入 --&gt; 执行变异体 执行变异体 --&gt; 计算变异得分 计算变异得分 --&gt; 优化、排序 优化、排序 --&gt; 覆盖阈值是否达到 覆盖阈值是否达到 --&gt; 测试套件是正确的吗: yes 覆盖阈值是否达到 --&gt; 生成测试输入: no 测试套件是正确的吗 --&gt; 结束: yes 测试套件是正确的吗 --&gt; fix测试套件: no fix测试套件 --&gt; 变异体筛选、创建 变异体筛选、约简变异算子定义设计原则：变异算子定义 如何有效设计变异算子： 根据编程语言 根据语言设计原则 根据应用场景 根据bug类型 约减策略： 随机选取 基于类型 基于分部 变异体生成 将选中的变异体实例化 基本方式：每个变体构建一个单独的源文件 核心：程序模式 研究方向：怎么把算子生成过程的开销减少 元变异，基于中间表示的变异体生成，热替换（直接在运行时生成变异体） 元变异 核心：程序模式 目的：减少生成变异体时所需的编译次数 基于中间表示 避免编译 直接操作中间目标：比如操作java字节码，.NET和LLVM中间表示 变异体优化 基本形式：通过静态分析的形式，识别并移除有问题的变异体 识别等价变异体，识别冗余变异体 变异体的执行变异测试中最昂贵的部分 研究内容： 计算变异得分：研究集中在变异杀死的条件（对于确定性系统，对于非确定性系统）、测试预言的条件（预言怎样搞出更好的的测试套件） 计算变异体矩阵：注意如果测试套件中有一个测试用例把变异体杀了，就不用再往下走了，由此可以有一些优化策略比如：改变测试顺序、匹配测试用例与变异体、避免执行必定存活的变异体、限定变异体的执行时间 变异测试的应用 评估作用 引导作用：利用变异测试 传统应用:应用于确定性系统 测试生成 预言生成 测试优化 Debug引导 变异&amp;AI：应用于非确定性系统 用例与预言生成 基于搜索的软件测试+变异分析 SBST，将软件测试过程转化为搜索问题，利用启发式算法 变异引导的单元测试及预言生成 变异辅助debug 利用变异自动为有缺陷程序推荐补丁 缺陷定位技术： 抽象测试轨迹，计算可疑度 自动修复技术 根据一定的语法规则转换缺陷程序为正确版本 挑战： AI测试TCP通过变异分析进行DNN测试输入排序 变异分析+测试排序+AI测试 TCP for DNN：谁应当最先被打标签 MA for DNN：模型的变异、输入的变异 核心思路：越能杀的测试优先级越高 模糊测试模糊测试架构 工具：模糊器 目标：待测程序 循环：执行程序崩溃分派 三个组件 stateDiagram direction LR Fuzzer --&gt; ExecuteProgram: Test inputs ExecuteProgram --&gt; PUT PUT --&gt; CrashTraige: Execution result CrashTraige --&gt; Fuzzer CrashTraige --&gt; Crashes 黑话 模糊是指从输入空间采样得到的输入来执行待测工具的过程，代表着测试人员针对待测程序定义的预期输入 模糊测试是一种应用模糊过程来检测 模糊器：一组用于实现 缺陷语言：确定一次给定执行是否违反正确性策略的程序 模糊测试家族 AFL（C/C++） LibFuzzer(C/C++)：一个基于LLVM的工具 JQF(Java)：AFL搬到了java上 其他(Rust（强化版c）,Python等) 模糊测试分类根据组件核心或技术贡献进行分类 按照采用的运行时信息：黑盒（很多嵌入式系统的设置）、灰盒（看一部分信息，比如覆盖率）、白盒（强力的程序分析手段融入到程序中） 按照输入生成的策略：基于变异的，基于文法的 按照引导过程：启发式算法、梯度下降 按照测试目标：定向、非定向、某一类缺陷 按照应用领域：网络协议、Compiler、DNN、IoT、内核 按照优化角度：种子调度、变异策略、能量调度、过程建模 黑盒模糊测试常用于IoT 引导方式：利用输入格式或输出状态引导测试执行 优点：不用插桩效率高，但是引导不好 白盒模糊测试使用混合执行、污点分析等比较昂贵的分析技术 引导方式：利用详细的程序分析结果引导测试执行 优点：反馈更加有效，但是效率不高、适配性差 灰盒模糊测试最流行 轻量级插桩进行监控 利用得到的部分信息引导测试 代表工作：AFL、AFLGo、EcoFuzz、Zest、BeDivFuzz 基于变异的模糊测试本质：将种子输入转换成bit串，对比特串进行变换 优点：可拓展性强，易于泛化 缺点：容易破坏输入的结构、产生无效输入；生成的大部分输入都无法通过语法检查 AFL变异算子 bitflip 翻转 arith 加减小整数 interest 翻转有趣的字节位 havoc 总结上面的 spilce 随机拼接两个种子输入 SLF思想：分析程序中的语义检查、识别比特串中与影响语义检查的域、根据两者之间的关系制定变异策略 基于生成的模糊测试基于一定的文法规则/结构信息 利用给定的、或者挖掘/学习得到的文法规则，来构建能够通过（语法）检查的结构化输入 优点：容易生成合法、有效输入，适用于对输入结构性要求较高的场景如编译器测试 缺点：需要人工赋予一定的领域知识 Inputs from Hell挖掘已有的测试输入，得到现有的测试输入分布，根据该分布进行输入生成以得到预期的测试输入 可以生成相似输入或者相反输入 按引导方式分类基于搜索将测试转化为搜索问题，以代码覆盖率为指示器、以启发式算法（类遗传算法）为核心，将测试导向更高覆盖的方向 如CGF 基于梯度将测试转化为优化问题，以最大化缺陷 示例：设计一个模糊测试 定义输入：一个操作序列，有一系列原子操作组成 定义输出：可以是插桩得到的值，也可以是程序本身的输出 种子调度：种子优先级排序，更长的序列优先，得分更高的序列优先，基于feedback结果计算energy 测试生成 执行 结果反馈 软件工程综述RWPH：SE研究的四个维度 Reading Writing Presenting Hacking 以新颖的的方式总结和组织最近的研究成果、整合并添加对该领域工作的理解和认识的研究工作 总结有关技术的现有进展 总结当前某个领域研究的不足 提供研究框架/背景 检查经验证据在多大程度上支持/反对理论假设，甚至提出新的假设 综述研究流程 三个环节，五个步骤 规划、实施、报告 五个步骤 框架搭建 文献检索（这次作业要50篇，最不济20~30篇） 文献阅读（主要读摘要） 文献分类（分成3~6个正交类别） 文献分析 写作的逻辑性 善用总分结构 注重语句之间的连贯性 测试用例优先级软件演化：如何确保演化后软件产品的质量？ 回归测试前一个版本的用例放到新版本跑，看看旧的功能有没有受到影响 回归测试一般占测试预算80%以上，占产品维护50%以上 重新执行已有测试用例 用例庞大跑不完 用例冗余浪费算力 用例失效，接口改了，功能砍了，逻辑变了 用例缺失，新的测试需求没有被覆盖 回归测试优化测试用例优先级依照某种策略赋予每个测试用例不同优先级，以提高测试用例集的故障检测率 采用启发式算法操纵测试用例，是的优先级较高的算法能够优于低优先级的算法执行 给定测试用例集，的全排列集，优先级目标函数，其定义域为，值域为实数，寻找使得 测试用例约减通过识别并移除冗余测试用例来降低成本 通过覆盖来进行评价 优先级策略 基于贪心的TCP策略 全局贪心 每轮挑选覆盖最多的测试用例 多个用例相同随机选择 增量贪心 每轮优先挑选覆盖最多，且未被一选择用例覆盖代码单元的测试用例 所有代码单元都被覆盖则重置优先级排序 多个用例相同随机选择 基于相似性的TCP 基本思想：如果一堆测试用例显示的异常聚在一起，那它们测到的很可能是同一个bug，所以相似的测试用例往往测到相同的bug，所以我们选择测试用例时应当选得均匀一些 基于搜索的TCP 基于机器学习的TCP 评估指标APFD 平均故障检测百分比给定包含m个故障和n个测试用例 T‘为T的一个优先级序列，TFi为地i个故障第一次被检测到时的下标，那么APFD为 缺点：未考虑测试用例的执行开销（有的用例一跑跑几天）和缺陷危害程度（有的只是渲染问题，有的导致用户密码泄露，有的导致服务器被注入） 开销感知平均故障检测百分比 NAPFD归一化平均故障检测百分比特点：考虑实际优先级排序场景中 测试用例集不能检测所有缺陷 由于资源限制无法检测所有的测试用例 基于学习程序修复技术移动应用众包测试众包：利用群体力量来完成传统方法中成本高昂或更耗时的大规模任务 举例：很多验证码其实是一半真的有答案，一半则是在利用用户的识别能力来获取数据集 移动应用碎片化问题：品牌、型号、系统、传感器… uTest、Testin、Baidu Crowd Test，Alibaba Crowd Test，TestIO，MoocTest 申请上传 任务选择和环境设置 提交报告 生成最终测试报告 报告验证 众包测试中的缺陷类型 功能缺陷 显示问题 性能问题 布局问题 应用崩溃 错误提示 空白屏 众包测试面临的挑战 任务分配 任务奖励 众测过程引导 测试报告质量控制 协作式众包测试 完成测试任务过程中进行信息共享与任务分配，用户在本系统中既承担测试任务也承担审核任务，充分利用用户协作，完成目标任务 信息共享：用户在提交报告时进行实时相似报告推荐，避免重复报告提交 任务分配：审核页面推荐待审核的报告列表，测试页面推荐待测页面 协作方式：点赞点踩 一键fork 功能测试 根据需求来细分功能点 根据功能点派生测试需求 根据测试需求设计功能测试用例 逐项执行功能测试用例验证 测试类型 正确性测试 可靠性测试 易用性测试 性能测试度量方法 服务器采用cpu、内存使用率 客户端根据系统处理用户请求的时间 负载测试 负载测试用于验证应用系统在正常负载条件下的行为 性能行为通过一些性能指标体现 两种方式 直接到达负载数 逐步增加复杂数（可以测到系统负载的上限） 压力测试评估系统处于超过预期负载的行为 不一定是关注性能行为，可能是某种bug，比如同步、内存泄漏 系统不应该崩掉 可以测到系统崩溃的临界点 历史区测试法 恶邻测试法：经常出bug的地方的旁边也经常出bug 博物馆测试法：很久没用的代码很容易失效 娱乐区测试法 配角测试法：重要功能旁边的功能重点关注 深巷测试法：测试那些最不可能被用到的特性 通宵测试法：一直让程序运行，看他能坚持多久 众测报告聚合Aggregator 截屏集合的距离矩阵DS计算 文本集合的距离矩阵DT计算 具体实现：合成层次聚类，Summarizer 众测报告排序： 文本 关键词提取 计算文本距离 图片 SPM算法计算图像距离 计算图片距离时要设法屏蔽掉一些无意义的内容，比如不同的主题背景造成的截图不同 将每份报告的文本距离和图片距离组合起来 于是就可以将这些报告分成一个一个有层次的聚类 测试预言问题测试预言是自动化软件测试中不可或缺的一部分 测试预言可以是： 体现被测单元预期功能的文档 是验证程序功能的机制 判定程序执行是否正确的程序 约束 映射（比如执行结果映射到成功或失败） 显示预言：通过assert之类进行显示检测 隐式预言：通过程序崩溃等很明显的错误进行检测 预言问题给定系统输入，如何找到能够正确鉴别出符合期望的正确行为与发现潜在的不正确行为测试预言的挑战性难题 蜕变测试测试用例生成新思路 虽然不能通过成功测试用例排除程序存在缺陷的可能，但是可以用相关的测试用例指导之后的测试 蜕变测试的几大注意点： 不是所有的必要属性都能作为蜕变关系 蜕变关系应当和多个输入实例相关 不是所有的蜕变关系都能够划分成输入端和输出端 蜕变关系不要求一定是等式关系 有测试预言也可以做蜕变测试 差分测试找一些竞品来，看看对于相同的输入，输出结果或者行为有没有区别，如果有就说明至少有一个竞品有问题 移动应用自动化GUI测试自动化测试框架selenuim web页面测试 appium 扩展了selenium，可以用selenium库来编写应用测试脚本 appium 基于webdriver协议 客户端库 会话控制 命令执行 元素定位与交互 无需修改应用 跨平台 无需修改应用 模拟器和真实设备 测试往往是通过人工录制+自动化回放，也有基于模型的自动化测试技术 存在的问题 测试脚本的执行依赖于操作系统接口 定位空间依赖GUI 人工编写脚本开销大 脚本随应用迭代的维护困难 基于图像的空间定位通过图像匹配算法来完成对GUI元素的识别和定位 捕获屏幕图像 编写脚本 图像识别 相似度阈值 执行操作 反馈和调整 深度图像提取UIED布局理解、控件意图识别 基于深度图像理解的录制回放工具 无法感知异形屏幕对UI控件的遮挡 难以模拟真实场景下人的交互操作 仍依赖操作系统接口执行测试操作 解决：从侵入式转为非侵入式 机械臂+AI 期末源码测试 随机测试 变异测试 查分测试 蜕变测试 应用题 测试用例优先级 主要算法的流程及复杂度 APFD计算 算法应用 测试用例选择 主要方法 动态静态 与测试用例优先级的区别和联系 测试用例优先级&amp; 随机测试大数定律 测试执行次数够多、测试数据随机生成 概率低的偶然现象发生 变异测试变异测试旨在找到有效的测试用例，发现程序中真正的错误，用于检测测试用例是否足够强悍 这里说的变异和AI测试中常用的数据增广的变异方法是相似的，但是测试的对象不同 蜕变测试通过输入与输出之间期望遵循的关系来判断测试是否通过，譬如sin函数的测试用例，180度互补的结果应当是一致的 差分测试通过将同一测试用例运行到一系列相似功能的应用中观察执行差异来检测bug 移动应用测试 基于图像理解的移动应用自动化测试 能够了解各个任务的难点 能够论述各个任务的解决方法 核心思想 方法步骤 基于群智协同的众包测试 能够了解众包的难点 能够了解基本的机制 能够了解解决办法 AI测试 AI测试概述 与传统测试的区别 测试的难点 模糊测试 基本流程 数据生成 结果反馈 简单应用 图像测试 公平性 后门攻击","tags":["课程笔记"],"categories":["课程笔记","软件测试"]},{"title":"大数据分析","path":"/2023/09/06/大数据分析/","content":"大数据分析大数据分析-&gt;机器学习-&gt;计算机视觉 ML：数据用于计算 BDA：计算用于数据 大数据定义 datasets whose size is beyond the ability if typical database software tool to capture, store, manage, and analyze. 4VsVolume velocity veracity variety (?value) 5GGain Growth Gamification Governance Globalization 数据挖掘给定大量数据 发现具有以下特征的模型： 有效性 可用性 出乎意料 可理解性 数据挖掘常见任务描述类方法 预测类方法 数据挖掘的风险发现没有价值的模式 考虑的几个方向数据形态，操作，挑战 本地与云hadoopapache开发的开源的分布式计算系统，是搭建大数据平台常用的 stateDiagram DataCollectioan --> DataStorage DataStorage --> DataProcessing DataProcessing --> DataGovernance DataGovernance --> UnifiedDataAccessAndDelivery UnifiedDataAccessAndDelivery --> UseCases BDA in Education Grading Career guidance Custom learning plans BDA in Healthcare Predictive analytics EHRs Monitoring Cure cancer BDA in government Defense Cyberattacks Welfare Schemes BDA in Media and Entertain Predict interest of audience Targeted ads Performance measuring BDA in transportation Government Private servieces（面向私域的服务，高速公路上的广告牌） Daily usage BDA in banking and finance 股票预测 诈骗检测 交易 风险监测 利率计算 BDA in retail predict spending personalization Demand forcast 云计算分类基于部署分类 私有云（自己保管） 公有云（第三方托管） 混合云 基于服务分类 IaaS（网络硬件） PaaS（云主机） SaaS（云应用） FaaS（云函数） 云平台 google cloud data flow Aws 生态很全嘞 Azure 云计算四大层Data layer 数据存储存储Raw data HDFS（最流行，很鲁棒） Amanzon S3 MongoDB（面向文件的数据库） … Ingestion &amp; Integration layer 数据集成集成，准备，清洗 Stitch Blendo Kafka（作业里面要用 Apache开源） … Data processing layer 数据处理是一个算力敏感的服务 Spark Postgresql（老东西了，可靠性比较好） Sqream（完全的relational base，可以提供较好的压缩服务） … Analytics &amp; BI layer 数据分析可以在这里使用query，建立dashboard等等 Tableau （数据可视化） Chartio （基于名?的BI） Looker Big data beyond HadoopTotal Cost of Ownership storage Analytics compute data migration and integration streaming analytics BI（Bussiness Intelligence） ML or AI 为啥要在云上部署 support pricing utilities questions to consider which to move Factors to consider Data integration Benefits expected Subscription models in cloud Hardware opt Set-up and ongoing expense IT Security Energy 订阅方式：flat-rate反正就是这么多钱，你给不给吧 tiered分层计费嘞 ScalingHorizontal-增加节点P2P，Hadoop，spark Vertical-提升单机的能力HPC，多核处理器，GPU Data IngestionTools: ​\tHand coding ​\tSingle-purpose tools ​\tData Integration Platforms ​\tA DataOps Approach Data DestinationsCloud data migrationData Ingestion vs Data Integration前者简单，后者复杂 前者主要在与将原始数据迅速集中转移到某处，后者是要将数据准备好，提高数据质量，包含一系列转换 Apache NIFIETL processstateDiagram data --> ETL ETL --> analytical_data analytical_data --> presentation Dirty data 数据缺失 被加密的数据 矛盾的数据 违反了数据规则 复用了主键 Unique特征不再Unique 数据集成问题 Data cleaning 数据清洗Data Ingestion优点 扩展性 集成 灵活性（Batch Streaming，多种处理方式，满足不同使用场景） ETl 优点 数据质量（数据清洗） insights（通过基本数据提取可以获得一致的数据格式） 业务流程的改善（多个来源的数据集成到单一数据中心） cost（自动化处理任务减少人力成本） 存在的挑战 数据质量 数据集成 数据安全与隐私 性能与可扩展性 数据血缘 Distributed File SystemAssumptions 由大量廉价的经常出问题的部件组成 大文件 读取：主要是流式读取，小部分随机读取 大规模顺序写入 良定义的语法，与app协同操作 高带宽比低延时更重要 GFS cluster 一个master（通过心跳和chunckserver通信） 很多chunkservers 同时被多个客户端使用 Files 文件被划分为固定大小的chunks chunks有副本，一般是是三个 每个chunk有一个独特的label Single Master 一个master服务器 存储了与chunck有关的metadada 通过心跳与chunckservers连接 Chunk servers 将文件以Linux文件存储 Chunk size大的chunk size 减少客户端与master之间的交互 减少客户端与chunkserver的TCP链接 减少master节点存储元数据的开销 缺点：增加出现热点的可能性（大家都请求一个chunk，但是可以通过多副本来缓解这个问题） 缺点：小文件也会占用整个块 Metadata 内容 namespaces mapping from files to chunks Location of each chunk’s replica Chunk locations 在启动时从chunkservers获取 master长久保持，控制所有chunck，通过心跳监控chunck状态 Guarantess by GFSImplications for apps Relying on appends rather on overwrites Checkpointing Writing self-validating records(可以验证) Self-identifying records(唯一标识) 租约和变更顺序 master通过租约来获得持久的针对副本的变更顺序 一个primary chunk或获得租约 数据流 Decoupled from control flow Pipelined fashion 数据通过Tcp管道式传输 每一个机器将数据转发到“最近的”机器 贝叶斯条件概率事件B发生的情况下，事件A发生的概率 贝叶斯定律$P(A)P(B|A)&#x3D;P(B)P(A|B)$ 后验概率&#x3D;先验概率*调整因子 Google 三架马车 GFS google file system：解决分布式存储的问题 BigTable MapReduce 知识图谱知识图谱其实是一种大规模语义网络，富含实体、概念及其之间的各种语义关系 领域知识图谱聚焦某一领域的知识图谱，比如司法知识图谱 诞生标志：2012年，Google收购Metaweb，正式发布知识图谱 传统知识工程 自上而下：严重依赖专家和人的干预 规模有限 质量存疑 隐形知识、过程知识难以表达 领域知识的形式化表达较为困难 专家知识不可避免的存在主观性 不同专家之间知识存在不一致性 知识表达难以完备，缺漏是常态 应用易于超出预先设定的知识边界 很多应用需要常识支撑 难以处理异常情况 难以处理不确定性推理 知识更新困难 大数据时代知识工程BigKE 大规模开放性应用 永远不知道用户下一个搜索关键字是什么 精度要求不高 应用推理简单 大部分搜索理解与回答只需要实现简单的推理 知识获取 众包技术 基于众包的Taxonomy 高质量UGC 优势 Large scale semantically","tags":["大数据分析"],"categories":["课程笔记","大数据分析"]},{"title":"机器学习","path":"/2023/09/05/机器学习/","content":"机器学习人工智能的三大基石技术之一 推理 知识 学习 利用经验改善系统的性能 经典机器学习学习是一个蕴含特定目的的知识获取过程，其内部表现为新知识的不断建立和修正，而外部表现则为性能改善 现代机器学习任何通过数据训练的学习算法都属于机器学习 线性回归 K-均值聚类 主成分分析 决策树和随机森林 支持向量机 人工神经网络 学习系统stateDiagram 模型空间 --&gt; 学习算法 数据 --&gt; 学习算法 学习算法 --&gt; 学得模型 学习方法关系图深度学习 &lt; 表示学习 &lt; 机器学习 &lt; 人工智能 学习过程分类和回归常规术语及其标记 输入 x, xi 输出 y, y(x,W) 权重 w, wi 目标 t, tj 误差 E 维数灾难样本复杂度与输入X的维度直接相关 以同维度的立方体体积和球的体积做比，比是先增大后减小直到趋近于0 重要任务：对数据进行降维 数据集的划分训练集、测试集、验证集 留出法、交叉验证 建模有关的要素 模型/映射函数的刻画(比如线性分类器,SVM,神经网络) 确定目标/损失函数(如平方损失，交叉熵，凸与非凸)并优化 评估 过拟合（Over-fitting）极端追求样本上的误差减小，导致测试样本精度下降 欠拟合学得不够 机器学习的共性问题样本数是有限的，而满足这个样本的拟合函数/模型是大量甚至无穷的 –&gt; 病态问题 模型选择No Free Lunch Theorem 没有免费午餐定理 最好对问题有一些先验的知识 模型选择 正则化/规整化(给模型添加条件) 模型组合或集成 多视图方法 正则化可用病态-&gt;良态 满足： 存在性 唯一性 ？ 评价指标混淆矩阵（多分类，二分类） 精度accuracy（预测对的数目占所有样本的数目） 错误率（1-精度） 查准率precision（查出来的正样本有哪些真的是正样本 tp/(tp+fp)） 查全率recall（所有的正样本有多少被查出来了 tp/(tp+fn)） 查准率和查准率会相互制约 F1度量： F1=2•(precision•recall)/(precision+recall) ROC曲线主要关注“真正是对的（查准率）”和“真正是错的” 不平衡数据集正例数量和反例数量相差巨大 譬如普查艾滋病，如果模型无脑蒙阴性，正确率至少95%+，此时精度等指标往往不能很好地查出模型的问题 所以我们用Matthew系数进行不平衡数据集的度量 测量精度系统的可重复性：类似的输入产生相近的输出 物理意义 类似于 概率分布中的方差 开发中往往愿意牺牲一些准确度选择测量精度更高的系统 先验的重要性泛化=数据+知识 相似的样本应当有相似的输出 输入和输出间的映射应当光滑 丑小鸭定理没有天生好的特征，只有结合了与问题相关知识的才是好的 统计学基本概念数据集的统计量均值、中位数、众数 期望：概率加权和方差、均方根 协方差cov 协方差矩阵 距离度量函数计算样本和样本之间的距离 欧氏距离 距离公式 余弦相似性 比较余弦相似度 曼哈顿距离 总是沿着坐标轴走 切比雪夫距离 曼哈顿距离中长的那段 马氏距离 在新的空间上算距离 数据分布高斯分布（正态分布） 概率输入 男生女生 输出 身高 类的先验概率 p(y=i) 男生有70% 样本的先验概率 p(x) 175以下身高占40% 类条件概率（似然）p(x|y=i) 一个男生身高在175以下的概率 后验概率 p(y=i|x) 一个175的人是男生的概率 概率角度的机器学习方法分类生成式模型 判别式模型 机器学习技术新发展 终身/连续学习 迁移学习和域适应 深度强化学习 … 概率与学习：KNN拿到数据之后，首先做一个特征工程（手动），得到比如一个特征向量 但是现在又有深度学习了，可以学习到数据的特征 分类问题训练集 训练样本是这些x，它们一般是向量 样本标签是这些y，标签有时候是离散的，比如猫、狗，有时是连续的，比如身高 还要一个测试集来检验 回归问题K近邻分类器 计算样本和中所有训练样本之间的距离 对计算的距离/相似度进行升序（降序）排列 选择k个最近的训练样本 采用投票法，将近邻样本数最多的类别标签分配给 最近邻分类器 泛化错误率：即便最近邻分类器如此简单，最近邻分类器的错误率没有超过贝叶斯分类器的两倍 k-近邻回归将标签进行加和 更好的方式是离我越近的，我就给越大的权重，做加权平均：一种简单的方式是令权重为距离的倒数 近邻平滑核平滑法 二次核 次方核 高斯核 … k-NN是典型的“懒惰学习” 训练阶段把样本存起来，啥也不做，所以训练开销为0 拿到了测试样本才真正开始计算 这在样本较小时是比较舒服的，但是如果样本很多就寄咯 SVM、CNN等是“急切学习” 训练阶段就对样本进行了学习处理，这类方法尝试在训练期间构造一个通用的、预输入无关的目标函数 KNN，评价优点： 精度高 对异常值不敏感（把k设大点） 无数据输入假定 缺点： 计算复杂度高： 训练阶段：0 测试阶段： logk是因为只用排出前k个，不用全拍了，所以不是快排的 空间复杂度高 降低计算难度 特征维度2-5：维诺图 Voronoi diagrams 根据一组给定的目标，将平面划分成靠近每一个目标的多个区块 维诺单元：X是一个点集，包含K个基点 维诺单元永远是凸多边形 不同的距离度量得到不同的维诺图 查询或测试 二维数据：计算图 查询 多维可以做树优化，但是复杂度很难量化 特征维度6-30：KD-Tree KD树是一种对K维空间中的实例点进行存储以便对其进行快速检索 构造流程 确定split域，计算每个特征维度的方差，方差最大的维度即为split域的值 确定Node-data域，数据集点集按期第split域的值排序 。。。 时间复杂度 排序算法选得好的话 查询： 高维特征： 降维算法，例如PCA 近似最近邻（approximate nearest neighbor，ANN） 核心思想：搜索可能是近邻的数据项而不再只局限于返回最可能的数据项，在牺牲可接受范围内精度的情况下提高检索效率 哈希（hashing）用简单的特征比如01代替复杂的特征比如实数 利用hash将任意长度的输入映射为固定长度的输出 概率化KNN传统knn的主要问题是不建立在任何概率框架上 K近邻算法的前途小样本学习 无监督学习聚类的好坏不存在绝对的标准 聚类也许是机器学习中“新算法”出现最多、最快的领域，总能找到一个新的“标准”，使以往算法对它无能为力 聚类算法根据给定的相似性评价标准，将一个数据集合分组/划分成几个聚类（簇） 数学形式化聚类的依据将整个数据集中每个样本的特征向量看成是分布在特征空间中的一些点，点与点之间的距离可以作为相似度 一个好的聚类算法： 内部高相似性 之间低相似性 类的特征 不是实现给定的 聚类的数目和结构都没有实现假定 目的是寻找数据中的 潜在的自然分组结构 感兴趣的关系 距离度量对聚类的影响数据的粗聚类是2类，细聚类是四类（因为距离度量函数不同） 数据分部形式影响聚类分析的有效性距离度量度量空间与度量函数一个有序对,X是一个集合，d是X上的度量函数，d将X中的每一对点映射到一个非负实数，并满足一下四条公理 非负 唯一 对称 三角不等式 常用度量函数是前面讲到的一些距离，还有一个是把欧式、曼哈顿和切比雪夫距离囊括的闵可夫斯基距离（Minkowski distance） 聚类准则 xi和xj之间的距离小于某个阈值就是一起的 试探方法 聚类准则函数方法 基于试探的聚类搜索算法按最近邻规则的简单试探法任取一个样本作为聚类中心的初始值，例如z1=x1 计算 如果小于阈值T，那么x2和z1在同一个聚类 如果大于，那么x2形成新的聚类中心z2=x1 接下来对于已经存在z1，z2…zn的情况，xn进来尝试归到小于阈值且最近的聚类中，如果都大于阈值，那么形成新的聚类 问题： 样本初始选取产生不同分类 样本顺序不同产生不同聚类 阈值不同产生不同聚类 最大最小距离算法基本思想：以试探类间欧式几何距离为最大作为预选出聚类中心的条件 任意选一个样本作为第一个聚类中心z1=x1 选距离z1最远的样本作为第二个聚类中心，比如z2=x6 逐个计算剩下样本与z1，z2间的距离，并选出其中最小距离 又选出最小值中的最大值，若改制达到z1-z2一定比例以上，那么取相应样本点为新的聚类中心 系统聚类法基本思想：将样本数据按距离准则逐步分类，类别由多到少，直到获得合适的分类要求为止 聚类中心是一个由多到少的过程 初始模式样本有n个，每个样本自成一类，即建立n类，计算各类之间的距离，得到一个初始矩阵 假设前一步求得了距离矩阵，则求其中最小元素，如果是ij之间的距离，那么将两类合并为一类 合并后计算新的距离 返回第二步，重复计算及合并，直到达到满意的分类结果（比如聚类数量达到要求，或是最小距离超过了某个阈值） 距离准则函数系统聚类法要计算聚类和聚类间的距离，这时就需要距离准则函数 最短距离法（两个集合间点距离的最小值） 最大距离法 类平均距离法 动态聚类法基本思想：首先选择若干个样本点作为聚类中心，再按某种聚类准则（通常采用最小距离准则）使样本点向哥中心聚集，从而得到初始聚类 然后判断聚类是否合理，如果不合理则更改聚类 直到满意为止 K-means算法 选择一个聚类数量k，这就是一个超参数 初始化聚类中心 可以随机选 对每个样本点，计算样本点到k个聚类中心的距离，将样本点分距离它最近的聚类中心所属的聚类 重新计算聚类中心，聚类中心为属于这一个聚类的所有样本的均值 如果没有发生样本所属的聚类发生改变的情况，则退出，否则，带着更新后的聚类中心返回step3 K-means算法的结构受到如下选择的影响 所选聚类的数目 聚类中心的初始分布 样本分布的几何性质 在实际应用中，需要试探不同的K值和选择不同的聚类中心的起始值 如果数据样本可以形成若干个相距较远的孤立的区域分布，一般都能得到较好的收敛效果 K-means++算法基本思想：K个初始的聚类中心相互之间应该分得越开越好 从数据集中随机选出一个样本作为初始聚类中心 首先计算每个样本与当前已有聚类中心之间的最短距离（即与最近的一个聚类中心的距离），用;接着计算每个样本点被选为下一个聚类中心的概率$$。最后，按照轮盘算法择出下一个聚类中心 重复第二步直到选出k个聚类中心 然后就是k-means ISODATA算法运行过程中能够根据各个类别的实际情况进行分裂和合并两种操作来调整聚类中心函数 从数据集中随机选取K0个样本作为初始蕨类中心 针对数据集中每个样本xi，计算它到K0个聚类中心的距离并将其分到距离最小的聚类中心对应的类中 判断上述每个类中的元素数目是否小于Nmin。如果小于Nmin则需要丢弃该类，令K=K-1，并将该类中的样本重新分配给剩下的类中距离最小的类 针对每个类别重新计算其聚类中心 如果类别数大于阈值，合并 小于阈值，分裂 直到达到迭代次数 合并操作： 计算当前所有类别聚类中心两两之间的距离，用矩阵D表示，其中D(I，i)=0 对于D(i,j)&lt;dmin的两个类别需要进行合并操作，变成一个新的类，该类的聚类中心为： 新的聚类中心可以看做是对这两个类别进行加权求和，如果一个类所包含的样本个数较多，所合成的新类就会更加偏向它 分裂操作： 计算每个类别下所有样本在每个维度下的方差 针对每个类别的所有方差调出最大的方差 如果某个类别的&gt;sigma并且该类别所包含的样本数量大于2nmin，那么认为可以分裂 与K-means算法的比较 k-means算法通常更加适合于类别数目已知的聚类，而ISODATA算法则更加灵活 从算法角度看，ISODATA算法与K-means算法相似，聚类中心都是通过样本均值的迭代计算来决定的 ISODATA加入了一些试探步骤，并且可以结合人机交互的结构，使其能利用中间结果所取得的经验更好的进行分类 ISODATA原理非常直观，但是需要额外指定更多参数，在实际应用中并不受欢迎 聚类的评价指标 聚类中心之间的距离 聚类域中的样本数目 聚类域内样本的距离方差 常用评价指标（标签未知）紧密度CP 是各个聚类样本点到聚类中心平均距离的平均值 间隔度SP 距离越大说明类间越分散 没有考虑到类内聚类效果 戴维森堡丁指数DBI DB值越小，表示类内越紧凑，类间越分散 缺点：使用欧氏距离，对于环状分布聚类评价很差 邓恩指数DVI计算任意两个簇元素最短距离除以任意簇内距离最大的值 聚类评价（标签已知）监督学习与无监督学习通过标注进行监督学习 但是标注实在是太麻烦了，人们开始寻找运用原始无标注数据的方式 自监督学习 自监督预训练 无标签数据 前置任务预训练 向下游迁移 前置任务学习典型：生成式方法-图像着色基本思想：如果一个模型有能力预测一张灰白图片的彩色状态，那么这个模型应该是可以识别这个物体的 彩色图像转为灰度图像，RGB-&gt;L（亮度）ab（色彩） L送给VGG，VGG网络重建ab 计算一个损失，损失如果在接受范围内就好噜 典型：图像修复这个就比较难了 一幅图像去掉一部分，一段文章丢掉一些单词，要求模型补全 典型：图像拼图把图像分成几个快，网络可以重新还原图像 对比学习给图像做一些变换，并不改变其类别，网络应当可以发现他们是类似的 树学习符号学习推理推理的角度 正向推理（演绎） 反向推理（反绎） 归纳推理 符号学习是一种归纳推理 概念学习给定样例集合以及每个样例是否属于某个概念，自动的推断出该概念的一般定义 概念学习任务 实例集合X:上例中用六个属性表示 目标概念：定义在实例集上的布尔函数 训练样例：正例c(x)=1,反例c(x)=0 假设集：每个假设h表示X上定义的布尔函数 作为搜索的概念学习当假设的表示确定后，也就确定了概念学习 假设的一般到特殊序更泛化：令和是定义在上的布尔函数，若，当且仅当 寻找极大特殊假设find-s 将h初始化为H中最特殊的假设 对每个正例x 对h的每个属性约束ai 如果x满足ai，不做任何处理 否则将h中aj替换为x满足的另一个最一般的约束 输出假设h 特点对以属性合取式（&amp;&amp;的形式而不是||的形式）表示的假设空间，输出与正例一直的最特殊的假设 列表消除算法变形空间 一致： h可以正确推断D 变型（版本空间）空间 关于假设空间H和训练空间D能一致的所有h的集合 极大泛化 H中集合g和D一致并且不存在比g更泛化的g’还能与D一致 极大特化 H中集合s和D一致并且不存在比s更特化的s’还能与D一致 变型空间表示定理候选消除算法 G初始化为最一般，S初始化为最特殊 if d是正例 从G中移去所有和d不一致的假设 对S中每一个与d不一致的假设s 从S中移除s 把s的所有极小泛化假设h加入到S中 且h满足与D一致，而且G中的某个成员比h更一般 从S中移去所有这样的假设：它比S中的另一假设更一般 if d是反例 归纳偏置问题 目标概念假设不在假设空间怎么办 能设计包含所有假设的假设空间吗 假设空间大小对未见实例的泛化能力有什么影响 假设空间大小对所需训练样例数量有什么影响 构造无偏的学习器 幂集 无偏学习的泛化 给定3个正例q1,q2,q3,两个反例q4,q5 不同的归纳偏置有偏程度不同的三种归纳学习算法 机械式学习器 候选消除算法 FIND-S（只要和正例的统计结果不一致的都是大坏蛋） 有偏性 如果一个学习器的有偏性越强，那么它的归纳能力往往也越强 决策树学习决策树学习 实例：“属性-值”对表示，应用最广的归纳推理算法之一 目标函数具有离散的输出值 有很好的健壮性（样例可以包含错误，也可以处理缺少属性值的实力） 能够学习析区表达式（析取是“或”，合取是“和”） 算法 ID3，Assistant，C4.5 搜索一个完整表示的假设空间，表示为多个if-then规则（这使得模型具有一定的可解释性） 归纳偏置 优先选择较小的树 问题设置问题设置 可能的实例集X 未知的目标函数f X-&gt;Y 得到一个函数集 H h:X-&gt;Y 决策树学习的假设空间搜索 搜索一个可以正确拟合训练样例的假设 搜索的假设空间就是可能的决策树的集合 从简单到复杂的爬山算法遍历假设空间 ID3算法 创建树的root节点 如果所有都为正，那就返回一个+的单节点root 都为负，- 如果属性都是空，那就返回一个root并且label标成example中出现最多的结果 否则（真的来了） 选出A，A是属性中分类能力最好的属性 根节点的决策属性就是A了 对于A的每个可能值vi EVi为examples中满足A属性为vi的子集 如果ExampleVi为空，直接加一个叶子结点设一个最多的 否则，在这个分支下加一个子树，递归这个过程 核心问题：如何选择“最佳”或“最优”的属性 衡量给定属性区分样例的能力：信息增益 信息的度量：熵（这个样例集合的纯度，样本越是确定，越是一致，熵就越低，反之越高） 假设X是一个有限取值的离散随机变量：概率分布，随机变量的熵: 目标属性为布尔值的样例集S的熵 信息增益的计算：核心思想：使用某个属性分割样例后，样本熵下降的量，这个量越大，说明带来的信息增益就大 ID算法的特点 假设空间：包含所有的决策树 遍历过程：仅维持单一的当前假设 回溯：不进行回溯，可能进入局部最优 基于统计：对错误样例不敏感，不适合增量 决策树学习中的归纳偏置 近似：优先选择较短的树 优先选择信息增益高的属性更接近根节点的树 这是一种优先偏置（搜索偏置），而符号学习的算法一般都是限定性的，叫做限定偏置（语言偏置） 奥卡姆剃刀原理如果对于同一现象有两种不同的假说，应该采取比较简单的哪一种（这样这个模型被证伪的机会就更少） 不是简单的选择最简化的假设，而是推理所依据的是使可证伪的假设的数目更少 C4.5算法核心改进是属性选择指标 信息增益准则对可取值数目较多的属性有所偏好 信息增益比：信息增益/该属性的熵 CART算法属性选择指标（分类） Gini指数：对于模型纯度的刻画，越小越纯，也就越好 K个类，样本点属于第K类概率为pk ,而pk可以就用 该类样本数/总样本数 来近似 属性A对样本集合划分下的基尼指数 基尼系数 VS 信息增益 二分类问题 基尼系数和熵正相关，并且很接近，可近似代表分类误差率 都可以代表叶子结点的损失 CART算法还可以做回归问题 剪枝处理：增强模型的泛化能力从完全生长的决策树的底端减去一些子树，使决策树变小，增强泛化能力 最小化子树损失函数 a是超参数，CT是预测误差，T是叶子数 决策树的优点 简单直观 可解释 缺点 非常容易过拟合 样本发生一点改动，树的结构可能剧烈改变 决策树的延伸将决策树的可解释性延伸到深度学习网络 集成学习核心思想：三个臭皮匠，顶个诸葛亮 是一个预测模型的元方法（并不是一个具体的学习方法） 特点（分类） 多个分类器集成在一起，以提高分类准确率 由训练数据构建基分类器，然后根据预测结果进行投票 集成学习本身不是一种分类器，而是分类器结合方法 通常集成分类器性能会好于单个分类器 数学保证在精度互相独立的假设下，可以数学证明只要基分类器的精度优于随机选择，并且参考无穷多的分类器，集成分类器的精度可以趋于1 Bias-Variance tradeoff问题 Bias 学习结果的期望与真实规律的差距 Variance 学习结果自身的不确定性 Total Error 当一个模型很简单，往往很难做到精确预测，但是结果会比较稳定，如果一个模型很复杂，相对预测（至少在测试集上）准确，但是结果会不稳定 核心问题序列集成 利用基学习器之间的依赖关系，依次生成 减小偏差bias 并行集成 利用基学习器之间的独立关系，并行生成 减小方差variance Core ProblemQ1：如何训练每个学习器 Q2：如何结合每个学习器 结合策略回归问题 简单平均 加权平均 分类问题 各种投票 学习法多样性策略数据层面 输入样本的扰动 输出样本的扰动 属性层面 随机选择部分属性，构建基学习器 参数层面Bagging原理Bootstrap aggregating基本原理 有放回采样方法（数据层面） 从样本池里面有放回的随机采样出多个不一样的数据集 流程训练集S，基学习算法I，训练轮数T 123456for i = 1 to T:\tS' = 从S中采样\tCi = I(S)\t将Ci结果结合 Bagging的优点 并行式 性能依赖基分类器 不依赖训练集实例 缺点 基学习器拉胯，集成后也拉胯 集成后的模型缺乏可解释性 依赖数据集，计算代价还是比较高 代表算法：随机森林 用N来表示训练用例（样本）的个数，M表示特征数目，输入特征数目m，用于确定决策树上一个节点的决策结果（m远小于M） 从N个用例中以有放回抽样的方式，取样N次，形成一个训练集，并用未被抽到的作预测，评估其误差（数据扰动） 对于每一个节点，随机选择m个特征（通常为），根据这m个特征，计算最佳的分裂方式（属性扰动） 每棵树都会完整成长而不会剪枝，这有可能在建完一课正常树状分类器后会被采用 随机森林的特点 差异性：每棵树是不同的，每棵树使用的特征是不同的 缓解维度灾难：因为每棵树没有使用全部特征，特征空间被减小了 可并行化：不同数据，不同特征，每棵树都可以并行的生长 训练-测试划分：训练和测试的划分不是必须的，构建每棵决策树时，总是有30%的数据是没有采样的 稳定性：结果经过了投票和平均，比较稳定 Boosting与AdaBoost概率近似正确理论（Probably approximately correct） 强可学习：如果存在一个多项式的学习算法能够学习到一个概念类，并且正确率很高，那么这个概念是强可学习的 弱可学习：多项式学不了 强学习器和弱学习器是等价的（并没有谁好或者谁差） 一个概念是强可学习弱可学习 将弱可学习器通过boosting提升为强可学习器 框架样本被分为简单样本和困难样本，本轮训练分类器可以正确处理的样本，被视为简单的样本，会被给予较低的权重，而无法正确分类的样本被视为困难样本，被赋予更高的权重，分类器带着分类的样本和权重进入下一轮迭代 Adaptive Boost核心思想：从弱学习算法开始，通过改变训练数据的概率分布（权值分布），反复学习，得到一些列弱分类器，然后进行组合，构成强分类器 策略： 权值分布 弱分类器组合：分类好的权重大，不好的权重小，组合 AdaBoost训练样本集合 分类器样本权重 评估分类器第k个分类器在训练集上的加权分类误差率为 权重系数 评估样本样本权重 Adaboost理解 其实是一个加法模型 损失函数为指数函数 前向分步 Boosting Tree加法模型，前向分步算法 以决策树为基函数的提升方法为提升树 采用平方误差损失函数 r是当前模型拟合数据的残差 拟合 梯度提升树GBDT几乎没有听懂任何东西 初始化弱分类器，就用一个最小化弱分类器，都预测样本均值 ​\t循环： ​ 根据残差构造样本集合 ​ 构建CART树拟合刚刚构造的残差集合 ​ 通过加法的方式，直接把刚刚拟合的结果加上去，直到达到循环退出的条件 得到强分类器 Extream Gradient Boosting（XGBoost）在深度学习出现之前，XGBoost一直是Kaggle竞赛的首选方法 GBDT的高效实现 目标函数通过二阶泰勒展开式做近似 定义了树的复杂度 分裂节点处通过结构打分和分割损失动态生长 分裂节点的候选集合通过一种分布式 Stacking算法（学习法）从初始数据集训练出 对于Model_1，将训练集 比较 Baggging：数据层面进行扰动 Boosting：串行方法 概率与学习黑话 scalar 标量：一个实数 vector 向量：一个实数序列构成一个向量 matrix 矩阵：一个实数构成的矩形数组 tensor 张量：一个泛化的实数构成的n维数组（0阶张量就是标量，1阶是向量，2阶是矩阵） 带约束的优化问题： minimizae f0(x) subject to 优化变量： 不带约束的优化问题：注意现在我们说什么都是在说向量了 凸函数：X是一个凸集合 凹函数就是改下比较符号 判断函数的凹凸：对于标量函数，二阶导数大于等于0，是凸；对于向量函数，如果hessian矩阵是半正定的，则是凸函数 判断正定：特征值都大于等于0，都大于0就是正定 凹函数的判定又是反过来 随机变量的期望：取值对概率密度函数pdf积分（连续）或对概率质量函数pmf求和（离散） jensen不等式，如果是凸函数，那么，凹反之 高斯分布：应用最广泛的概率分布 单变量高斯分布/正态分布（高中高斯分布） 是平均数是标准差，方差越大，越矮胖，否则高瘦 累计分布函数 多变量高斯分布 均值向量（协方差矩阵） 高斯混合模型 GMM通过不同的权重，把不同的高斯模型组合在一起 概率密度函数也是加权求和的 可以将高斯混合模型数据的生成分成两个阶段来解释，首先生成了一个i，这个i决定了从第i个高斯分布中出现的，(一般i的概率就是高斯分布的权重)，然后再从第i个高斯分布中采样，这里i的生成我们就要假设有一个隐藏变量在决定它，也就是hidden z，我们可以认为，也就是z将会激活第i个高斯函数 那么既然z和x一一对应，那么怎么估计参数?首先聚集每个子高斯分布的样本x得到 然后算出每个高斯模型的参数，权重就是 该模型的采样数/总采样数 最大似然估计 MLE Maximum likehood estimation定义：MLE是通过最大化一个似然函数来估计一个概率分布的参数，使得在假设的统计模型下，观测数据最有可能出现 似然函数 最大似然估计MLE: 假设数据点i.i.d 高斯混合模型最大似然估计最大对数似然估计MLE，同时还引入z 期望最大化算法 EM Expectation-Maximization algorithm核心思想：一个迭代的方法，采用最大似然估计，先固定一个参数，然后去优化另一个，再固定这个，优化那个，一直迭代，直到局部最优 EM的实际运用完全没听懂 EM可以保证下界不断地被迭代与优化 Kmeans中就隐含着EM 点的类别就是隐藏变量，聚类中心就是参数，准则函数是让点们离聚类中心尽可能近 初始化就是一个选取预制参数的过程 E step是根据预选的中心，将点分到聚类 M step是根据点的类别，计算新的聚类中心 然后迭代 支持向量机从统计学的观点来看，机器学习的目的是得到映射：数据样本标签 类的先验概率: 样本的先验概率:（样本中x的概率占多少） 类条件概率:(给定这个类别，它来自x的概率是多少) 后验概率:(我们最想要的，给定x，它是y的概率是多少？) 从概率框架的角度： 生成式模型 估计和，用贝叶斯定理求 判别式模型 直接估计后验概率 判别函数：不假设概率模型，直接求一个把各类分开的边界 感知机：线性超平面二分类问题 可以看做作是在特征空间上对类别进行划分的任务 如果可以找到一个超平面可以让$\\mathbf{w^T x_i}+b0$时将数据i分成不同的类别，那么这就是一个可以用线性超平面解决的二分类问题 而我们在机器学习中要求的就是和 线性支持向量机核心思想：最大化所有训练样本的最小间隔 计算所有样本点到想象中的超平面的间隔 找到那个最小的间隔 我们希望这个间隔最大化 支持向量具有最小间隔的样本点被叫做支持向量 样本点到超平面的距离看起来就是高中点到直线距离的展开 证明与高中也相似也就是 SVM问题是什么？找到一组w，b，使得对于所有样本的至超平面的最小间隔最大 如何简化计算？我们可以对于w,b乘以一个参数c得到cw，cb，而这两个数也可以实现分类，就好像把超平面沿着它延展的方向移动了一样 于是我们找到一个合适的c，使得 可以让c为最优解的最小间隔，这样同时一除，就相当于限定为1，于是我们就只需要最大化 于是我们进一步转为求解最小，使得 接下来我们将带约束的优化问题转为不带约束的优化问题拉格朗日乘子法 SVM对偶形式原来，变量是，拉格朗日之后，变量是 求出现在的最优解，就能得到原空间的最优解 求出了w*，怎么求b*呢对于拉格朗日乘子&gt;0的情况，就一定有 优化与改进不能给予过强的假设，我们应该允许少数点不满足可以允许少数点margin比1小 但是犯错误要有惩罚 我们做了一个松弛 为了避免非常离谱的，我们必须做一个惩罚 让优化目标成为 代价 正则项 C超参数 很多样本是不可以通过线性超平面分类的，很可能是非线性把数据映射到高维空间 定理：如果原始空间是有限维（属性数有限），那么一定存在一个高维特征空间使样本可分 核技巧： 定理：低维度空间的非线性函数，我们可以找到一个高维（尽管可能是无限为），将它转为高维空间里向量的内积 核支持向量机kernel SVM将对偶形式的xi,yi内积替换为核函数，对应的分类边界中xi也成为$$ 常用的kernel function现实中的分类往往也不是二分类，对于多分类我们该怎么做呢如何选择超参数呢采用交叉验证的方式 如何解决多类问题呢？ 最原始的方式：每两个类之间都训练出一个分类器 另一种：设计C个分类器，对于类别i，除了i以外的类别都是负类 神经网络来了！神经元和感知机发展历史 1943 一个心理学家和一个数理逻辑学家提出 1948 冯诺依曼提出相互再生自动机网络 1950s 感知机模式 1960s 非线性多层自适应网络 1969 《感知机》 1982、1984 Hopfield 2006 深度信念网络 MP神经元基本结构 输入X 权值W 激活函数 偏置单元,对应权值 一组输入加权wi相当于突触 一个加法器把输入信号相加，与收集电荷的细胞膜相似 一个激活函数决定神经元是否要被激活，类似细胞是否放店 MP神经元的局限输入方面：线性求和 输出方面：单一输出值 更新机制：时钟同步更新 权值的物理意义：兴奋、抑制 激活函数单个神经元不管怎么样都是在求和，怎么搞都是线性操作 激活函数就引入了非线性 阶跃函数 不连续 对变化敏感 x=0 时不可微 适用于单层感知机 sigmoid函数阶跃函数的平滑近似 连续、光滑、严格单调 函数范围在(0,1)之间 S形曲线，非线性函数 导数为其本身函数的组合 问题： 饱和性激励函数（当趋于无穷时梯度趋于0） 梯度和导数很容易变成0，导致梯度消失 导数始终小于1，在0周围变化 不以0为对称轴 指数计算代价大 ReLU Leaky ReLU(a=0.01)/PReLu RReLU在训练时a从一个均匀分布中采样 最早的神经网络ALVINN 感知机与感知机学习最简单形式的前馈式神经网络 input是输入，hiden是隐藏层，是神经元的主体，边上有权重，最后输出前走一次激活函数 非线性前馈网络 同层内无互联 层层间全相连 有监督学习机制每一轮我们会计算一个权值的变化量 感知机学习算法 初始化权值 计算权值和，应用激活函数，获得输出 查看输出和期望是否一样，如果不一样就会更新权重 线性可分决策边界 鉴别函数 感知机收敛理论给定一个线性可分数据集，感知机将在有限迭代中收敛到一个决策边界 定义是分离超平面与最接近的数据点之间的距离，则迭代次数的界是 感知机学习缺点 感知机属于单层神经网络，不能解决非线性可分问题 典型的例子是异或 一种方法是投影到高维空间 也可以采用多层感知机，就好像对数据进行了变换，可以在影藏层做升维，也可以增加神经元相当于变换数据 感知机的表达能力 走向远处多层感知机MLP为什么要有隐藏层？隐藏层实际上是特征检测算子，隐藏层神经元逐步发现数据的突出特征 如何计算隐藏层的权值？前向与后向前：分阶段，逐层计算，逐层输出 后：计算一个偏差，分阶段，逐层调整权值 反向传播误差反传 误差的计算 Delta规则Delta规则是基于错误平面的（神经网络在训练集上的累积误差，每一个权值向量都会对应一个误差，也就对应误差平面上的一个点），Delta规则要求激活函数连续且可微分 学习常数C对于delta规则影响很大，c过小更新很慢，c过大会在最优震荡 反向传播算法 前向阶段：网络权值固定，输入信号在网络正向一层一层传播，直到达到输出端，获得网络的输出 反向阶段：通过比较网络的输出与期望输出，产生一个误差信号，误差信号通过网络反向一层一层传播，在传播过程中对突触的权值进行修正 信用分配问题：修正隐藏值的权值时，如何给隐藏层的神经元分配信用或责任呢 BP神经网络： 三层或三层以上结构 无反馈 层内无连接 输入层+输出层+隐含层 采用误差反向传播学习算法 BP本质上是一个学习算法，MLP假借了它的名字成为BP学习算法 神经元是输出层可以直接用真实值算误差 但是隐藏层没有期望输出，所以要借助下一个节点的误差传播来实现 随机梯度下降 最小化一个损失函数 批量梯度下降：拿全部的样本去算梯度，取平均值更新 只拿一个样本去更新肯定也不行吧（随机梯度下降） Mini-batch随机梯度下降：随便搞一些来更新 反向传播就是利用链式法则，根据下一层的偏导数*本层的输出对于本层的权值的偏导数，乘上学习因子就是了 初始权值简易方法是权值直接服从正态分布（0,1），但是权值过大会导致sigmoid饱和，导致梯度趋近于0，进而导致学习失效，所以早期我们使用（1，1/√n） 批量训练今天，20世纪的人们爱用mini-batch 局部极小和冲量冲量相当于加大步长，借此跨过一些局部最优 停止机制 固定迭代步数 误差小于某个阈值直接停下来 利用验证集观察误差的变化，打击过拟合 自动编码器 AutoEncoder早期的自动编码器用来去噪 Encoder-&gt;latenet space -&gt; Decoder 自动编码器可以实现无监督的特征提取，也可以在latenet space进行采样丢给decoder生成新的数据 径向基网络RBF受到视网膜的启发，RBF认为不需要每个神经元都接受全部的信息，而是可以接受一部分，也即感受野 高斯函数作为激活函数 当神经元的输入离径向基函数越近，神经元激活程度越高 …越远…程度越低 输入空间到隐层空间是非线形变换 隐层空间到输出空间是线性变换 求解的参数 基函数中心、方差 隐藏层到输出层的权值 径向基函数算法 放置RBF中心 用均值算法初始化RBF中心的位置 用随机选择的数据点作为RBF的中心 BP是对非线形映射的全局逼近，可以有多个隐层 RBF具有局部映射的特性，只存在一个隐含层，RBF计算速度快 深度学习经典机器学习 input-&gt;特征表示-&gt;学习算法 深度学习 神经网络自动学习特征 深度学习具有良好的非线形结构神经网络可以一层一层的拆分十分复杂的复合函数 手工特征 固定 难以设计 任务无关 底层特征 需要专业知识 与学习算法是分离的 深度特征 特征是可学习的 黑盒 学到的特征与任务是相关的 学习层次表示和高级特征 端到端的，特征抽取与学习算法耦合在一起 卷积神经网络局部连接的神经网络 对于一个1000*1000的图片，如果隐藏层也是1000*1000，如果还是全连接，最保守估计也有10^12个参数 所以我们使用局部连接，如果我们使用10*10的局部连接，我们就只需要10^8个参数了 但是这样还是很离谱，于是有人提出了“参数共享”的机制，比如就只要100个Filter（滤波器），每个Filter自己有一组参数，就只有100*100=10000个参数了 卷积核卷积 池化Pooling/下采样Subsampling 减少参数 避免过拟合 扩大感受域（池化后单个点对应的上一层的区域要大得多） 因为中间神经元可能会很大，给下一层带来很大的压力，因此我们可以采用池化减小中间神经元 Max pooling Average pooling L2-norm pooling Global average pooling Covariance pooling … 最后如何对应到输出呢？把最后一层输出拉成一维向量，交给全连接神经网络，最后得到一个输出向量，比如十分类问题，我们就可以得到一个十维向量 但是这样不就又陷入了全连接巨大的参数陷阱么？ 所以我们可以通过Global Average Pooling，先进一步大幅减少参数量，在去映射到解空间 Dropout解决全连接巨量参数的问题，我们可以直接抛弃一些连接，这就好像人类从儿童变为成年人时大脑的神经元连接数在不断的减少一样 最简单地Dropout以固定的概率p随机保留一写神经元，这意味着每次Dropout，神经网络都是不一样的，从这个角度来讲，也是一种集成学习 因为Dropout可以带来非常可观的性能提升，现在大家不仅对全连接层做Dropout，还对卷积层有时也Dropout Batch Normalization通过对每层的输出进行归一化，我们可以减少内部方差偏移或避免梯度扩散 BN可以帮助我们把网络搭得更深 BN首先对每层的结果做了减去平均数和除以方差的操作，然后为了避免破坏结构又反过来做了类似的事 交叉熵损失函数 将错误类别的负对数概率降至最低 最大化真实类别的正对数 回归损失函数回归问题的label是连续值，需要拟合真实标签的值 三元组损失三元组损失比较锚点和结果的相似度1 机器学习技巧数据增广比如flipping（翻转），crop（裁剪）、color jitter;ing（颜色变化） 除了可以增加数据量，还可以提高模型的泛化能力 mixup（图像按不同权重拼接起来） cutmix（把一个目标裁剪下来帖到另一个上） 预处理过滤器batch-size 每次训练采用的样本数，比如数据集有1000张，每次只用100张，batch-size能选多大和gpu的能力直接相关，因为要把样本载入显存 filter-size也会对结果产生效果 池化大小学习率的设定（重中之重）学习率的效果与优化器也有关 SGD是随机梯度下降最经典的优化器 Adam优化器是SGD的优化成果 SGD类开始可以采用比较大的学习率，然后随着迭代将学习率降得越来越小 adam优化器一般就采用一个固定的学习率 当batch-size很大时，可以采用比较大的学习率，如果比较小就要更谨慎一点 预训练避免模型随机初始化，比如预训练的大模型可以快速帮助我们训练出具体的好的大模型 在预训练模型上微调时不要一下子调所有的参数，而是调一小部分或是新嫁接一些层数 但是如果你手里数据量很多，就不用束手束脚，直接微调大量参数甚至整个模型都没事，如果是新加一层的话，新加的层学习率可以设大点，原来的层学习率可以设小点，如果是指更新部分参数的话（很多参数里面都有requireGraddiance这个选项，为false时神经元就不会接受梯度带来的更新了） 激活函数的选择图像分析tensorboard可以画出一些关键的数据比如损失随着训练轮次的变化 当验证集上的精度和训练集上的精度差别很大时，模型应该是过拟合了 还可以把一些重要的特征可视化 注意力机制经典神经网络架构LeNet第一个成功的神经网络，识别支票的数据 AlexNetleNet风格的骨干网 VGGResNet：目前最成功的网络提出了残差的结构，可以帮助实现数百甚至上千层的网络 Vision TransformerRNN把上一时刻的输出当成下一时刻的输入 LSTM长短期记忆网络通过输入门和遗忘门控制信息流 Self-Attenton演化学习涌现学习模型：模仿生物的生命演化形式 遗传算法：学习是问题候选假设（解）在进化中的一种竞争，较好的候选假设在自然选择中不断演化 人工生命：模拟生物的进化条件 在连续的世代中有选择地淘汰适应性较低的个体，通过这样简单的过程，生物体的适应性得到提高 演化和涌现出现在群体中 选择的压力不仅来自外部环境，也来自群体中个体相互作用中 遗传算法 genetic algorithms（GA）通过对当前最好的假设模型重组来产生后续假设模型 生成并测试的柱状搜索 一般形式 t:=0，初始化种群P(t) 如果不满足终止条件 评估种群P(t)中每个染色体的适应度 根据适应度函数选择部分染色体 根据所选择的染色体产生后代 根据P(t)中染色体的适应度，选择被替换的染色体，以后代替换 t:=t+1 终止 如何表示染色体？二进制位串的编码 每个属性值用二进制的1位表示 单属性100 sunny 110 sunny||overcast 111 sunny || overcast || rain 多属性合取101 10 (sunny||rain)&amp;strong if then规则101 10 10 决策属性用一位表示 1(Yes)、0(No)、#(Don’t care) 什么是适应度函数？示例 背包问题，假设背包容量为50 1代表选择相应的物品，0代表不选 适应函数目的是找更高的值集合 fit(染色体)=所有物品的货币价值和，当总重量大于50时设为0 种群是一组染色体及其计算的适应度 GA工作在每一代的种群上，第0代种群中染色体随机生成 如何选择染色体？选择父母 锦标赛选择：每次从种群中取出一定数量的个体，然后选择其中最好的一个M进入子代种群，重复该操作，直到新的种群规模达到原来的种群规模 截断选择：根据适应度排序，前f个染色体进入下一代种群，对染色体进行复制，直到填充至种群规模达到原来的种群规模 轮盘赌选择：与适应度成比例选择 当前适应度/总适应度，还可以利用指数函数全算成正值 注意探索和利用的平衡 如何产生后代？遗传算子：对当前群体中选择的染色体进行重组，以产生后代 交叉：选择两个候选个体，分解每一个个体，然后交换分量形成两个新的候选个体 单点交叉 两点交叉 均匀交叉 变异：选择一个候选个体，随机的选择一位，然后取反 常以小概率1/L（L是染色体长度）发生变异 后代种群演化简单方法：直接替代父代染色体：易丢失优秀解 精英法：替换掉最差的 锦标赛法 小生境法：将每一代个体划分为若干类，每个类中选出若干适应度较大的个体作为一个类的优秀代表组成一个群，再在种群中，以及不同种群之间杂交，变异产生新一代个体群 GA的优势 无需理解问题内部的相关性和因果性 以一个随机群体开始，以适应度作为某种启发式 进化论保证整个种群的演化 未解决的问题 表示的问题：编码不规范，表示可能也不准确 约束的问题：单一的遗传算法编码不能全面地将优化问题的约束表示出来，考虑约束的一个方法就是对不可行解采用阈值，这样计算的时间必然增加 搜索效率问题：一般比其他算法慢 过早收敛：遗传算法容易过早收敛 模式m(s,t)表示在第t代种群pt中模式s的实例数量 自然计算 模仿自然界特点 具有自适应、自组织、自学习能力的模型与算法 遗传算法、蚁群算法、粒子群算法、免疫算法 往往用来解决非凸优化的问题（凸优化可以直接用梯度找到最优解） 学习分类器系统维度约简 特征选择 特征诱导/变化 目的： 降低过拟合风险 避免维度灾难 增加可解释性 去除冗余特征 我们很难想象在高维空间中数据之间有什么关系 特征选择N个原始特征，2^N-1非空特征空间，搜索最优的特征子集 搜索方向前向（起点为空），后向（起点为全集），双向 搜索策略穷举、序列、随机 特征评估函数（用于判断特征是否重要）过滤式、封装式 过滤式 使用评价准则来增强特征与类的相关性，削减特征之间的相关性 距离度量、信息度量、依赖性度量、一致性度量 封装式 特征及其与任务目标的相关性 如分类错误率 嵌入式模型正则化，如加上稀疏约束 线性判别分析LDA 计算每个类别的均值,全局样本均值 计算类内散度矩阵Sw，类间散度矩阵Sb 对矩阵Sw-1Sb做特征值分解 取最大的数个特征值所对应的特征向量 计算投影矩阵 主成分分析PCA无监督特征降维方法 找到数据中的主要成分，并以之表征数据 最大可分性：样本点在第一主成分上的投影其离散程度要大于其在第二主成分上的投影的离散程度 最近可重构性：样本点到第二主成分的平均距离都要大于其到第一主成分线的距离 最大化样本点在主成分上投影的偏差 给定去中心化的样本数据（方便算协方差） 投影后数据 计算投影后数据的方差 最大化投影数据方法 max tr(WtCW) 前提：WtW=I 求解优化目标函数：拉格朗日乘子法 独立成分分析因素分析FA假设数据是由多个数据源产生的，并且有噪声，我们想将数据解释成少数不相关因素的叠加 独立成分分析期末第一章-概论各种概念的了解 第二章-聚类 距离度量函数 knn流程 超参数的意义 减少计算复杂度 第三章-无监督学习 聚类准则 聚类评判 三类聚类方法中比较有代表性的：基于试探、系统聚类、动态聚类、常用的评价指标（前沿进展不考咯） 第四章-树学习 概念学习 怎么构造决策树，怎么选择节点 id3 c4.5 cart各种不同的评价指标 第五章-集成学习 集成学习基本原理 bias-variance tradeoff bagging boosting adaboost、GBDT、XGBoost看一看就行 第六章-概率与学习 高斯混合模型 带约束优化、不带约束优化（比如最小二乘） 最大似然估计、期望最大化（核心思想要了解） 第七张-支持向量机 都要看 推导不会现场要求 非线性支持向量机 第八章-神经元与感知机 脑和神经元 感知机学习 线性可分 激活函数 第九章-神经网络 更深入的要求 多层感知机 损失、前向传播、反向传播 第十章-卷积网络 卷积 核心概念、关键模块 第十一章-演化学习 遗传算法 模式理论 第十二章-维度约减 线性判别分析 主成分分析 独立成分分析 第十三章-强化学习 MPD模型 动态规划 强化学习 蒙特卡罗方法 时间差分方法 自举方法、采样 Q学习、TD、回退","tags":["课程笔记"],"categories":["课程笔记","ML"]},{"title":"需求与商业模式创新","path":"/2023/09/05/需求与商业模式创新/","content":"需求与商业模式创新软件工程到底难在哪软件工程“没有银弹”（银弹：对狼人的致命武器，引申为一下子就能解决问题的方法） 问题域和解系统问题的产生地：当现实的状况与人们的期望的状况产生差距时，就产生了问题。 要解决问题，需要改变现实当中某些实体的状态或改变实体状态变化的演进顺序，使其达到期望的状态或演进顺序 这些实体和状态构成了问题解决的基本范围，称为该问题的问题域 软件工程解决问题的基础：模拟与共享软件系统中的某些部分对问题域中的某些部分具有模拟特性 通过这些映射建立的共同知识，就是问题域和解系统之间的共享现象 最后将解系统的模型操作与计算结果用于指导现实世界的问题解决 需求的两个维度需求（要求，问题域端） 信息、娱乐、社交、服务 直接需求、间接需求 不切实际的期望 需求规格说明（解系统端） 数据：现实世界的模型 功能：对模型的操作，将结果反馈回现实世界，（辅助）解决问题 过程式分析：以功能分解为核心 面向对象分析：以封装的数据和对数据的操作为核心 需求的四个基本概念：问题域、需求、解系统、需求规格说明 需求的定义 IEEE 用户为了解决问题或达到某些目标所需要的条件或能力； 系统或系统部件为了满足合同、标准、规范或其它正式文档所规定的要求而需要具备的条件或能力； 对（1）或（2）中的一个条件或一种能力的一种文档化表述。 需求工程是软件工程的一个分支 需求和设计的主要区别，需求阶段关注系统和外部，设计主要架构系统本身 需求工程的难点本身是创造性的活动 不可复用，接近于艺术 需要对问题所在的领域有深刻的认识 需要完整的设计思维方法论，并系统持续的运用 只要人类还试图掌握程序运行的方向与原因，需求就无法被忽略 无聊经济 b站：冷门、垂直、分享 商业模式类型b站收视体验：分区+推荐+订阅，内容+弹幕，评论+回复，转发+话题，内容推广，社区管理 多边商业平台模式：两个或两个更多独立但相互依存的客户群体进行连接 平台推广：google三大件：google、adwords、adsense 平台收益流补贴主机游戏核心：打造差异化的游戏体验（要把PC和手机的游戏体验比下去） ps&#x2F;xbox 硬核体验（硬件亏钱，游戏赚钱，非常非常痛恨盗版，因为玩盗版卖一台亏一台） wii 性能与游戏权衡（主机本身可以盈利） Switch 开创全新赛道（因为每卖一台机器都可以赚钱，所以官方几乎默许盗版） 多边平台商业模式总结 价值主张一般体现在如下三方面 吸引用户、群体配对、利用平台交易渠道降低成本 客户群体相互依存，无法独立 核心资源是平台，成本主要来自于平台的维护和开发 三项关键活动：平台管理、服务实现、平台升级 轻资产（搜索引擎） vs 重资产（京东：自营物流网络，盒马：自建冷链） 多个收益流，补贴正确的客户群是定价决策的关键 如何设计收益流补贴？如何定价？ 免费商业模式至少有一个关键的客户群体可以持续免费地享受服务 不付费客户得到的财务支持来自于另一个客户群体 对价格为0的商品的需求要数倍于定价于一分钱或更高的商品 数字产品与服务的复制传播成本接近于0（海量用户下边界成本于0） 广告商业模式 Metro,瑞典的东方卫报 新闻价值有限，有价值的报纸依然要有订阅费（The Guardian除外）（NYTimes，The Time，The Economics） FaceBook大幅增长广告收益 复合增长率59%（直接收购Instagram，WhatsApp） 免费增值 大量用户从免费服务获益，少量用户为增值服务付费 关键指标：免费用户服务成本、增值用户转化率 典例 照片分享网站 百度网盘、印象笔记 OneDrive 开源：Redhat，IBM转向开源咨询 Skype 保险：倒转的免费增值 大部分客户定期支付小额费用以补贴小部分产生实际索赔的项目 强制险：五险一金、交强险、出国旅游意外险 核心资源：平台 成本：客观的固定成本、免费账户的低边际成本服务、增值账户成本 关键业务：客户关系自动且低成本，免费用户向增值用户转化率是重要指标 更加倒置：Cookpad食谱网站，付费的比免费的还多 诱饵·陷阱 免费手机 合约机：手机免费，套餐收费 吉列剃须刀 刀柄便宜，不停地买刀片 类似的还有打印机+墨盒&#x2F;硒鼓 第三方耗材vs三年保修 施乐公司敌意收购事件 重要成本结构 初始产品补贴与后续产品的成本 慢慢融入平台与免费增值 新套餐体验+自动续费 各类社交裂变式促销 游戏本体+DLC或平衡性无关的道具 活动门票式的促销 知乎大平台笼罩下的新创业机遇 BATJ，TMDP为代表的各领域平台的壮大成熟增大了后续的创新创业的难度 机遇 颠覆性的技术升级 5g、大模型 我们倾向于高估科技在短时间的影响，低估长期的影响 更多赛道的开拓 极致的客户细分（更好的满足需要） 支撑原理：长尾商业模式 长尾需要：独特主张以打动人心、构建自己独创的价值流动与商业模式 我们想要的商业模式客户细分 一家企业想要获得的期望服务的不同的目标人群和机构 细分条件：需求催生新供给、需要新分销渠道和客户关系类型、产生的利润率不同、愿意为某方面的特殊改进买单 需要谨慎处理客户的细分与取舍 互联网+软件属于大众还是小众大众：没有明确的用户认知 小众：明确的目标 互联网+软件多是大众 价值主张为某一客户群体提供能为其创造价值的产品或服务 让事情变得更简单（价格）、让事情更复杂（定制）、让事情透明（一站式服务） 创新 性能 定制 保姆式&#x2F;一站式服务 设计 价格 缩减成本 风险控制 可获得性 便利性&#x2F;实用性 渠道通路一家企业如何同它的客户群体达成沟通并建立联系，以向对方传递自身的价值主张 渠道的五个阶段与运营方式：知名度-评价-购买-传递（线上、线下、外卖、拼多多）-售后（三包、评论、种草） 订金可以退，定金不可以退 渠道可以自有，可以合作，混用 合作方渠道：蓝绿大厂、品牌贴牌和认证授权、能主动引发流量的社交类互联网平台 客户关系一家企业针对某一客户群体所建立的客户关系的类型 ​\t一些靠人员维护 vs 一些是自动化设备 客户关系类型 私人服务 personal assistance： 商场导购、柜台服务与电渠、销售员 专属私人服务 dedicated（私人教练） 自助服务 self-service（话费流量充值、银行普通业务） 自动化服务 automated-services（各类平台推荐系统、网站导航设计、无货推荐、加入购物车、立即购买） 社区 communities（王者营地、花粉俱乐部） 客户共同创造 co-creation （元气森林不停地换口味、游戏版本更换反馈、UGC平台（让用户自己创造内容，但是当时没有智能手机，土豆提出时技术不足，但是音频可以，所以有一部分分化出了喜马拉雅，后来有了智能手机，剪映）） 多边平台商业模式：尽可能容纳新用户类型并促进各方交互 看起来好像是电商平台，但其实还是对于传统购物商场策略的模拟 收入来源企业从每一个客户获得的现金收入 探索用户真正愿意付费的点 一次性交易收入、持续收入 定价机制 固定 浮动 收入来源方式 资产销售：实物产品所有权转让 使用费：电信、宾馆、付费网游点卡、公共交通车票 会员费：健身卡、游戏月卡、公共交通月票、音乐会员 租赁：（所谓的共享经济）充电宝（花费并不大，在热销景区也可以卖到100元一小时），特定资产在特定时间的使用权转移并获益，一种很重的模式 许可使用费：专利授权、版权（图片、音乐、字体）（版权流氓）、加盟（加盟费，控制进货渠道）或特许经营（JetBrains License） 经纪人佣金：信用卡、手续费、中介 广告费：传媒、品牌策划、软件业与服务业、（广告费增长乏力，分蛋糕太多） 核心资源 保证一个商业模式顺利运行所需的最重要的资产 用于：价值主张的创造与提供、开拓市场、维护客户关系并获益 可以“自主拥有”或者“寻求合作” 核心不意味着不可替代 核心中核心：对细分客户的认知和对价值主张的塑造（所有的UP主） “拥有”意味着额外的管理、折旧和“故障”，“合作”意味着让出的利润空间与颠覆式的生存危机-从“核心”向外扩展：拥有 - 合作 类型 实物资源：一堆A100、分销渠道、销售点管理系统 知识性资源：品牌、专利（芯片）、知识产权与体系 人力资源：出色的营销团队、对于创新性和知识密集产业最重要 金融资源 financial：花呗、车贷、互联网金融（润滑消费和经营），风险投资（国资）、资本市场-助力创新企业快速增长 大厂的“屯人”竞争 把会做某件事的人都囤积起来，不让他们流到竞争对手 挖友商墙角+高薪囤积实习生、应届生，大厂“公务员化”，实际：圈养+考核+“输送人才” 第一次工作要进核心部门 劳动力高价的来源：“赛道稳定程度”-对个人创造力的依赖程度 举例：芯片制造与芯片设计，IT开发&#x2F;产品&#x2F;算法&#x2F;金融，体制&#x2F;公司&#x2F;科研&#x2F;创业 如何应对：持续知识体系构建下的“肉食者鄙”-初步能够观察互联网市场的持续变化+“适当追求赛道风险”-选择对个人创造力依赖强的业务领域+”无限进步“-面向个人长期持续进步（能够应对未知）的学习与工作-会点大厂不会的 风投的利弊 商业模式初步可行前提下的扶植验证与大规模复制 互联网+时代创新的关键要素（钱+人+资源+渠道） 流派：赛道 vs 赛车 vs 赛手 资金使用效率决定风投追求确定性的结果：要么赢，要么毁灭 天性重“复制”、重“退出”导致的“信托化”、“泡沫化” 容易诱发：揠苗助长+无序竞争+垄断兼并&#x2F;异地鸡毛+压制创新 “元宇宙”和Web3.0的某种必然性：多项风投技术投资的逻辑延伸（而非用户需要） 本轮“互联网寒冬”的重要诱因-被美元回流与美股脱钩打断的“烧钱扩张” 关键业务 保证其商业模式正常运行所需做的最重要的事情 价值主张、获得市场、客户关系与收益 与价值主张强相关，价值主张的具象化 重要合作 保证一个商业模式顺利运行的供应商和合作伙伴网络 非竞争者之间的战略联盟 微信生态 vs 苹果生态 fortnite vs App Store + Google Play 竞争者之间的战略合作 红蓝快乐水、微信支付与支付宝、米国两党制 新业务的合资公司 大厂“生态”：3q大战之后的腾讯联盟 vs 阿里直系 稳定供应关系的供应商和采购商 产业园、苹果认证供应商、闭环的互联网影视平台 合作动机 优化与规模效应-提高业务效率 特殊资源及活动的获得 降低风险和不确定性-降低业务风险 成本结构商业模式的评估商业模式环境评估 远见 行业管理趋势 社会和文化趋势 技术趋势 社会经济趋势 市场分析 市场分类 诉求和需求 市场问题 切换成本 收入吸引力 宏观经济 经济基础设施 大宗商品和其他资源 资本市场 全球市场情况 竞争分析 供应链和价值链 利益相关 竞争对手 挑战者 替代产品与服务 网易考拉海购 市场：2014年消费需求旺盛，对国外商品期待较高 市场分类：为中层家庭打造“正品低价”的体验，聚焦母婴产品 需求和诉求：经济承受范围内的有品质、有保障的购物体验 切换成本 收入影响力：识别与收入吸引力和定价能力相关的因素，主要选择了母婴产品，因为高复购、高附加值、品质重要、“不能亏了孩子”，没有选择竞争激烈的美妆产品，也没有选收入不稳定或较弱的烟酒、手表、电子类产品 技术趋势：大型电商平台的技术发展已经较为成熟，但是品牌种草、直播、拼购红包与社交裂变，购物社交化、娱乐化，拼购与市场下沉 行业管理趋势：影响你的商业模式的管理规定和管理趋势，收取跨境电商综合税，但是洋品牌正在本地化，国内品牌崛起 社会文化趋势：国内对“洋”产品和服务的认知逐渐冷静，新国货 社会经济趋势：三四线城市购买能力逐渐增强，一二线城市生活压力加大，中高端消费能力的增长放缓，极简主义逐步流行 行业影响力：主流竞争对手（阿里京东）能力强，有专长，耕耘时间久，覆盖面广，市场规模巨大 挑战者：新出现的玩家以及它们的商业模式的不同，市场下沉拼多多，品牌种草小红书，专业清仓唯品会 替代产品和服务：人肉代购，社交网络，国外免税店与折扣店 供应商与价值链上的其他厂商：0到1的重资产模式 利益相关者 全球市场情况：08-20，经济增长放缓，国家尝试供给侧改革 资本市场：与资本需求相关的当前资本市场，资本寒冬 国内产品壁垒对商业模式的总体评估（考试重点）Amazon.com整体评估 评估自己的优势和劣势 运营好，技术高 销售产品利润低 销售额高 拓展机会 配送 云 卖更全面的东西 小米2015年：“小米是电商” 对商业模式做SWOT评估传统SWOT分析与商业模式画布结合 画布的存在帮助聚焦SWOT分析，避免模糊，实现聚焦 按照价值主张、成本&#x2F;收入、基础设施、客户界面展开评估 网易严选价值 性价比是一个非绝对的概念 共情与性价比，品类扩增导致价值主张没有网络效应，无法获得用户信任 缺基于反馈的选品设计渠道 网易严选遇到投诉比较多 成本&#x2F;收入 利润问题 收入是否可预期 是否有经常性收入 收益来源是否多样化 收益来源是否可持续 是否在只出钱就有进账 客户真正想买的是否是我们提供的 我们的定价机制能否抓住客户全部的购买意愿 定价机制的进一步讨论 三级价格歧视 SWOT：客户界面 网易严选的情感诉求在忠诚度上明显弱于PDD-高性价比与便宜好玩 百亿补贴适合知名高流量且可以较高频次更换的产品 （作为消费者：不要买立省百分百） SWOT：基础设施 核心资源是否易被复制 资源需求是否可以预测 我们是否在正确时间部署了合适资源 关键业务执行是否有效 关键业务是否易被复制 执行质量如何 自由活动和外包活动是否达到理想平衡 是否聚焦 与重要合作伙伴关系是否融洽 长尾、拆分经典商业模式 多边商业模式 免费商业模式 长尾商业模式 开放式的商业模式 分拆商业模式 长尾商业模式 提供相当多种类的小众产品，每类卖出量相对很少，但汇总的销售收入可以与传统模式销售媲美 行业内20%的产品占据绝大多数销量 长尾商业模式专注于销售剩下80%内尽可能多的品类，并获得媲美主流产品销售收入 在高效的互联网 样例： 图书出版：从选题加工 到 佣金平台，自助出版 乐高数字在线：生产与渠道的复用，提高用户忠诚度，挖掘用户额外需求，不仅要占那20%，还要占那80% 长尾商业模式依赖与多边平台链接小众客户和产品 长尾平台收益来源五花八门，广告、产品销售、订阅费 长尾的平台，平台的长尾经典： Soul、贴吧、陌陌&amp;探探、比心、Blued（荷尔蒙社交）、Github、找工作黑名单、全国停贷名单、全国楼盘烂尾名单、全国导师黑名单… 为长尾内容服务的长尾类型平台：A站，专注于为二次元服务 长尾的发展趋势：坚持 - 转化长尾之后： 突破因传统生产、设计、营销导致的二八曲线，长尾部分扁平化，形成若干“小众中心”，并分别向“大众中心”转化 成功转化： B站：二次元-Z时代文化社区-共情 原神：二次元仿品-“Genshin Impact”-造梦 客户洞察与构思六种商业模式设计方法 客户洞察 构思 视觉化思考 模型构建 讲故事 场景 目标模型要考 涉众分析要考 涉众分析互联网产品的涉众涉众识别主体依赖不考 看看共赢分析 期末考试 需求部分需求获取 30’ 需求获取上半段 20’ 确定项目前景与范围 10’ - 目标模型 涉众分析 10’ 涉众评估 Power-Internet Power-Attitude 涉众共赢 Stakeholder-Issue 需求获取下半段 面谈、原型、观察三大获取手段的联系与区别 需求分析 需求分析基本任务 需求规格说明 需求验证与管理 三挑一 需求验证基本活动 需求管理任务与活动 需求变更控制过程、组织与注意事项","tags":["课程笔记"],"categories":["课程笔记","需求与商业模式创新"]},{"title":"人机交互","path":"/2023/09/05/人机交互/","content":"人机交互HCI human computer interaction 凡是与人交互的计算系统都有人机交互，包括手机、电脑、微波炉 HCI is a discipline concerned with the design, evaluation and implementation of interactive computing systems for human use and with the study of major phenomena surrounding them. –ACM 中国人机交互圈 CCF 学界 UXPA 工业界 用户体验user Friendly –&gt; usability –&gt; user exprience 不能够设计用户体验，只能为用户体验而设计 设计和开发人员易犯的错误 假设对于技术的使用方式的理解可以通过他们的自主思考实现，即想象这个技术是如何被使用的 认为每个人都是相同的 以用户为中心的设计方法本科人机交互研究的内容交互设计方法 评估技术 示例系统和案例学习 设计方法 实现技术和工具 命令行交互–基于记忆的交互 图形界面–基于识别能力 人机交互的发展历史一大特点：新的交互方式出现后，旧的交互方式往往并不会消失 1945 Vannervar Bush “As we may think” Memex 1960 人机共生 1970 施乐公司 Palo Alto研究中心 1980s Interface -&gt; Interaction 1990s 智能化交互、多通道交互… 四个阶段 批处理阶段（打纸袋，插硬件） 联机终端时代 图形用户界面时代 人机交互中常见的问题 不要隐藏关键的信息 将操作放在正确的地方 正确的命名 EEC模型stateDiagram 形成目标 --> 形成意图 形成意图 --> 明确动作 明确动作 --> 执行动作 执行动作 --> 外部世界: 执行阶段 外部世界 --> 感知系统状态: 评估阶段 感知系统状态 --> 解释系统状态 解释系统状态 --> 评估输出 评估输出 --> 形成目标 执行隔阂： 我想这么做，但是系统没有提供我想要的（e.g 找不到确认按钮） 评估隔阂：系统给了这个操作并且我执行了，但是我不能确定事务的状态（e.g 支付完成后既没有支付成功也没有支付失败） 扩展EEC模型可用是用户使用的基础 可用性目标：目的是为交互设计人员提供一个评估交互式产品和用户体验各方面的具体方法 易学性：“十分钟法则” 易记性：学会以后能够迅速回想起使用方法 效率高：使用这个系统后应该比不用这个系统好 效用高：提供了正确的功能，能让用户做他们需要做的事 安全性：避免用户陷入危险（e.g 减少危险功能被直接启动的风险） 用户体验目标：多样性的用户体验目标，涵盖一系列主观感受 体验和可用性的关系主观vs客观 矛盾性 大家喜欢玩有挑战性的游戏 用锤子砸地鼠比用鼠标点更累但是更有趣 有些可用性和用户体验目标是不兼容的 设计一个安全又有趣的过程控制系统是不可能或不可取的 认识和理解可用性和其他用户体验目标之间的关系是交互设计的核心！ 四种主要技术 完整的可用性工程过程 了解用户 竞争性分析 设定可用性目标 用户参数的设计 迭代设计 产品发布后的工作 简化 用户和任务观察 了解产品的目标用户是可用性工程的第一个步骤 注意 直接与潜在用户进行接触 不要满足于间接的接触和道听途说 “你”不是用户！ 场景 简化的边做边说 让真实用户在使用系统执行一组特定任务的时候，讲出他们的所思所想 最有价值的单个可用性工程方法 可了解用户为什么这样做，并确定其可能对系统产生的误解 实验人员需要不断地提示用户，或请他们事先观摩 启发式评估 专家以角色扮演的方式模拟目标用户 5名专家大致能发现80%的问题，被认为是最恰当的可用性测试用户数量 启发式原则 设计规则 说明 不是完美的，有的还相互矛盾 基本来自经验 必须和实际情况相结合 基本规则 可学习性 灵活性 健壮性 黄金规则 尽可能保持一致 … 十条启发式规则 系统状态的可见度 系统和现实世界的吻合 让用户听得懂 用户享有控制权和自主权 一致性和标准化 不要搞得像是好多设计师设计的 避免出错(预防并处理错误) 依赖识别而非记忆 使用的灵活性和高效性 帮助文档 简单&#x2F;最小化设计 帮助用户及时识别诊断恢复错误 评估 评估应该依赖于产品的用户 评估与设计应结合进行 评估应在用户的实际工作任务和操作环境下进行 要选择有广泛代表性的用户 快速评估：找到用户就问可用性测试 20c80s主导方法 评测典型用户执行典型任务时的情况 问题：测试用户数量通常较少（最佳用户数5-12，一般研究得有20+）。不适合进行细致的统计分析 实地研究（feild research）基本特征：在自然环境中工作 目的：理解用户实际工作庆幸以及技术对他们的影响 作用： 探索新技术的应用契机 确定产品的需求 促进技术的引入 评估技术的应用 重难点 如何不对受试者造成影响 控制权在用户，很难预测即将发生和出现的情况 预测性评估 研究人员通过想象或对界面的使用过程进行建模 基本目标： 用户可以不在场 整个过程快速、成本较低 评价指标 提供的信息 相应的及时性 干扰程度 所需资源 实验假设零假设假设不同条件下没有差异 备择假设一般和零假设相反 因变量自变量自变量是研究人员感兴趣的因素 因变量随着自变量改变发生变化 寻找自变量的变化是否会引起因变量的变化，以及如何引起因变量的变化 研究必须可以复现 实验条件：我们需要比较的不同技术、设备或程序 试验单位：我们应用实验条件的对象 分配方式：将实验单位分配到不用实验条件的方式，可以掷骰子，可以用随机数表 实验设计真正的实验 以至少一个可检验的研究假设为基础，并旨在验证它 通常至少有两种条件（实验条件和对照条件）或组（实验组和对照组） 因变量通常使用定量测量 通过各种显著性检验对结果进行分析 具备不同的参与者样本 如果没有使用随机分配但是有对照组，只能算准实验，如果对照组都没有，那么就不是实验了 绿野仙踪法：在控制条件时，如果实在是达不成某种条件，比如不出错的语音识别器，那么就搞个活人来扮演机器 实验结构 实验中我们要研究多少自变量 基本设计 or 析因设计 每个自变量有多少个不同的值 条件数 &#x3D;&gt; 组件设计、组间设计、裂间设计 组件设计：每个参与者只暴露在一种实验条件下优点：设计简洁、避免学习效应 缺点：结果受个体影响大、样本量大 组内设计：一组用户要参加多种实验条件减缓学习效果和疲劳 使用拉丁方设计进行平衡（专门的工具生成） 多个自变量的实验析因设计 分析数据时，比较同一行可以检查不同键盘的影响，任务效果可以通过比较同一列的数据来检验 组内设计or组间设计 裂区设计 析因研究中的一种设计，既有组间成分，又有组内成分 举例 研究问题：年龄和GPS的使用情况对驾驶效果的影响 自变量：年龄（组间设计）、有无GPS（组内设计） 优点：允许在一个实验中研究两个或两个以上自变量之间相互作用的影响 相互作用可以被描述为“一个自变量对因变量的不同影响，取决于另一个自变量的特定取值” DECIDE评估框架六步 决定评估需要完成的总体目标 评估目标决定了评估过程，影响评估范型的选择 问什么要评估 产品设计是否理解了用户需要 为概念设计选择最佳隐喻 界面是否满足一致性需要 探讨新产品应做的改进 发觉需要回答的具体问题 找出为什么用户更喜欢买纸质机票而不是互联网电子机票 问题 用户对新票据的态度如何 用户是否能够通过互联网订票 是否担心交易的安全性 订票系统界面是否友好 问题可以逐层分解 选择评估范型和技术 范型决定了技术类型 必须权衡实际问题和道德问题 最适合的技术可能成本过高 或所需时间过长 或不具备必要设备或技能 可结合使用多种技术 不同技术有助于了解设计的不同方面 不同类型数据可从不同角度看待问题 组合有助于全面了解设计的情况 明确实际问题 应选择恰当的用户参与评估 能代表产品的目标用户群体 可以先做测试，确定用户技能所属的用户群 任务时间多长 20分钟休息一次 可在任务执行前，安排用户熟悉系统 设施及设备 期限及预算是否允许 是否需要专门技能 处理道德问题 保护个人隐私 除非获得批准，否则书面报告不应提及个人姓名，或把姓名与搜集到的数据相联系 可以申请IRB许可证 评估、解释并表示数据 搜集什么类型的数据，如何分析，如何表示 通常用评估技术决定 可靠性 给定相同时间，不同时间应用同一技术能否带到相同结果 非正式访谈的可靠性较低 有效性 能否得到想要的测量数据 偏见 评估人员可能有选择地搜集自己认为重要的数据 范围 研究发现是否具有普遍性 环境影响 霍桑效应 小规模测试 Pilot Study先试试水 对评估计划进行小范围测试 以确保评估计划的可行性 如检查设备及使用说明 练习访谈技巧 检查问卷中的问题是否明确 小规模试验可以进行多次 类似迭代 可用性问题分级对问题进行分级 方法一：基于量化数据的分级 方法二：问题严重性的主观打分，取平均值 方法三：可用性分级的两个因素 有多少用户会遇到这个问题 用户受到该问题困扰的程度 用户测试 在受控环境下测量典型用户执行典型任务的情况 目的是获得客观的性能数据，从而评价产品或系统的可用性，如易用性、易学性 最适合对原型和能够运行的 测试设计 用户测试须考虑实际限制并做出适当的折衷 确保不同参与者的测试条件相同 应确保评估目标特征具有代表性 实验可重复，但通常不能得到完全相同的结果 以DECIDE框架为基础 定义目标和问题 目标描述了开展一个测试的原因，定义了测试在整个项目中的价值 目标对关注点的说明和检查 设计测试任务 观察用户两种方式 真实环境中的观察 观察者既可以观察，也可以参与实验 实验室观察 测试区，观察区 用户坐在家中测试 优点 提供了可控且一致的评估环境 缺点 人为环境，不自然 实验室观察生理反应监控选择难以伪造的生理指标监控 观察中的问题 不知道用户在想什么 边做边说 两位用户共同合作，以便互相讨论、相互帮助 实际场景观察可以发现很多实验室观察不到的问题 几个难题 要观察结果 如何根据紧凑的开发期限和开发人员的技能相应修改现场研究技术 如何降低噪音，测试中断及其他易使注意力分散的外界干扰 方案一：健壮的评估设计 方案二：将测试协议设计成包含“有计划的干扰” 注意事项 观察人员自始至终应尽量保持安静 不要在实验初期提供帮助 观察人员看不懂用户在干嘛时要问一问 数据记录 纸笔记录（现场记录） 音频记录 … 日志与交互记录举例：命令行操作系统超过30%的错误是拼写错误 定性分析分析方法详细分析一般都不用，只用粗略分析 定量分析平均值、标准差、t检验 访谈步骤 开始 访问人先介绍自己 解释访谈的原因 热身 先提出简单的问题 正式 访谈类型 非结构化访谈 结构化访谈 半结构化访谈 集体访谈 问卷 常规问题： 年龄、性别、职业、居住地、应用计算机的经验 自由回答问题： 你能对这个界面提出改进意见吗 能够提出设计人员没有考虑到的建议 其实5分满意度，至少要3.6以上才算基本满意 用户满意度调查表QUIS认知走查 逐步检查使用系统执行任务的过程，从中找出可用性问题 专家来做，无需用户参与 认知走查的主要目标是让系统易于学习 … 协作走查 由用户、开发、专家一起合作 启发式启发式评估基于启发式原则，不过这也只是一个参考，你可以有自己的评估原则 问题的严重性分类 严重性等级： 表面问题 次要问题 主要问题 灾难性问题 交互需求设计 需求 关于目标产品的一种陈述，它指定了产品应该做什么，或者应如何工作 应该是具体的、明确和无歧义的 完整下载任何网页的时间应少于5秒 用户特性体验水平差异 程序员总是想创造适合专家的界面 市场人员想创造适合新手用户 数目最多的是中间用户 中间用户往往被忽略 设计目标 让新手无痛成为中间用户 别阻碍用户成为专家 让中间用户感到愉快 开发人员总是喜欢自参考设计 新手用户 特点 敏感，很容易有挫折感 设计要求 不能将新手状态视为目标 让学习过程快速且具有针对性 专家用户 特点 对缺少经验的用户有很大的影响 喜欢快捷键 中间用户 特点 需要工具 直到如何使用参考资料 能够区分经常使用和很少使用的功能 希望还是要有高级功能 设计要求 工具提示 找到你的用户 人物角色是与系统有关的用户假定的一组公共需要、兴趣、期望、行为模式和责任 这些属性可能是若干用户共有 同一个用户也可以扮演系统的任意个不同角色 注意用户要被细分，同样是来高考咨询的学生，拿着985分数的学生和拿着普通本科的学生是不一样的，中产家庭的学生和低产家庭的学生和富裕家庭的学生和红三代也是完全不同的，我们最主要关注的还是核心用户和广大用户 建模过程 拼凑 组织 细节 求精 确定需求 需求验证 可以直接展示原型 原型分为低保真和高保真（比如用visual basic） 鼓励多用低保真模型(高保真模型限制你的想象) 实验分析通过方差分析进行 误差 第一类误差：零假设为真，却拒绝了原假设（轻信错误，造成的后果更严重，因为会比目前的状况更糟糕） 第二类误差：零假设为假，但是却没有推翻零假设（无知错误，会导致失去改变现状的机会） p值：如果零假设成立，获得观测数据的概率，表述为自变量对因变量的影响有统计学意义 设计简单原型 通过验证性的场景剧来检查设计 关键线路变种场景剧本：用户不想打电话了，想发电子邮件 必须使用的场景剧本：手机被卖了，要删除原有信息 边缘场景使用剧本：用户添加联系人，但是两个联系人同名了 卡片分类格式塔心理学 相近性原则：空间上靠近的物体容易被视为一组 相似性原则：长得相似的东西容易被分为一组 连续性原则：共线或者具有相同方向的物体容易被划为一组 对称性原则：对称且能够组合为有意义单元的物体会被组合在一起 完整和闭合性原则：人们倾向于忽视轮廓而将其视作一个完整的整体（页面上的空白可以帮助实现分组） 前景与背景：前景和背景在某些情况下可以互换 任务培训可能考","tags":["人机交互"],"categories":["课程笔记","人机交互"]},{"title":"嵌入式系统","path":"/2023/09/04/嵌入式系统/","content":"1.嵌入式系统概要计算机发展三大阶段 研究大型机 个人计算机PC 后PC时代（becoming an old fashion） 术语演化 泛在计算（任何时间任何地点都在算） 不可见计算机（计算机被集成到物件） 普适计算（计算设备进入日常生活）Bill Gates提出 环境智能（未来家庭、智能楼宇） 嵌入式系统定义IEEE：用于控制、监视或辅助操作机器和设备的装置 国内：以应用为中心，以计算机技术为基础，软硬件可裁剪，适用于应用系统对功能、可靠性、成本、体积、功耗有严格要求的专用计算机系统（一个具有特定功能或用途的隐藏在某种设备中的计算机软硬件集合体，没有固定的特征形状） 老师喜欢：包含计算机，但又不是通用计算机 不单单指嵌入到某个设备，也可以是被嵌入到某个过程 嵌入式系统三要素 嵌入性：嵌入到对象体系，有对象环境要求 专用性：软硬件按对象进行裁剪 计算机 CPS 信息物理系统 Cyber-Physical System 嵌入式和物理学深度融合 通信的重要性无线感知网络-wireless sensor network许多空间中分布的自动装置组成的无线通信计算网络，使用传感器协作监控不同位置的物理或环境状况 IOT 物联网 Internet of Things比上面那个功能强多了，智能化识别、定位、跟踪、监控和管理 物联网技术开发被称作工业4.0 2.导论嵌入式系统的组成 一般由嵌入式硬件和软件组成 硬件以微处理器为核心集成存储器和系统专用的输入输出设备 软件包括：初始化代码及驱动、嵌入式操作系统和应用程序等 ROS 集成操作系统 OTA 空中下载技术 3.处理器和处理器体系结构类型多关注成本最重要的成本是系统成本 成本主要包括: 一次性开发成本 硬件BOM，外壳包装，软件版税 批量产品的总体成本=NRE成本+每个产品成本*产品总量 每个产品最后的成本=总体成本/产品总量=NRE成本/产品总量+每个产品成本 实时性和可靠性的要求 大多数实时系统都是嵌入式系统 多数嵌入式系统有实时性要求 嵌入式系统要求有出错处理和快速启动的功能 大多数嵌入式系统的软件一般都包括一些机制，比如硬件看门狗计时器，软件的内存保护和重启动机制 适应多种处理器、可裁剪、轻量型、实时可靠、可固化的嵌入式操作系统 由于嵌入式操作系统的特点，嵌入式操作系统多种多样 大多数商业嵌入式操作系统可同时支持不同种类的嵌入式微处理器。可根据应用的情况进行剪裁、配置 嵌入式操作系统规模小，所需的资源有限如内核规模在几十KB，能与应用软件一样固化运行 一个实时内核，一般采用基于优先级的可抢占的调度算法（为了满足实时要求） 可靠 旧的交叉开发工具已经不那么流行了嵌入式系统的分类 按嵌入式处理器的位数来分类 四位 八位 十六 32 64 按应用来分类 按速度 强实时系统 一般实时系统 弱实时系统 按确定性分类 硬实时：系统响应时间不能得到满足，系统就会寄掉 软实时：不满足也不会寄掉 准实时：两个之间，偏向于软实时 按照嵌入式软件的复杂程度分类 循环轮询系统 有限状态机系统 前后台系统 单处理器 发展趋势 嵌入式人工智能 安全 以往的安全策略，由于嵌入式设备不具备通用计算性，可能不可用 设备接入公网后漏洞百出 不断增加的计算需求 互连的需求 灵活性需求 软硬件协同设计 更高集成度 IP重用 设计方法的多样性 云、边缘计算（云边端计算） 4.嵌入式系统设计嵌入式系统面临的挑战 需要多少硬件？ 如何满足时限要求，如何处理多项功能在时间协调上的一致关系？ 如何降低系统功耗？ 如何保证系统可升级？ 如何保证系统可靠的工作？ 嵌入式系统设计者要求 懂得整个系统架构 详细了解硬件的细节 详细了解硬件的细节 软件设计满足 实时要求 低功耗 代码量小 详细了解领域知识 设计目标 成本 性能 功耗 尺寸 可伸缩性和可重用性 容错 … 体系结构设计 主要组件 硬件软件 软硬件划分 嵌入式系统的设计涉及硬件和软件，设计中必须决定什么功能由硬件实现，什么功能由软件实现 硬件和软件具有双重性（有很多问题既能用硬件实现，也能用软件实现） 算法 加密解密 编码解码 压缩解压 … 数学运算 浮点运算,FFT,… … 软硬件技术对系统结构的影响 软硬件设计的趋势 嵌入式系统设计方法的演变 以PCB（印刷电路板）、CAD（电脑辅助设计）和在线仿真器为主要工具 EDA（电子设计自动化）和EOS（嵌入式操作系统）为开发平台 以IP（知识产权）内核库为设计基础，用软硬件协同设计技术的系统级设计方法 传统嵌入式系统的设计过程 基本特征 系统已开始就被划分为软件和硬件两大部分 软件和硬件进行独立开发设计 硬件优先 隐含的一些问题 软硬件之间的交互收到很大限制 凭经验划分软硬件 软硬件之间的相互性能很难评估 系统集成相对滞后，NRE（一次性工程费用：开发新产品的单次成本）较大 因此： 设计质量差 设计修改准 研制周期不能有效保障 软硬件协同设计HW/SW Co-design 任务并发管理 高级的转换 设计空间探索 软硬件划分 编译、调度 stateDiagram behavior --&gt; SW: partitioning behavior --&gt; HW: partitioning SW --&gt; compilation HW --&gt; synthesis compilation --&gt; 验证方案 synthesis --&gt; 验证方案 4.硬件部分硬件总览 传感器：将非电信号转为电信号 A/D D/A converter：模拟信号与数字信号之间的转换 微控制器 展示 执行器 actuator 硬件平台 cpu bus memory I/O 嵌入式微处理器Embedded Microprocessor 流行的微处理器指令集 ARM架构： ARM（Advanced RISC Machine）是一种精简指令集计算机（RISC）架构，最初由英国的ARM Holdings开发。它在移动设备（如智能手机和平板电脑）和嵌入式系统中得到广泛应用。 ARM架构具有较低的功耗和较高的能效，适合于便携式设备。它采用了三级流水线结构，具备较高的指令并行性，并且支持多核处理器。 MIPS架构： MIPS（Microprocessor without Interlocked Pipeline Stages）是另一种RISC架构，最初由美国的MIPS Technologies开发。它在早期计算机和嵌入式系统中得到广泛应用。 MIPS架构以其简洁的设计和高性能而闻名。它采用了五级流水线结构，具备较低的指令延迟和高的指令并行性。MIPS架构在路由器、嵌入式控制系统和一些游戏机中得到广泛应用。 PowerPC架构： PowerPC是由IBM、摩托罗拉（Motorola）和苹果（Apple）共同开发的RISC架构。它最初是为个人电脑和工作站设计的，但后来在游戏机和服务器领域也有广泛应用。 PowerPC架构在科学计算和高性能计算领域表现出色。它采用了乱序执行（Out-of-Order Execution）和超标量技术，具备较高的性能和并行处理能力。 x86架构： x86架构是英特尔（Intel）和AMD等公司开发的复杂指令集计算机（CISC）架构，最初用于个人电脑。现如今，x86架构在桌面计算机、服务器和数据中心中占据主导地位。 x86架构具有广泛的软件支持和较高的兼容性。它采用了复杂的指令集，可以执行多种复杂的操作。x86架构的一些变种包括IA-32和x86-64（也称为AMD64或Intel 64），后者为64位扩展。 RISC vs CISC精简 vs 复杂 RISC比较好做编译器优化 RISC-V 简单、完全开源且免费 基准指令和扩展指令分开，可以做定制化的模块和扩展 提供32、64、128位指令集 设计芯片需要考虑的五件事 成本 生态系统 碎片化风险 安全性 设计保证 嵌入式微处理器 种类繁多，按位数可分为4、8、16、32、64 嵌入式微处理单元（MPU） 嵌入式微处理器就是和通用式计算机处理器对应的cpu 功能和微处理器基本一样 体积小、功耗少、可靠性高 有的可提供工业级应用 嵌入式微控制器（MCU） 嵌入式微处理器将整个计算机系统的主要硬件集成到一块芯片中，一块芯片内部就有了POM、EPOM、RAM、bus、Timer、I/O、串行口等各种必要功能和外设 特点 一个系列，多种衍生 单片化，可靠，功耗低，便宜 主力军，份额50% 一般用于性能比较低的产品，比如洗衣机冰箱的嵌入式系统 一般是八位或十六位 嵌入式DSP 嵌入式DSP是专门用于信号处理方面的处理器，其在系统结构和指令计算方面进行了特殊设计，具有很高的变异效率和指令执行速度 应用领域 嵌入式SoC 追求产品系统最大包容的集成器件，绝大多数系统构件都在一个芯片 SoC芯片可以有效降低电子信息系统产品开打的成本 典型： 高通骁龙 海思 嵌入式微处理器的特点 基础还是通用微处理器 与通用相比 体积小重量轻可靠性高 功耗低 成本低 工作温度、抗电磁干扰，可靠性增强 ARM公司 成立于1990年11月 设计了ARM系列的RISC处理器内核 授权ARM核心设计的半导体合作伙伴制造和销售给他们的客户 同时开发技术以协助ARM架构设计 ARM架构 典型的RISC架构 丰富的寄存器 加载/存储体系结构 简单寻址模式 统一和固定长度的指令字段 Meltdown &amp; Spectre与推测性执行和Cache有关的硬件级漏洞 cpu进行分支预测推测操作时提前执行了代码，并且将结果存在了cache里，结果分支清空时只清空了寄存器，没有清空cache，黑客可以利用cache中的结果进行越权操作 选择微处理器 列出所需的硬件接口 检查软件架构 选择体系结构 确定内存需求 开始搜索微控制器 检查成本和功率限制 检查零件可用性 选择一个开发工具包 研究编译器和工具 开始尝试 存储器架构 对许多应用来说，存储系统对整个系统性能的影响比对数据流水线的影响更大 复杂： 在同一个嵌入式系统中，通常需要组合各种存储技术 至少需要一些非易失和易失 易失性存储器SRAM DRAM 非易失性存储器disk，ROM，Mash ROM，EROM，EEROM，Flash 固件firmware一般存在EEPOM或Flash中，用户可以通过特定刷新程序来进行升级 ROMable 可固化 可以被编程到POM芯片中的机器语言 固件其实也是一种程序，是软件，只不过被固化到了ROM上 Flash比较快的读取时间，但是还是比RAM慢 写入时间大大超过读取时间，而且写入次数是有限的 flash类型 NOR 按快擦除 擦除和写入时间较长，但能够像RAM那样访问 NAND 以块为单位，一个数据块是数百或数千比特 擦除和写入速度比较快 按页读取（512-4K字节） 主要应用对比 NAND NOR 文件存储 代码执行 存储容量高 低 成本低 高 动态功耗低 高 待机功耗高 低 写入速度快 慢 读取速度慢 快 execute in Place（XIP）就地执行（芯片内执行，不用拷到RAM中）不支持 支持 可靠性低 高 存储器层次结构 寄存器 spm cache 内存 外存/互联网存储器 Cache之于EScache的加入导致了访问时间的不可预测，对嵌入式系统的可靠性和实时性能产生负面影响 SPM暂存存储器比cache功耗低，速度快，和处理器集成在一个芯片上 存储器访问时间难以预测虚拟存储器MMU，使各种存储技术看起来是一个连续的地址空间 地址转换TLB 总线式嵌入式系统访问存储 独立I/O和内存空间 I/O不占用内存 使用I/O指令，程序清晰 译码电路比较简单 只能用专门的I/O指令，访问的方式比较少 内存映射I/O 使用同一方式寻址，可以用C语言直接编写 不需要额外的保护机制 缓存设备控制器可能影响I/O设备的使用，一般需要专门的逻辑设置缓存禁用 如果只有一个地址空间，内存模块和I/O设备必须检查所有的内存引用，以决定要响应哪一个 混合方案 嵌入式系统递归函数所有递归函数都必须是可重入的 在嵌入式系统中尽量避免使用递归，递归调用栈带来的内存开销很可能是致命的 异步硬件/固件竞态条件设备或系统出现不恰当的执行顺序，从而得到不正确的结果 解决： 把导致竞态的服务禁用 乐观锁 悲观锁 IO总线复用多总线机制一根高速总线，一根低速总线，中间桥接一下 常用的总线UART（经济、简单，功能有限）、CAN（安全快速，很复杂）、USB（适用于即插即用的硬件，需要强大的主机、需要指定驱动）、SPI（快速、低成本，无即插即用硬件）、IC 嵌入式软件系统概述与桌面软件的区别 内存十分有限 cpu能力十分保守 操作系统 实时行为 开发工具 es使用交叉编译器 往往在开发中嵌入一些汇编代码 软件组件 库，这些库必须是适合es环境的，比如c++的STL库有一些就不适合es环境 软件、硬件的权衡 微处理器 内存大小组合（调试的时候能用ram别用rom） 需认真考虑设计中包含哪些外设 需要重点考虑硬件费用 有时可用软件替代 调试 在线仿真器ICE 模拟CPU的功能 价格昂贵 监控调试器 需要通信通道 占用系统资源 片上调试 JTAG是边界扫描的一个标准协议 价格便宜，易于实现 广泛使用 自检 IO电路 板载开关 状态显示 单线程模型 优点 编程再编程简单 改变系统响应特性的同时 多任务模型 优点 允许将系统工作划分为几个逻辑阶段 ROS ROS是一个适用于机器人的开源操作系统 提供了操作系统应有的服务，包括硬件抽象、底层设备、常用函数、进程间消息的传递 提供用于获取、编译、编写和跨计算机 管道 ROS的核心是提供一个消息传递系统 通过匿名发布/订阅模式管理分布式节点之间的通信细节 这种方法鼓励软件开发中的良好实践 嵌入式软件设计模式 两部分 业务逻辑 实时依赖硬件的逻辑 抽象层将所需操作的高级请求转换为操作所需的低级命令 非结构化单体架构 很容易构建，但很难维持规模和移植 与应用层的应用程序紧密耦合 事件驱动架构微服务架构微内核架构故障恢复机制：看门狗一个计数器，每来一个时钟脉冲+1，一旦计数器溢出，就reset MCU，造成恢复 为了避免触发恢复，我们要“喂狗”，重置看门狗的计数器 线性数据中断服务器直接访问，需要由锁保护起来，避免竞态条件 RTOS应用程序设计模式RTOS程序通常有两种同步： 资源同步：共享资源的访问是否安全 活动同步：决定执行是否已达到特定状态 资源同步中断锁定抢占锁当两个任务都在访问时，最先访问的任务抢到锁 在临界期内核抢占锁会被禁用，可能导致高优先级的任务无法执行 互斥锁保护共享资源的最安全、最推荐的方法之一是使用互斥锁。互斥锁通 过创建一个对象来保护临界区，该对象的状态可以被检查，以确定是 否可以安全访问共享资源，其唯一目的是为共享资源提供互斥 互斥锁不会禁用中断，它不会禁用内核的抢占调度程序 保护共享资源的互斥锁的一个潜在问题是，开发人员需要知道它的存在 活动同步关于协调任务执行 单向同步双向同步广播设计模式发布和订阅模型（在ES中广泛使用）发布者向特定的主题发布消息，订阅这个主题的接受者收到这类消息 系统完全可扩展 低功耗设计模式尽可能保持设备关闭 多核架构 同构多核 异构多核 比如可以一块内核用于机器学习推理，一块内核用于标准实时运算 ROS 入门节点 Nodes单一用途的可执行程序，比如传感器驱动、地图构建、规划、UI 单独编译、执行和管理 使用ROS客户端库编写节点 roscpp python 节点可以发布或订阅topic 节点也可以通过或使用服务/行动 节点管理器Master为节点提供链接信息，以便各节点之间互通消息 跟踪和记录主题/服务通讯，辅助节点相互查找、建立连接 提供参数服务器，节点使用此服务存储和检索运行时的参数 唤醒参数ROS_MASTER_URL包含ROS Master的ip和port 节点管理器是违背分布式理论的，在ROS2中已经被剔除 ROS主题已定义类型的命名消息流 可对名为scan的主题发送来自测距仪的数据，消息类型为LaserScan ROS消息消息：用于节点间通信的严格类型的数据结构 .msg是带有字段类型和名称的简单文本文件，编程语言无关 使用geometry_msgs/Twist表示速度命令 支持一般的数据结构 ROS服务同步节点事务 客户机/服务器模型 使用编程语言无关的.srv文件定义请求和应答数据结构 服务角色 远程计算 出发行为 检索 动作action 与服务类似，动作客户端向动作服务器发送请求，在执行动作时，动作服务器会向动作客户端发送进度反馈消息 动作时异步的 ROS1 动作借助主题完成信息交换 ROS2 可以使用服务 ROS BagsROS数据记录的主要机制，用于存储来自topics和services的metadata ROS package ROS中的软件以包的形式组织 包的目标是创建易于重用的最小代码集合 一个包包含一个或多个节点，文档，并提供ROS接口 大多数ROS包都托管在Github上 常用ROS命令ROSshell用起来很像linux bash roscd rosls rosed roscp roscore rosrun roslunch rosclean rostopic rosservice rosnode rosparam rosbag rosmsg rossrv rosversion catkin_create_pkg rosinstall rosdep m模型模型应该具有的一些特征： 简单 经得起理论检验 高表现力 提供逻辑推理能力 可执行 可综合：通常要求设计正交性 能够适应各种不同的任务 描述不存在歧义，易于理解和修改 常见的一些建模 面向状态的建模 面向活动 面型结构 面向数据 异构模型 有限状态机反应式特征 其特征是事件驱动 可以定义为可能的io集合、条件、动作和时序约束 确定性FSM特性 确定性：对于每个状态，每个输入值仅可激活一个转移 可接受性：每个输入能能够被接受 Moore机和Mealy机moore机输出完全由当前状态决定，与输入信号的当前值无关，mealy机输出依赖于当前状态和当前输入，moore机结构简单但是装太多，mealy机复杂但是比较精简 等价对所有输入具有相同输出的FSM等价，看起来结构完全不同的FSM都可能等价，因此有限状态机是可以优化的，主要是进行状态的缩减 非确定性FSM状态输出有多个值 NFA（非确定）可以通过幂集构造转变为DFA（确定） 常规FSM 经常过度指定 完全指定的 缺乏组合潜力，可伸缩性差 状态爆炸 不支持并发 一种解决方案是在模型中引入层次结构 层次FSM支持并发 当前状态：活跃态 包含其他状态：超状态 被包含：子状态 不包含其他状态：基本状态 包含基本状态的状态是这个基本状态的：祖先状态 任何时候若FSM只能处于超状态S的某个状态中，则该状态被称为OR型状态 默认状态机制超状态变为活跃时将要激活的状态 历史机制采用这个机制，就可能回到超状态退出之前最后一个活跃子状态 也就是跳出去之后再调回来应该回到上次跳出去时候的状态 并发与型超状态：无论什么时候包含状态S的系统在进入S状态时都将进入S的所有子状态中 相当于S里的子状态机在并发执行了 定时器边的标号语法: event(引发迁移的事件)[condition(进行测试的条件)]/action(执行迁移所产生的输出) off-key[msg==true]/on:=0 优势 层次结构允许任意嵌套与型和或型超状态 语义足够详细 大量仿真工具 可以在后端自动生成C或者VHDL 不足 生成的玩意儿效率低下 难以生成分布式应用程序 没有结构化层次的描述 层次FSM特性 合理的默认活动 多个地方增强行为 所需状态数减少 状态转移减少 易于扩展 更复杂，实现成本更高 要在表现力和复杂性和可维护性中平衡 实践课：AEBAEB需要的功能 碰撞预警与紧急制动 系统失效警告 驾驶员可中断 相邻车道不响应 面对低障碍物不应启动 嵌入式操作系统概论实时系统 一个实时系统是指计算的正确性不仅取决于程序的逻辑正确，也取决于得到结果的时间开销，如果时间要求得不到满足，也不能得到结果 黑话 确定性 非确定性 截止时限 硬实时：截止实现一旦错过就是失败 软实时：不是失败 准实时：不是失败，但是服务质量可能降低 实时操作系统支持构建实时系统的操作系统 只有实时操作系统和确定性代码同时满足才能产生实时性能 多任务级别 软件和硬件资源管理 为应用提供基本的OS服务 从软件应用抽象硬件 嵌入式应用上下文具有更高可靠性 满足应用需要的裁剪能力 更快 减少内存需求 为实时嵌入式系统提供可裁剪的调度策略 支持无盘化嵌入式系统，可以从ROM或RAM上引导和运行 对不同硬件平台具有更好的可移植性 RTOS关键要求 操作系统的时间行为必须可预测 任何调度策略必须是确定性的 为了避免关键事件处理过程中的不可预测的延迟，禁止中断的时间必须尽可能短 操作系统必须管理线程和进程的调度 一些系统要求操作系统管理时间 对时间的精度要求可能会有所不同 一些与环境的连接可用来获取精确的时间信息，如GPS或移动网络 操作系统必须是快速的 可靠性 简介紧凑 为什么使用RTOS 可被复用的标准软件组件 灵活性 响应时间 RTOS类别 快速专有内核 对于标准操作系统的实时扩展 通过比如RT_PREEMPT的内核补丁将Linux调度器改为完全可抢占 Xenomai：一个协同内核，会把Linux内核视作它的最低优先级任务 RTAI 协同内核的替代方案 标准操作系统实时扩展： 优点： 有标准OS API 快速应用 非实时不会影响实时 缺点： 设备驱动存在冲突，一般将设备划分为由实时进程处理和由标准OS处理 实时进程还是不能用标准OS的服务 最流行的嵌入式操作系统 Embedded Linux FreeRTOS Ubuntu 物联网操作系统要求： 内存占用小 如下各方面需要正确的权衡 性能 方便的API 操作系统内存占用小 支持异构硬件 网络连接 有有线有无线 节能 很多物联网设备使用电池供电 实时功能 安全 调度模型抢占式，非抢占式 内存分配 内存以静态还是动态分配是一个重要问题 标准C的malloc是非确定性的，实时操作系统要为malloc提供一个确定性实现，比如TLSF 动态内存分配要处理内存不足的情况，很难处理 基于堆的malloc通常导致内存碎片 网络缓存管理两种方式 内存复制：从资源角度是昂贵的 不同网络层之间传递指针：会产生谁来负责分配的问题 编程语言主要选择 标准C与C++ 调试工具 GDB 为了运行实时调试系统，需要JTAG或Spy-Bi-Wire 用printf()简单调试 甚至直接用LED等闪烁 特征集 操作系统可以分为内核和更高级别的功能 测试测试挑战来源于这些系统的分布式特性，并且典型的嵌入式系统通常是受限的 证书找认证机构搞一个证书来 文档调度程序 完全静态调度程序 静态顺序调度程序/离线调度程序 在线调度程序 静态分配调度 完全动态调度 任务模型任务周期一个任务的每次执行被称为一个作业 调度算法两个时间T：任务重新就绪的周期 C：任务执行需要的时间 可行调度：每个任务都在截止周期之内被完成 RMS 单调速率调度RMS直接用周期来设定优先级，周期越短，优先级越高 只要一个任务集可以被静态调度，就可以被RMS调度 RMS CPU利用率，当n（任务数）趋近于无穷时，cpu利用率趋近于0.7 优点： 单处理系统中最优的固定优先级抢占式调度算法 静态优先级 临界时刻定理对于固定优先级调度，如果任务T1与所有更⾼优先级 的任务同时释放，那么，每个任务 在单处理器系统上执⾏的响应时间就是最⼤化的 当低优先级任务的开始相位与⾼优先 级任务的开始相位⼀致时，低优先级任务的完成时间是最差的 因此，在检查调度可⾏性时，只考 虑最坏的情况就⾜够了，即所有的 任务同时开始周期式执⾏ Jackson算法针对有限非重复、无优先关系的任务集 最早交货期：截止时限最早的首先执行 EDD在最大延迟最小化方面是最优的 EDD不支持任务到达，可通过允许任务在任何时刻到达来扩展EDD 最早截止时限有限 EDF允许任务一个个到达 既适用于周期任务，也适合非周期任务 最晚时限优先从后往前安排 EDF* 任何任务都必须在截止时限内完成执行 任何任务完成执行的时间不能晚于其后记任务的最晚开始时间（也就是截止时限-执行时间） 优先级反转问题​ 所谓优先级翻转问题（Priority Inversion）即当一个高优先级任务通过信号量机制访问共享资源时，该信号量已被一低优先级任务占有，而这个低优先级任务在访问共享资源时可能又被其它一些中等优先级任务抢先，因此造成高优先级任务被许多具有较低优先级任务阻塞，实时性难以得到保证。 例如：有优先级为A、B和C三个任务，优先级A&gt;B&gt;C，任务A，B处于挂起状态，等待某一事件发生，任务C正在运行，此时任务C开始使用某一共享资源S。在使用中，任务A等待事件到来，任务A转为就绪态，因为它比任务C优先级高，所以立即执行。当任务A要使用共享资源S时，由于其正在被任务C使用，因此任务A被挂起，任务C开始运行。如果此时任务B等待事件到来，则任务B转为就绪态。由于任务B优先级比任务C高，因此任务B开始运行，直到其运行完毕，任务C才开始运行。直到任务C释放共享资源S后，任务A才得以执行。在这种情况下，优先级发生了翻转，任务B先于任务A运行。 解决优先级天花板（Priority Ceiling） 优先级天花板是当任务申请某资源时， 把该任务的优先级提升到可访问这个资源的所有任务中的最高优先级， 这个优先级称为该资源的优先级天花板。这种方法简单易行， 不必进行复杂的判断， 不管任务是否阻塞了高优先级任务的运行， 只要任务访问共享资源都会提升任务的优先级。 优先级继承（Priority Inheritance） 优先级继承是当任务A 申请共享资源S 时， 如果S正在被任务C 使用，通过比较任务C 与自身的优先级，如发现任务C 的优先级小于自身的优先级， 则将任务C的优先级提升到自身的优先级， 任务C 释放资源S 后，再恢复任务C 的原优先级。这种方法只在占有资源的低优先级任务阻塞了高优先级任务时才动态的改变任务的优先级，如果过程较复杂， 则需要进行判断。 调度算法都是脆弱的如果一个具有固定优先级、执行时间和优先级约束的任务集在固定数量的处理器上 嵌入式系统内核可移植，可固化、可扩展、抢占式、实时确定性的多任务内核，适用于微处理器、微控制器和DSP 最多可以管理64个任务，每个任务都有唯一的一个优先级 保留了四个最高优先级和四个最低优先级的任务作为系统任务 实际使用的优先级只有两个：OSTaskCreat和 系统总是创建一个优先级最低的空闲任务，空闲任务把32位计数器加一，统计任务要用 统计任务是倒数第二的任务，提供运行时间统计，统计任务是可选的 任务控制块TCB里面有栈指针、描述任务状态的标志位、描述任务优先级的标志位、还有链表指针 空闲TCB链表 所有任务控制块都被放置在任务控制块链表数组OSTCBTbl[]中 初始化的时候所有TCB被连接成空闲的单向链表 一个头指针从链表头开始始终跟踪下一个空闲的指针 当一个任务被创建，头指针指向的TCB给了这个任务，并且加入到使用链表中，头结点向后移动 为了方便找到一个任务，提供一个64大小的OSTCBPrioTbl[]数组来帮助快速索引 状态的转换调度：找到就绪态里面优先级最高的转为运行态 任务就绪表每个任务的就绪态标志放入在就绪表中 就绪表中有两个变量 OSRdyGrp：任务按优先级分组， 进程同步PV，邮箱，消息队列 实时内核：存储管理采用实模式存储管理，整个系统只有一个地址空间，每个系统任务都是线程，只有上下文和栈是共享的，其他为独享 malloc和free不能用标准c的，因为具有不确定性，可能不能保证线程安全性、产生内存碎片、占用较多代码 中的malloc和free确定的，分配固定大小的内存块 存储管理 µC/OS把连续的大块内存按分区来管理，每个分区包含有整数个大小相同的块 在一个系统中可以有多个内存分区， 用户的应用程序就可以从不同的内存分区 中得到不同大小的内存块，但特定的内存块在释放时必须重新放回它以前所属 于的内存分区 这样就解决了内存碎片 Freetos内存管理heap_1：应用程序不删除任务和信号量，加载进来跑到死 heap_2：采用一个最佳匹配算法分配内存，分配与需求最接近的内存，并支持内存释放 ，不会自动合并相邻空间，会产生内存碎片 heap_3：简单的调用了标准库malloc()和free()，但是通过暂时挂起调度器保证线程安全 时钟节拍一种特殊的中断 提供周期性信号源，用于实现时间延迟和确认超时 节拍率应在10到100Hz之间，时钟节拍率越高，系统的额外负荷就越重 板级支持包和引导加载期末复习嵌入式系统概述定义与术语术语 泛在计算（任何时间、任何地点） 不可见计算机（计算机被集成到物件中） 普适计算（计算设备对日常生活的渗透） 环境智能（未来家庭或智能楼宇中的通信技术） CPS信息物理系统，计算进程和物理进程的集成，强调嵌入式系统与物理学深度结合 人机物融合系统 深度融合各类信息技术 无线感知网络，分布着的自动装置组成的传感器感知计算网络 定义以应用为中心，以计算机技术为基础，软硬件可裁剪，适用于应用系统对功能、可靠性、成本、体积、功耗、可伸缩性、容错有严格要求的专用计算机 嵌入式系统组成 嵌入式硬件 以微处理器为核心，集成存储器和系统专用的输入输出设备 嵌入式软件 软件包括：初始化代码及驱动、嵌入式操作系统和应用程序 嵌入式系统设计方法嵌入式系统设计所面临的挑战 需要多少硬件 如何满足时限要求，如何处理多项功能在实践上的协调一致性 如何降低系统的功耗 如何保证系统可升级 如何保证系统可靠的工作 嵌入式系统设计目标 成本 性能 功耗 尺寸 可伸缩性和可重用性 容错 传统嵌入式系统设计过程需求分析、规格说明、体系结构、构建设计、系统集成 基本特征 系统在一开始就被划分为软件和硬件两大部分 软件和硬件独立开发设计 一般硬件优先 隐含的问题 软硬件之间的交互收到很大限制 凭经验划分软硬件 软硬件之间的相互影响难以评估 系统集成相对滞后 NRE 导致 设计质量差 设计难修改 研制周期不能有效保障","tags":["嵌入式系统"],"categories":["课程笔记","嵌入式系统"]},{"title":"记一次azure突然无法访问互联网","path":"/2023/08/16/记一次azure突然无法访问互联网/","content":"8月13日，突然clash订阅就不能用了，显示i&#x2F;o timeout 最开始以为是被墙了 当时第一反应就是被墙了，但是经过ip和端口的ping和curl测试发现没有被墙，域名也没有被抢 完全无法访问外网 通过azure cls登录后，发现v2ray和Nginx都在正常运行，所以也排除了脚本出问题 这个时候我想用apt update检查依赖并且更新依赖，结果得到了无法访问ubuntu依赖仓库的报错 这个时候事情就变得魔幻了，我开始尝试 1ping www.google.com 但是发现package 100% loss 但是 1ping 127.0.0.1 完全正常 检查dns 论坛上查询后有人说可能是dns解析时间过长（因为azure默认使用由azure特别提供的dns，然而这个dns会定期抽风），于是我将vps的dns换成了1.1.1.1，但是无济于事，并且我ping 1.1.1.1也是不通的，所以应该不是dns解析的问题 检查防火墙规则 接下来有人说可能是防火墙，但是我的ubuntu本身的防火墙早就为了省事禁用了，azure自己的安全组也是早就配好了的，为了验证这一点，我甚至尝试直接允许了所有inbounds和所有outbounds，但是还是不行 检查虚拟网卡 在一段长时间痛苦的迷思之后我想到了NIC，azrure的vps都是通过虚拟网卡获得mac地址并且上网的，而这个虚拟网卡，根据论坛网友的反馈，也经常抽风 我一开始想的是干脆把整个网络服务重启算了 1service network restart 结果vps没有network这个service 所以还是通过卸载网卡来处理 1ifconfig 首先查看网络配置 发现了虚拟网卡eth0 接着卸载它 1ifconfig eth0 down 本来我下一步是up，结果我忘了我是远程连接vps的，这一下直接给vps干失联了… 但是最好玩的是当我回到控制台，发现vps正在重启，重启完成以后，vps又能正常上网了，clash也能用了… 复盘 \u0015其实我到现在也没想明白导致这一切的原因，不过有一种可能的解释： 我是通过vmess+tls+wf+tcp出境的，为了访问chatgpt还套了一层cloudflare warp 这一套虽然用起来很爽，但是因为我两个部分使用github上不同大神的不同一键脚本分别部署的，而这两个脚本的依赖之间似乎有冲突，所以我运行了一段时间之后，Nginx就突然停止运行了 我当时并没有多想，直接重启了Nginx服务，就这样又搞了几周，依赖冲突终于在一天爆炸了，当时我登录后好多命令都不能用了（ 为了修复我是这么做的 sudo dpkg --configure -a sudo apt-get install -f sudo dpkg -i --force-overwrite /var/cache/apt/archives/*package+name* 1234567 这确实解决了dkpg的问题，但是或许也一起干掉了azure的虚拟网卡需要的一些依赖，因为我当时一心想着重装v2ray，其他被干掉的包都没怎么管- 最后我的这条命令- ```shell ifconfig eth0 down 或许触发了azure vps的某种保护机制，促使azure重新为我的vps装载了虚拟网卡 后记： 问题解决了吗？我想没有，也许再过两天Nginx又会停止运行，下一次遇见这个问题，我不能再像个无头苍蝇一样乱搞了，应该先读一读那两个脚本的源码，看看它们到底对我的vps做了什么…","categories":["云服务","azure"]},{"title":"Android开发坑总结","path":"/2023/07/21/Android开发坑总结/","content":"暑期课程，感觉作业量相当大，不过想到隔壁cloudwego还要手搓网关，心里就平衡了:-) 使用.addTextChangedListener无效 这个问题到现在也没解决，这个代码就是不触发监听事件，搞了一下午也想不通，论坛里大家都是这么用的，但是我就是不行？ 1234567891011121314151617181920newsTitleElement.addTextChangedListener &#123; object : TextWatcher &#123; override fun beforeTextChanged( s: CharSequence?, start: Int, count: Int, after: Int ) &#123; // 这里不需要处理 &#125; override fun onTextChanged(s: CharSequence?, start: Int, before: Int, count: Int) &#123; // 这里不需要处理 Log.i(&quot;abcdefg&quot;, &quot;text change了&quot;) &#125; override fun afterTextChanged(s: Editable?) &#123; // 在文本更改后保存EditText中的文本到contentText newsTitle = s.toString() Log.i(&quot;abcdefg&quot;,&quot;标题赋值&quot;) &#125; &#125; &#125; 换成kotlin提供的api就可以… 123newsContextElement.doAfterTextChanged &#123; Log.i(&quot;abcdefg&quot;, &quot;changee text!!!&quot;) &#125; 这说不通，因为本质上来说这个api无非就是将java里的写法封装了下… 在主线程使用数据库被系统拒绝 本来我想用户一点击提交按钮就直接将实体往数据库存 12345678910111213private fun setUpOkButton()&#123; val okButton: ImageButton = findViewById(R.id.post_news_ok_button) okButton.setOnClickListener &#123; if (newsTitle.isEmpty() || newsAbstract.isEmpty() || newsContext.isEmpty())&#123; Toast.makeText(this, &quot;标题、摘要、正文不能为空&quot;, Toast.LENGTH_SHORT).show() return@setOnClickListener &#125; val newsId: Long = db.newsBriefDao.insert(NewsBriefEntity(null,newsTitle,&quot;&quot;,&quot;《史记》&quot;,&quot;火爆&quot;)) db.newsContentDao.insert(NewsContentEntity(newsId,&quot;&quot;,newsAbstract,newsContext)) Toast.makeText(this, &quot;发布啦&quot;, Toast.LENGTH_SHORT).show() finish() &#125; &#125; 但是这样是在Ui 线程里进行数据库操作，会把ui界面阻塞，所以被系统拒绝了 12java.lang.IllegalStateException: Cannot access database on the main thread since it may potentially lock the UI for a long period of time. 解决方案是启动kotlin协程 12345678910111213141516171819202122private fun setUpOkButton()&#123; val okButton: ImageButton = findViewById(R.id.post_news_ok_button) okButton.setOnClickListener &#123; if (newsTitle.isEmpty() || newsAbstract.isEmpty() || newsContext.isEmpty())&#123; Toast.makeText(this, &quot;标题、摘要、正文不能为空&quot;, Toast.LENGTH_SHORT).show() return@setOnClickListener &#125; // 在子线程中执行数据库操作 GlobalScope.launch(Dispatchers.IO) &#123; val newsId = db.newsBriefDao.insert(NewsBriefEntity(null,newsTitle,&quot;&quot;,&quot;&quot;,&quot;&quot;)) db.newsContentDao.insert(NewsContentEntity(newsId,&quot;&quot;,newsAbstract,newsContext)) // UI操作需要回到主线程 withContext(Dispatchers.Main) &#123; Toast.makeText(this@PostNewsActivity, &quot;发布成功&quot;, Toast.LENGTH_SHORT).show() finish() &#125; &#125; &#125; &#125; 协程我还没有弄明白，这部分代码是claude给我写的 kotlin的用于解析Room注解的依赖声明方式与java不同 这个问题也是相当炸裂 java引入room注解的方式是 1annotationProcessor &quot;androidx.room:room-compiler:$room_version&quot; 而kotlin是 1kapt &quot;androidx.room:room-compiler:$room_version&quot; 最让我恼火的是如果使用了第一种写法，根本没有任何显式的机制来提醒我，所有的room注解都不会引起IDE的报错或提示，程序会正常通过编译，APK甚至可以在真机上运行直到首次尝试实例化数据库时，APK直接崩溃并提示不存在database_impl，也就是说room实际上没有对注解做任何事情，我想现在我明白为什么这么多人要选择用react_native来开发APP了 一个比较好的全局主题 默认的主题button背景强制是紫色的，所以需要自己覆盖默认主题里的设置，同时把丑陋的导航栏也禁用了，状态栏也换成了更好看的透明式 123456789&lt;style name=&quot;Base.Theme.MyApplication&quot; parent=&quot;Theme.Material3.DynamicColors.DayNight&quot;&gt; &lt;!-- Customize your light theme here. --&gt; &lt;!-- &lt;item name=&quot;colorPrimary&quot;&gt;@color/my_light_primary&lt;/item&gt; --&gt; &lt;item name=&quot;windowActionBar&quot;&gt;false&lt;/item&gt;//无ActionBar &lt;item name=&quot;windowNoTitle&quot;&gt;true&lt;/item&gt; //无标题 &lt;item name=&quot;android:buttonStyle&quot;&gt;@style/AppButtonStyle&lt;/item&gt; &lt;item name=&quot;android:windowTranslucentStatus&quot;&gt;true&lt;/item&gt; &lt;item name=&quot;android:fitsSystemWindows&quot;&gt;true&lt;/item&gt;&lt;/style&gt; content provider提供的地址在其他activity中失效 这个问题让我深刻体会到了什么是“维护的结束就是软件死刑的宣告”，仅仅在三年间，Android对于一个最简单的获取一张照片地址的鉴权方式来去变化了好几次，我在解决问题时遇到了包括但不限于以下报错： 1WRITE_EXTERNAL_STORAGE is deprecated (and is not granted) when targeting Android 13+. If you need to write to shared storage, use the MediaStore.createWriteRequest intent 这是因为Android从13+开始不再允许这种一次申请到处读取的鉴权方式，并且从10+开始，即使开发者声明了这个权限，app也不会得到任何鉴权 12Process: com.liuyaoli.myapplication, PID: 14712 java.lang.RuntimeException: Unable to start activity ComponentInfo&#123;com.liuyaoli.myapplication/com.liuyaoli.myapplication.PostNewsActivity&#125;: java.lang.SecurityException: UID 10451 does not have permission to content://com.android.providers.media.documents [user 0]; you could obtain access using ACTION_OPEN_DOCUMENT or related APIs 这里是我想用 1this.grantUriPermission(targetPackageName, contentUri, permissionFlags) 来为相关activity鉴权，但是提供照片选取器的content provider是被保护起来的，不允许这样鉴权 1java.lang.SecurityException: Permission Denial: reading com.android.providers.media.MediaDocumentsProvider uri content://com.android.providers.media.documents/document/image%3A255293 from pid=10706, uid=10450 requires that you obtain access using ACTION_OPEN_DOCUMENT or related APIs 这里是我开始用系统提供的照片选择器来避免去申请存取权限的问题 123456789101112 headImgPickImage.launch(PickVisualMediaRequest(ActivityResultContracts.PickVisualMedia.ImageOnly)) private val headImgPickImage = registerForActivityResult(ActivityResultContracts.PickVisualMedia()) &#123; uri -&gt;if (uri != null) &#123; // 在这里展示选择的图片，可以将 URI 传递给相应的 ImageView 或其他展示图片的组件 uploadHeadImgButton.setImageURI(uri)// thumbnailUri = Uri.fromFile(File(getRealPathFromURI(this,uri)!!)).toString() headImgUri = uri.toString() Log.i(&quot;ttttt&quot;, headImgUri) &#125; &#125; 但是即使是这样，即便申请获取图片的activity有了权限，同一app下的其他activity也无法获得权限 接下来我又不知道从哪里弄了个鉴权方法，又换成报这个错 12Request threw uncaught throwable java.lang.SecurityException: Permission Denial: opening provider com.android.providers.media.MediaDocumentsProvider from ProcessRecord&#123;1f9acfc 13239:com.liuyaoli.myapplication/u0a450&#125; (pid=13239, uid=10450) requires that you obtain access using ACTION_OPEN_DOCUMENT or related APIs 最后chatgpt告诉我 “你应该使用 takePersistableUriPermission 来授予长期持久的权限。下面是使用 takePersistableUriPermission 的方法：” 原来加上这几行获取持久权限就行了： 1234567891011121314 private val thumbnailsPickImage = registerForActivityResult(ActivityResultContracts.PickVisualMedia()) &#123; uri -&gt; if (uri != null) &#123; contentResolver.takePersistableUriPermission( uri, Intent.FLAG_GRANT_READ_URI_PERMISSION or Intent.FLAG_GRANT_WRITE_URI_PERMISSION ) // 在这里展示选择的图片，可以将 URI 传递给相应的 ImageView 或其他展示图片的组件 uploadThumbnailsButton.setImageURI(uri)// thumbnailUri = Uri.fromFile(File(getRealPathFromURI(this,uri)!!)).toString() thumbnailUri = uri.toString() Log.i(&quot;ttttt&quot;, thumbnailUri) &#125; &#125; 回过头来看，我debug的过程正好是Android发展的过程，从以前的程序申请一次权限就可以到处访问数据，到要用grantUriPermission来分content provider来鉴权，再到又套一层takePersistableUriPermission来要求申请持久权限，权限的管理越来越精细了","tags":["Android","kotlin"],"categories":["Android开发"]},{"title":"windows7 0x0000004F与0xc00000e修复","path":"/2023/07/15/windows7-0x0000004F与0xc00000e修复/","content":"错误的开始7月14号的晚上，老爸看到仿真软件仿制失败了，便让电脑重新仿制，但是突然电脑卡死，过一会出现了蓝屏错误 这个时候我和老爸犯下了更严重的错误，因为当时急着走人，所以直接用电源键把电脑强制关机了，这么以来电脑的引导分区被损坏，开机之后出现了0xc00000e错误，无法进入系统了 尝试修复引导分区首先我尝试了通过外接U盘启动，通过装机工具的修复引导来修复引导分区，这样的修复成功了，并且进入了系统，但是一开机，就弹出了windows7 副本不是正版的提醒，并且警告激活期限已过，今天必须激活，并且整个电脑奇卡无比，即便内存资源占用和cpu占用都不到10% 并且同时如果再次尝试启动电脑，引导区又处于损坏状态。 电脑有三个大问题 引导区反复损坏 系统严重卡顿 系统等待激活 尝试激活windows或禁用盗版检查我首先怀疑电脑卡顿是windows发现激活期限已到于是千方百计阻挠使用导致的，于是希望先激活windows 首先我尝试通过互联网上搜到的产品密钥激活win7，但是这些密钥都没有成功激活系统，爸爸的公司贪图便宜，所以在电脑城买了组装机，我猜电脑城的人使用了魔改的系统 于是我尝试禁用激活检查 1SLMGR -REARM 但是这个命令需要重启生效，而重启又会直接得到引导区错误，所以反复搞了好几次，都没有成功 尝试查看Dump文件激活失败之后，我又想到可以通过电脑的dump文件直接查看昨天晚上究竟是什么导致了系统崩溃，但是令我崩溃的是c盘windows下的minidump文件是空的，我想当时的系统崩溃相当严重，所以根本没有写入minidump的机会 接下来我来查看系统事件日志，这一次确实有了收获，日志显示在昨天晚上的22:50分左右（就是我和老爸准备回去的时候），系统接连生成了两个错误信息 这是第一个错误的详细信息 123456789101112131415161718192021222324252627282930313233日志名称: System来源: Schannel日期: 2023/7/14 20:54:00事件 ID: 36887任务类别: 无级别: 错误关键字: 用户: SYSTEM计算机: MS-BSANBJZXSRDT描述:接收到以下严重警告: 70。事件 Xml:&lt;Event xmlns=&quot;http://schemas.microsoft.com/win/2004/08/events/event&quot;&gt; &lt;System&gt; &lt;Provider Name=&quot;Schannel&quot; Guid=&quot;&#123;1F678132-5938-4686-9FDC-C8FF68F15C85&#125;&quot; /&gt; &lt;EventID&gt;36887&lt;/EventID&gt; &lt;Version&gt;0&lt;/Version&gt; &lt;Level&gt;2&lt;/Level&gt; &lt;Task&gt;0&lt;/Task&gt; &lt;Opcode&gt;0&lt;/Opcode&gt; &lt;Keywords&gt;0x8000000000000000&lt;/Keywords&gt; &lt;TimeCreated SystemTime=&quot;2023-07-14T12:54:00.586024200Z&quot; /&gt; &lt;EventRecordID&gt;3477251&lt;/EventRecordID&gt; &lt;Correlation /&gt; &lt;Execution ProcessID=&quot;816&quot; ThreadID=&quot;876&quot; /&gt; &lt;Channel&gt;System&lt;/Channel&gt; &lt;Computer&gt;MS-BSANBJZXSRDT&lt;/Computer&gt; &lt;Security UserID=&quot;S-1-5-18&quot; /&gt; &lt;/System&gt; &lt;EventData&gt; &lt;Data Name=&quot;AlertDesc&quot;&gt;70&lt;/Data&gt; &lt;/EventData&gt;&lt;/Event&gt; 虽然这些信息似乎有用，但是我不知从何处入手，只能先放在这里了 尝试彻底修复引导分区出错我通过u盘启动，进入疑难解答的命令行模式，尝试执行下面的命令 123bootrec.exe /fixmbrbootrec.exe /fixbootbootsrc.exe /rebuildbcd 但是执行到fixboot却提示拒绝访问，但是我明明应该是在管理员模式下的 windows论坛建议在安全模式下再试试，我想等我下次重启电脑再尝试吧 寻找卡顿原因我首先想到中毒的可能性，但是在此之前老爸似乎没有什么会让电脑被木马入侵的操作，并且cpu和内存的占用都很低，所以我更加怀疑是驱动问题。 我运行了火绒的全盘扫描，到下午两点我来看的时候，发现大丰收了： 内核后门病毒是一种恶意软件，针对计算机操作系统的内核进行攻击并在系统内植入恶意代码。它利用操作系统的漏洞或者其他弱点，绕过系统的安全机制，从而获得对操作系统的完全控制权限。 内核后门病毒通常以隐蔽的方式操作，常常隐藏在合法的系统文件或驱动程序中，使其难以被检测和清除。一旦内核后门病毒成功安装在目标系统中，它可以执行各种恶意活动，包括但不限于以下几个方面： 控制和监视：内核后门病毒可以远程控制受感染系统，并监视用户的活动，例如记录键盘输入、截取屏幕截图、窃取敏感信息等。 文件和进程操控：内核后门病毒可以修改、删除或隐藏文件和进程，包括系统文件和进程，从而破坏系统的正常运行。 网络攻击：内核后门病毒可以与远程恶意服务器建立连接，用于传输数据、下载其他恶意软件，或者作为僵尸网络的一部分，进行分布式拒绝服务攻击（DDoS）等网络攻击。 权限提升：内核后门病毒可以利用漏洞提升自身的权限，从普通用户权限提升到管理员或系统级别权限，以获取更高的访问权限和控制权。 不幸的是，处理这些病毒和广告程序并没有改善电脑卡顿的情况，但是在修复的同时，电脑还弹出了另一个提示框 这让我怀疑硬盘存在配置、驱动甚至是硬件本身的故障 问题仍在我以为删除了两个病毒，这时再重启就可以避免0xc0000e了，但是重启后电脑再一次出现引导分区损坏 为了修复引导分区，我开始着手解决fixboot拒绝访问的问题 ”拒绝访问“是微软windows众多粪坑中的一个，在当前的情况下，既可能是引导分区损坏及其严重，也可能是第三方（在当前的情况下，最可能是内核病毒）在阻止我启动fixboot，我在这篇文章找到了下面的解决方案 ( fixboot拒绝访问问题的修复_hymnal的博客-CSDN博客 ) 12345bootrec /fixmbrbootsect /nt60 sys /mbrbootrec /fixbootbcdboot c:\\windows /l zh-cnbootedit /enum //查看启动点 然而这也只是短暂能让电脑开机，当我尝试重启时，第一次系统未能正常关闭，第二次系统仍然是未能正常关闭，第三次，引导分区再一次损坏 启动磁盘扫描再次启动usb恢复盘，我开启了梅傲磁盘修复工具，扫描整个c盘，目前预计剩余时间达到了28小时… 回到最初的错误一筹莫展之际，我想到了最初的错误日志，我决定从这里入手，通过查询，我发现schannel errror 36887是一个相当常见的错误，通常是TLS的问题","tags":["电脑修复"],"categories":["修电脑"]},{"title":"读史记","path":"/2023/07/14/打卡读史记/","content":"2023.7.14 “吾必见寇至咸阳，麋鹿游于朝也”——李斯 我一定会亲眼看见叛军攻入咸阳，朝廷变成麋鹿嬉戏游玩的地方 “吾欲与若复牵黄犬俱出上蔡东门逐狡兔，岂可得乎！”——李斯 我想和你再一起牵着黄狗，从上蔡东门出去打猎，追捕狡兔，这些事情难道还可能办到吗 （李斯的大儿子李由官至三川守，这时已经被起义军杀死，这段话是行刑前李斯对他的二儿子说的，二人”父子相哭“） “赵高使其客十余辈诈为御史、谒者、侍中，更往覆讯斯。斯更以其实对，辄使人复榜之。后二世使人验斯，斯以为如前，终不敢更言，辞服【辞服：招供认罪。】。奏当上，二世喜曰：“微赵君，几为丞相所卖。”及二世所使案三川之守至，则项梁已击杀之。使者来，会丞相下吏，赵高皆妄为反辞。”——《李斯列传》 赵高派他的十多个门客假扮成御史、谒者和侍中，轮流前去审问李斯。如果李斯改为以实回答，就命人再对他进行拷打。之后二世皇帝派人前去验证李斯的口供，李斯以为还和之前的几次一样，终于不敢更改自己的口供，在供词上伏法认罪。赵高将判决书上呈给皇帝，二世皇帝大喜，说：“如果没有赵先生，我差点就被丞相出卖了。”等二世皇帝派遣的使者来到三川调查李由的时候，项梁已经将李由杀死。使者返回咸阳的时候，李斯已经被狱吏看押，赵高就编造了一整套李由参与谋反的罪状。 “一死一生，乃知交情。一贫一富，乃知交态”——《汲郑列传》","tags":["读书"],"categories":["闲书","史记"]},{"title":"记录一次考科目二","path":"/2023/07/09/记录一次考科目二/","content":"自从6月9日那次科目二连续两次都挂在四项的第一个项目坡道起步之后，我对于科目二就非常紧张 准备考试6月24日最后一门编译原理考完，大概是6月27日我开始练车准备新一轮的科目二考试，张见教练特别好，本来按照规定科目二挂过一次之后应该是只有两节考前课，但是以我的水平只练两次肯定是过不了的，张教练让我从27日起大概接连练了六七次，差不多驾校不休息，我就在练车，这样才磕磕绊绊过了科目二 练车时的回忆最让我痛苦是就是坡道起步，毕竟我第一次考试连着挂在这里，在驾校练车时也发现坡道起步非常难，首先是与右边线要在30cm之内，但是绝对不能碰到右边线，这就很难了，稍稍动一动方向盘，车头就会摆动十到二十厘米，因此我要么经常往右压线，要没距右边线大于30cm甚至50cm，另外一边，停车也有很大的难度，必须要求车最前头在一块30cm宽的区域内。 我第一次考科目二时，第一次机会挂在停车大于50cm，第二次为了停车不大于50cm，我有意往右边调，结果轧到了右边线。 如果我想要通过科目二，坡道起步最多也就扣二十，这样才有可能80过，但是我的倒车入库大概率会因为中途停车扣分，这样一来，我的坡道起步最多扣个十分，压力相当大。 除了坡道起步，曲线行驶也有比较大的问题，我常常会车头斜右进项目，结果车子转不过来轧到线。 这段时间，我每天早上7.15起床，7.35买了早餐从教育超市出发，一遍听着《无名之辈》《Dumb ways to die》，一遍骑车去驾校，现在想起来紧张中又透着几分惬意。 模考考前两天，我跟教练说我想去车管所模考，车管所的模考一直是个一本万利，回扣多多的项目，6次倒库，8次四项就能收360元，如果是自动挡12次倒库，12次四项能收到1200元 张见教练其实并不推荐我去模考，（我也不太明白是认为我已经练得差不多了还是认为我即便模了也不大可能过哈哈哈哈哈哈）但是我之前桩考也没试过，上次全部挂在四项第一个项目所以后面的三项也没有在机器的监测下考过，所以还是决定模一下 7月5号下午，我到驾校来模考，我算是看到了社会的肮脏，首先是那个卖模拟票的老女人，我猜它不是哪个小领导的亲戚就是小情人（毕竟现代人的性癖也太奇怪了），在我前面买票的是个衣着寒酸的大爷，他学的是自动挡，那老女人看也不看他一眼 “手动自动。” “自动挡。” “要400的，600的还是1200的。” “大概有什么区别呢？” “400是倒库XX次，三项XX次，600是倒库XX次，…1200是…” 大爷一看就不是能为这样一场考试花1200的人，他说到”啊那我还是…” 这老女人猛地就像是被抽插侮辱了一般，”我知道！你是不会买后面的！所以我也没打算讲！“然后没好气的撕了两张倒库和三项的票给他。 我是手动挡，虽然不用花这么多钱，但是即便买最便宜的票，也要360，车管所这可真是坐在金山银山上啊！ 我后来和一些人说起这些七七八八的收费，他们非但不感觉不合理，反而笑我不经世事，反过来说他们当时考驾照给安全员送了多少多少，打点了上面的小领导多少多少云云，口气里甚至带着几分得意，这时我又想起鲁迅先生说的： 中国只有两个时代，做稳了奴隶的时代和争做奴隶而不得的时代。 说回模考，进去之后我先去倒库，结果带我倒库的安全员见我两手空空，既无烟酒，又无红包，当时脸就阴了下来，我自知不够”孝敬“，陪着笑脸说道，“您能不能给我看看我倒库的点位呀，谢谢您嘞。“他直接问”我为什么要给你看？”我拳头已经攥得死死的，还是挤出笑脸说：“这倒库挺难的嘛，还得您帮忙看看呢。” 上车之后是真的紧张呀，第一把调好座椅就忘了调后视镜，而且手刹也忘了拉，更糟糕的是，从右边往库内倒的那一段，点位和驾校的不一样，在驾校我是等到白线插入后视镜再向右打死，但是在考场这样明显晚了，而我甚至一直没想到早一点打死方向，就这样第一个库的两把都挂了。 到第二个库的第二把，我的脑子终于转起来了，我试着早一点打，白线离后视镜一个半指就打死方向，果然，后面的点位都对上了，终于过了一把，靠着这个点位，我第三个库的第一把也过了，但是到最后一把的时候，因为我一直想着早点打，结果打得太早了，轧到了左边线。 几乎整个过程，那个安全员都没有怎么指导过我，特别是我开始倒第二个库的时候，又来了一个模拟的人，上来就塞了一包烟，这安全员就只围着后来的人转了。我不禁想着，如果我一开始送了包烟，这个后来的人是不是就要送芙蓉王来让安全员围着他转了，如果我送了芙蓉王，这个人是不是就得提一瓶茅台来才能达到他想要的效果，这就是所谓内卷吧。 现在想起来，官僚主义盛行、腐败与贿赂的滋生，不仅这些官僚要处理，这些开了送礼贿赂之风的人，这些鼓噪酒桌文化为中华优秀传统的人，也要一并被扫进垃圾堆里，才能遏制不正之风。就像鲁迅先生的《捧与挖》里说的： …也许是《笑林广记》罢，说，当一个知县的寿辰，因为他是子年生，属鼠的，属员们便集资铸了一个金老鼠去作贺礼。知县收受之后，另寻了机会对大众说道：明年又恰巧是贱内的整寿；她比我小一岁，是属牛的。其实，如果大家先不送金老鼠，他决不敢想金牛。一送开手，可就难于收拾了，无论金牛无力致送，即使送了，怕他的姨太太也会属象。 …当初自然是防其溃决，所以壅上一点土；殊不料愈壅愈高，一旦溃决，那祸害就更大。于是就“抢堤”咧，“护堤”咧，“严防决堤”咧，花色繁多，大家吃苦。如果当初见河水泛滥，不去增堤，却去挖底，我以为决不至于这样。有贪图金牛者，不但金老鼠，便是死老鼠也不给。那么，此辈也就连生日都未必做了。单是省却拜寿，已经是一件大快事。 中国人的自讨苦吃的根苗在于捧，“自求多福“之道却在于挖。其实，劳力之量是差不多的，但从惰性太多的人们看来，却以为还是捧省力。 接着是四项的模拟，四项的安全员应该是我在整个模拟中唯一遇到的还不错的人了，虽然他看到我没准备什么礼物，也不高兴，顿时变成了一个谜语人，我问他问题他扑通扑通说个不停，但是都是谜语，比如我问他线路一的坡道起步左转应该在那个位置,他开始扑打扑打地说：“哎呀你是来模考的，是你来考还是我来考呀，怎么还问我来了，你有问题我不会说吗，刚刚那里有问题我没说吗，你就按你学的来不行吗？” 但是慢慢地我问地多了，他居然也就开始回答我了，或许一个是因为我比较客气，另一个是因为我四项开得还可以，有一次死亡线路二甚至拿了满分。 甚至后面他问我上一次是不是抽到了线路二，我说是的，他叹气说“诶，这个线路二确实，这个也是电脑抽的，就是这么玄乎，说不定你这次考还是线路二。” 线路二一直被称作死亡线路二，因为它是一个起步右转，并且马上就是坡道起步，如果打方向的位置稍早，一定会轧线，稍晚，大概率超出50cm，难度非常大。 最后四项的模拟，我八次过了5次，但是如果倒库停车的话，那就只能过四次了。 小插曲因为倒库实在是太差，张见教练建议我再花40买两次倒库，可是那个老女人坚决卖120元6次起步，见拗不过我，便要我第二天来考试时买。 “你不要听她的，明天她又坐地起价了。”张见教练在电话另一头说。 我说：“不，你就现在卖我40元的票吧，我明天早上来。” 老女人又像是受到了抽插侮辱一般，尖声说：“我们不卖第二天的票！” 这个时候带我模四项的安全员来了，他笑着问我：“怎么啦，倒库不太行吗？”我解释说我想买一张便宜些、次数少些的倒库票，安全员笑了，拍着我的肩膀说，“卖一张吧。” 那老女人一脸的不可思议：“这是你带的学生吗？” 安全员淡定地笑着说：”上个月接手的学生。“ 老女人极不情愿的撕了张票给我，并且表示最少要卖60三次的，我也没有再争，直到我付了钱，她把票撕给我时，还尖声高呼了一声：”我们从不卖第二天的票！“ 离开时，我朝着四项的安全员深深鞠了一躬，或许他也没做那么大的好事，但是在这个牛鬼蛇神盘踞的地方，真是一股清流了。 考试考试还是比较惊悚的，第二天的早晨，因为提前和张见教练重新对了点位，我模的三次都过了，但是两次都因为储杆没有及时刹车，导致车往后滑判定成中途停车扣了5分，好在张教练又及时指出了我的错误。 正式考试，我首先抽到了倒桩，虽然触杆及时刹车了，但是往右出库的时候离合没控制好，还是中途停车了一次。 紧接着考四项，我抽到的又是四号线，好在昨天练的主要也是四号线，可是我在外头等了半天，轮到我考的时候，一摸口袋我才意识到我把身份证落在倒库了。 只好又去倒库的地方找身份证，那里的安全员个个五大三粗，我一下子没找到失物招领的地方，一个安全恶狠狠的说：”看你那个笨拙的样子，还考驾照。“还有一些别的难听的话云云。我是一下子也受不了了，转过身去直接说：”草你妈。“声音并不大，但他一定注意到我说了什么，我抓起身份证赶快赶往四项，当天正是台风，随时都会下雨，一旦下雨，坡道起步就很难通过了。我一路往四项跑，至于那个安全员还在喊什么，我完全没听到。 终于轮到我四项，其实我的心里压力很大，毕竟我已经问候过倒库的安全员父母了，如果我第一次四项不合格要考第二次的话，我是需要重考倒库的，那时候可就尴尬了。而且我等了这么久，看了这么多人考试，线路二通过的，似乎还只有一个人，大家几户都挂在了死亡坡道上。 几乎是坐到车上，我才发现自己如此的紧张，我的腿抖得几乎压不住离合器，车子几乎是在坡道上蹦迪，随时都会熄火，好在只是停车时因为大于30cm扣了10分，但是我的腿抖得越来越厉害，侧方停车甚至都有熄火的风险，做完侧方，我感觉因为离合踏板伴随着我抖动的左腿反复横跳，车子已经被我开成了摇摇车。 这时我记起来在项目与项目之间，我是可以停车的，于是我停车空挡拉手刹，在项目外面猛锤自己的左腿，深呼吸试图放松，大概过了一分钟，我终于重新起步，但是腿还是时不时开始抖，我在车里大声说：”我不怕！“，我想在看监控的工作人员一定会被这一幕笑到，但是我终于还是实现了目标，通过了直角转弯和曲线行驶。 伴随着”恭喜您！考试成功的。“播报，我高悬着的心终于落下了。 离开考场前，我最后回头看了一眼那带给我太多焦虑与紧张的二号线，这是我看到了昨天塞给安全员一包烟的人，他用光了两次四项的机会，正垂头丧气地从车里出来…这一刻我心情复杂，既感到爽快，又对他惋惜，毕竟看他的穿着，也不是有钱人，或许他太需要这张驾照了，但也许就像车管所候考区标语所写的一般： 能包你过的，只有你自己","tags":["学车","科目二"],"categories":["my Life","学车"]},{"title":"使用kubernetes部署云服务","path":"/2023/07/03/使用kubernetes部署微服务/","content":"使用kubernetes部署云服务 这个小项目通过kubernetes部署，包括eureka服务器，userService，adminService，并部署mysql服务存储持久化对象 加入各类组件并实现基本功能 以user-service的pom为例,加入eureka、mysql、springcloud各类组件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;\txmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\txsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;\t&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\t&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.1.RELEASE&lt;/version&gt; &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt;\t&lt;/parent&gt;\t&lt;groupId&gt;io.daocloud&lt;/groupId&gt;\t&lt;artifactId&gt;user-service&lt;/artifactId&gt;\t&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;\t&lt;name&gt;user-service&lt;/name&gt;\t&lt;description&gt;Demo project for Spring Boot&lt;/description&gt;\t&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Hoxton.SR6&lt;/spring-cloud.version&gt;\t&lt;/properties&gt;\t&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;\t&lt;/dependencies&gt;\t&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;\t&lt;/dependencyManagement&gt;\t&lt;build&gt; &lt;finalName&gt;user-service&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;\t&lt;/build&gt;&lt;/project&gt; 编码实现基本功能，以添加用户为例 12345678910111213141516171819202122232425package io.daocloud.userservice.service;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import io.daocloud.userservice.dao.UserDao;import io.daocloud.userservice.domain.User;/** * Author: Garroshh date: 2020/7/9 8:19 下午 */@Servicepublic class UserService &#123;\t@Autowired\tprivate UserDao userDao;\tpublic User add(User user) &#123; return userDao.save(user);\t&#125;\tpublic User get(long id) &#123; return userDao.getOne(id);\t&#125;&#125; 启动mysql服务 拉取镜像 12docker pull mysql:8.0.33//这个版本要与deployment.yaml和pv.yaml里面的版本一致 部署mysql 1234567891011121314151617181920212223242526272829303132333435363738394041424344piVersion: v1kind: Servicemetadata: name: mysqlspec: ports: - port: 3306 selector: app: mysql clusterIP: None---apiVersion: apps/v1kind: Deploymentmetadata: name: mysqlspec: selector: matchLabels: app: mysql strategy: type: Recreate template: metadata: labels: app: mysql spec: containers: - image: mysql:8.0.33 name: mysql env: # 在实际中使用 secret - name: MYSQL_ROOT_PASSWORD value: dangerous ports: - containerPort: 3306 name: mysql volumeMounts: - name: mysql-persistent-storage mountPath: /var/lib/mysql volumes: - name: mysql-persistent-storage persistentVolumeClaim: claimName: mysql-pv-claim 123456789101112131415161718192021222324252627apiVersion: v1kind: PersistentVolumemetadata: name: mysql-pv-volume labels: type: localspec: storageClassName: manual capacity: storage: 100Mi accessModes: - ReadWriteOnce hostPath: # 注意这里改成服务器上的一个空文件夹路径 path: &quot;/Users/lyl/moss&quot;---apiVersion: v1kind: PersistentVolumeClaimmetadata: name: mysql-pv-claimspec: storageClassName: manual accessModes: - ReadWriteOnce resources: requests: storage: 100Mi apply 12kubectl apply -f mysql-deployment.yaml kubectl apply -f mysql-pv.yaml 在容器中创建user database 123456789kubectl run -it --rm --image=mysql:8.0.33 --restart=Never mysqlclient -- mysql -h mysql -pdangerousIf you don&#x27;t see a command prompt, try pressing enter.mysql&gt; create database user;Query OK, 1 row affected (0.03 sec)mysql&gt; ^Cmysql&gt; exitBye 查看资源 1234567kubectl get po,svc NAME READY STATUS RESTARTS AGEpod/mysql-7b99cd9bc9-js7lh 1/1 Running 0 23mNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 176mservice/mysql ClusterIP None &lt;none&gt; 3306/TCP 23m 这里可能会遇到一个问题：The PersistentVolume “mysql-pv-volume” is invalid: spec.persistentvolumesource: Forbidden: spec.persistentvolumesource is immutable after creation，这是因为这个mysql服务已经存在了，解决方案是换一个名字或者把原来服务的删除 1234kubectl get pvkubectl get pvckubectl delete pvc mysql-pv-claimkubectl delete pv mysql-pv-volume 接下来将三个服务的jar包打好 在三个服务的子文件夹下运行 1mvn -B -Dmaven.test.skip clean package 接下来根据dockerfile将容器build出来 特别注意这里的标签名要和development.yaml里面的名字相符 123docker build -t user-service:2023 .docker build -t admin-service:2023 .docker build -t eureka:2023 . 接下来我们apply，通过kubernetes部署三个service 123kubectl apply -f admin-deployment.yaml kubectl apply -f admin-service.yaml//user-service和eureka以此类推 现在我们查看资源： 12345678910111213kubectl get po,svcNAME READY STATUS RESTARTS AGEpod/admin-service-84444789db-mtrdt 1/1 Running 0 7m20spod/eurkea-76cff4d569-j2hbt 1/1 Running 0 9m41spod/mysql-7b99cd9bc9-js7lh 1/1 Running 0 55mpod/user-service-7cb8755bd7-xhd6w 1/1 Running 0 9m2sNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/admin-service NodePort 10.108.205.242 &lt;none&gt; 10000:30521/TCP 7m7sservice/eureka NodePort 10.104.237.255 &lt;none&gt; 8080:31011/TCP 9m28sservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 3h27mservice/mysql ClusterIP None &lt;none&gt; 3306/TCP 55mservice/user-service NodePort 10.99.98.6 &lt;none&gt; 9090:32657/TCP 8m50s 验证部署已经成功 向user-service发送一个post请求 1curl -H &quot;Content-Type: application/json&quot; -X POST -d &#x27;&#123;&quot;name&quot;:&quot;张三&quot;, &quot;pwd&quot;:&quot;888&quot;&#125;&#x27; http://localhost:32657/user 收到回应 1&#123;&quot;id&quot;:1,&quot;name&quot;:&quot;张三&quot;,&quot;pwd&quot;:&quot;888&quot;&#125; 向user-service发送错误的post请求，收到报错 同时也可以访问eureka服务 访问特定的id 在admin-service中编码 1234@GetMapping(&quot;/user&quot;)public Object get(@RequestBody @Valid UserDto id)&#123; return userService.get(id);&#125; 发送请求 1curl http://localhost:30521/user?id=1 收到回应 1&#123;&quot;id&quot;:1,&quot;name&quot;:&quot;张三&quot;&#125; 负载均衡 直接使用自带服务中的RandomRule服务 在admin_service中的UserFeign.java中设置 123456789101112131415161718192021package io.daocloud.adminservice.fegin;import com.netflix.loadbalancer.RandomRule;import io.daocloud.adminservice.dto.UserDto;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PostMapping;/** * Author: Garroshh * date: 2020/7/9 8:39 下午 */@FeignClient(name = &quot;user-service&quot;, configuration = RandomRule.class) //使用随机策略public interface UserFeign &#123; @PostMapping(&quot;/user&quot;) Object add(UserDto userDto); @GetMapping(&quot;/port&quot;) String port();&#125; 接下来我们启动两个user-service服务，分别注册端口9090和9000 application.properties 12spring.application.name=user-serviceserver.port=9090 //另一个就是9000 更改user_deployment和user_service 123456789101112131415161718192021222324252627282930313233apiVersion: apps/v1kind: Deploymentmetadata: name: user-service-1 //另一个就是-2 labels: app: user-service-1spec: replicas: 1 selector: matchLabels: app: user-service-1 template: metadata: labels: app: user-service-1 spec: hostname: user-service-1 containers: - name: user-service-1 image: user-service-1:2023 imagePullPolicy: IfNotPresent env: - name: EUREKA_URL value: http://eureka:8080/eureka ports: - containerPort: 8080 resources: requests: cpu: 0.5 memory: 256Mi limits: cpu: 0.5 memory: 256Mi 12345678910111213apiVersion: v1kind: Servicemetadata: name: user-service-1 //另一个就是-2 labels: app: user-service-1spec: type: NodePort ports: - port: 9090 targetPort: 9090 selector: app: user-service 重新运行之后就可以看到新的服务在eureka上注册了 这时访问admin-service的port地址，就可以发现相应的user-service是随机的","tags":["docker","kubernetes","mysql"],"categories":["云原生与微服务开发"]},{"title":"使用容器部署服务","path":"/2023/07/01/使用容器部署服务/","content":"dockerfile多阶段构建，减小容器的大小,同时过程中产生的文件不会附加到最后，可以避免代码泄露 注意yaml里面有个path路径要改 JPA会自动清空数据 user-service 客户端负载均衡 新建一个springboot 项目 注意使用2.7.14版本 ORM object-relationship-mapping","tags":["kubernetes","dokcer"],"categories":["云原生与微服务开发"]},{"title":"将本地已有的项目初始化git并上传到远端的空仓库","path":"/2023/07/01/将本地已有的项目初始化git并上传到远端的空仓库/","content":"其实鼠鼠一直不知道怎么搞这个… 首先init仓库 1git init 将本地的内容提交 12git add .git commit -m &quot;msg&quot; 将远端设置为目标仓库并提交 123git remote add origin git@github.com:liuyaoli12345/train_ticket.gitgit branch -M maingit push -u origin main","tags":["git"],"categories":["小寄巧","git小寄巧"]},{"title":"git记录过大处理过程","path":"/2023/06/29/git记录过大处理过程/","content":"今天写编译原理的时候，codeLLDB说要更新，但是因为docker的端口映射有问题，所以只好从网页下载手动安装，但是我把50M大小的安装包拷贝到了Lab里面，而Lab又不允许超过10M，这个时候我直接git add . + git commit了，于是这个文件直接进入了git记录，导致文件过大无法上传了！ 查看大文件 1git rev-list --objects --all | grep &quot;$(git verify-pack -v .git/objects/pack/*.idx | sort -k 3 -n | tail -5 | awk &#x27;&#123;print$1&#125;&#x27;)&quot; 删除要删除的文件（把big-file.jar换成要删除的即可） 1git filter-branch --force --index-filter &#x27;git rm -rf --cached --ignore-unmatch big-file.jar&#x27; --prune-empty --tag-name-filter cat -- --all 出现这样的输出就是成功了 1Rewrite 6cdbb293d453ced07e6a07e0aa6e580e6a5538f4 (266/266) 如果要推送到远端需要用force 1git push origin master --force 通过垃圾回收GC彻底删除文件 123rm -rf .git/refs/original/git reflog expire --expire=now --allgit gc --prune=now 这样终于是解决了，幸好是最后一次算分的实验了，不然后患无穷啊，据助教说git记录是不准改的…标准的方法是从lab0 remake…","tags":["git","编译原理"],"categories":["小寄巧","git小寄巧"]},{"title":"Hello World","path":"/2023/06/27/hello-world/","content":"Welcome to Hexo ! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub . Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment"},{"path":"/baidu_verify_codeva-bITp12Wttw.html","content":"a295bb2ee5cfe35e51ae173d4bad1812"}]