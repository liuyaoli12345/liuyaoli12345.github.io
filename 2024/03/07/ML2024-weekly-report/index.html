<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="力崽！">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="http://blog.lsmcloud.top/2024/03/07/ml2024-weekly-report/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
        <meta name="description" content="Week 1   Process Progress    Basic Knowledge 了解高斯过程(Gaussian Process)与高斯过程回归   Few-shot learning Reading Literature Review Generalizing from a Few Examples: A Survey on Few-Shot Learning并阅读其中提到的一些论文">
<meta property="og:type" content="article">
<meta property="og:title" content="ML2024:weekly report">
<meta property="og:url" content="http://blog.lsmcloud.top/2024/03/07/ML2024-weekly-report/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Week 1   Process Progress    Basic Knowledge 了解高斯过程(Gaussian Process)与高斯过程回归   Few-shot learning Reading Literature Review Generalizing from a Few Examples: A Survey on Few-Shot Learning并阅读其中提到的一些论文">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://files.lsmcloud.top/blog2334f4df521747812b0dbb5eb0ab642f.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog34a2437b62d69c1b4640f6433df666c1.png">
<meta property="og:image" content="https://files.lsmcloud.top/blogc381365264df89ecaa7e4a53822f03cf.png">
<meta property="og:image" content="https://files.lsmcloud.top/blogbd3620ce03a0c52974ced0aac942103c.png">
<meta property="og:image" content="https://files.lsmcloud.top/blogbc3d1914c94ec384a877ad2c582f3c9c.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog8f1d5e214f3bb30557bb5e610daf6c38.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog292d4eb954649a20c1a2898ff545fec9.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog04eee0d65ea708f4ad63715e6c7b18b3.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog768e5de85c0755129abb89731acbdc0b.png">
<meta property="og:image" content="https://files.lsmcloud.top/blogd78bd307e49b906218f2c1be78938db0.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog9b61b388ade93946238c22103332be2d.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog639a1ec8ee8f6f9c81736fd7bcbc9db7.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog55aeb014492454a61c54aee007ec3d96.png">
<meta property="og:image" content="https://files.lsmcloud.top/blogea48567194d0bd9b332a71d12244124b.png">
<meta property="og:image" content="https://files.lsmcloud.top/blogc0336c63d1d90f824cb8d345258e7990.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog7638221aefd7974be18de4d527c2721f.png">
<meta property="og:image" content="https://files.lsmcloud.top/blogd6dda93add91a3851fdeafac3ce5ba44.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog82d2ed4fb8476547a58f57447b5f1759.png">
<meta property="og:image" content="https://files.lsmcloud.top/blogfe3b707deb7c56d86509266f5274f493.png">
<meta property="og:image" content="https://files.lsmcloud.top/bloge1bbe6759419d8aeaf6405683c20ec76.png">
<meta property="og:image" content="https://files.lsmcloud.top/blogb5ed3d8fc6f7667b63bc062c41f96250.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog22abc5c2ac59e86854e7fc3b0d4ae4c4.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog2c6435e31785ce63003d347afa58efd6.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog8c62b9e718a373705a6dbdc1e7afa686.png">
<meta property="og:image" content="https://files.lsmcloud.top/blogb53aa7dcbb0a6a502a4dc6ef9faba99b.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog9db73672ecc82c8ee99207db52940deb.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog479b3c7215166f00f00bfd1100c58976.png">
<meta property="og:image" content="https://files.lsmcloud.top/blogbaf6e3e8cb80d6bc5f5b89b89c4a6e4f.png">
<meta property="og:image" content="https://files.lsmcloud.top/blogfff66128cfe7073a3755e06611b96a56.png">
<meta property="og:image" content="https://files.lsmcloud.top/blogbdfe569634cc660de5c5816d65ac2b12.png">
<meta property="og:image" content="https://files.lsmcloud.top/blogf2573a4682c75e9919fc365700467765.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog479b3c7215166f00f00bfd1100c58976.png">
<meta property="og:image" content="https://files.lsmcloud.top/bloge38fccd4324b0215f46b20b15294ce19.png">
<meta property="og:image" content="https://files.lsmcloud.top/blog3e7a6b6c5289374968fb1841f7af786f.png">
<meta property="article:published_time" content="2024-03-07T12:56:34.000Z">
<meta property="article:modified_time" content="2024-07-03T00:15:30.340Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="ML">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://files.lsmcloud.top/blog2334f4df521747812b0dbb5eb0ab642f.png">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/li.png" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/li.png">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/images/li.png">
    <!--- Page Info-->
    
    <title>
        
            ML2024:weekly report -
        
        力崽的blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">


    
        
<link rel="stylesheet" href="/css/build/styles.css">

    

    
<link rel="stylesheet" href="/fonts/fonts.css">

    
<link rel="stylesheet" href="/fonts/Satoshi/satoshi.css">

    
<link rel="stylesheet" href="/fonts/Chillax/chillax.css">

    <!--- Font Part-->
    
    
    
    

    <!--- Inject Part-->
    
    <script id="hexo-configurations">
    let Global = window.Global || {};
    Global.hexo_config = {"hostname":"blog.lsmcloud.top","root":"/","language":"en"};
    Global.theme_config = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"14px","image_alignment":"center","image_caption":false,"link_icon":true},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":false,"list":[]},"code_block":{"copy":true,"style":"mac","font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":false,"expand":true,"init_open":true},"copyright":true,"lazyload":true,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"mobile_limit":2,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"website_counter":{"url":"https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js","enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"single_page":true,"open_graph":true,"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"fixed","image":{"light":"/images/wallspace.jpeg","dark":"/images/wallspace.jpeg"},"title":"力崽的blog","subtitle":{"text":["永恒诤语，不存在文明"],"hitokoto":{"enable":false,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":false,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":true,"links":{"github":"https://github.com/liuyaoli12345","instagram":null,"zhihu":null,"twitter":null,"email":"linshuoming12345@163.com"},"qrs":{"weixin":null}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null}]},"mermaid":{"enable":true,"version":"10.0.0"}},"version":"2.4.4","navbar":{"auto_hide":false,"color":{"left":"#f78736","right":"#367df7","transparency":35},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Categories":{"path":"/categories","icon":"fa-regular fa-folder"},"About":{"icon":"fa-regular fa-user","submenus":{"Blog":"https://blog.lsmcloud.top"}},"Links":{"icon":"fa-regular fa-link","submenus":{"添添崽":"https://blog.wuct.site/"}}},"search":{"enable":false,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"blur"},"home":{"sidebar":{"enable":true,"position":"left","first_item":"menu","announcement":null,"links":{"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Tags":{"path":"/tags","icon":"fa-regular fa-tags"},"Categories":{"path":"/categories","icon":"fa-regular fa-folder"}}},"article_date_format":"auto","categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}},"footerStart":"2023/6/28 11:45:14"};
    Global.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    Global.data_config = {"masonry":false};
  </script>
    
    <!--- Fontawesome Part-->
    
<link rel="stylesheet" href="/fontawesome/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/brands.min.css">

    
<link rel="stylesheet" href="/fontawesome/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/regular.min.css">

    
    
    
    
<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>


<body>
<div class="progress-bar-container">
    

    
        <span class="pjax-progress-bar"></span>
        <span class="swup-progress-icon">
            <i class="fa-solid fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container" id="swup">

    

    <div class="main-content-container">


        <div class="main-content-header">
            <header class="navbar-container">
    
    <div class="navbar-content">
        <div class="left">
            
            <a class="logo-title" href="http://blog.lsmcloud.top/">
                
                力崽的blog
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/"  >
                                    
                                        
                                            <i class="fa-regular fa-house"></i>
                                        
                                        HOME
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/archives"  >
                                    
                                        
                                            <i class="fa-regular fa-archive"></i>
                                        
                                        ARCHIVES
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/categories"  >
                                    
                                        
                                            <i class="fa-regular fa-folder"></i>
                                        
                                        CATEGORIES
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="has-dropdown" 
                                    href="#" onClick="return false;">
                                    
                                        
                                            <i class="fa-regular fa-user"></i>
                                        
                                        ABOUT&nbsp;<i class="fa-solid fa-chevron-down"></i>
                                    
                                </a>
                                <!-- Submenu -->
                                
                                    <ul class="sub-menu">
                                    
                                        <li>
                                        <a href="https://blog.lsmcloud.top">BLOG
                                        </a>
                                        </li>
                                    
                                    </ul>
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="has-dropdown" 
                                    href="#" onClick="return false;">
                                    
                                        
                                            <i class="fa-regular fa-link"></i>
                                        
                                        LINKS&nbsp;<i class="fa-solid fa-chevron-down"></i>
                                    
                                </a>
                                <!-- Submenu -->
                                
                                    <ul class="sub-menu">
                                    
                                        <li>
                                        <a target="_blank" rel="noopener" href="https://blog.wuct.site/">添添崽
                                        </a>
                                        </li>
                                    
                                    </ul>
                                
                            </li>
                    
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile drawer -->
    <div class="navbar-drawer w-full absolute top-0 left-0 bg-background-color">
        <ul class="drawer-navbar-list flex flex-col justify-start items-center">
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group " 
                        href="/"  >
                             
                                
                                    <i class="fa-regular fa-house"></i>
                                
                                HOME
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group " 
                        href="/archives"  >
                             
                                
                                    <i class="fa-regular fa-archive"></i>
                                
                                ARCHIVES
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group " 
                        href="/categories"  >
                             
                                
                                    <i class="fa-regular fa-folder"></i>
                                
                                CATEGORIES
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group has-dropdown" 
                        href="#" onClick="return false;">
                            
                                
                                    <i class="fa-regular fa-user"></i>
                                
                                ABOUT&nbsp;<i class="group-hover:rotate-180 transition-transform fa-solid fa-chevron-down"></i>
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                              
                        
                            <li class="text-base flex justify-center items-center hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                <a class="py-0.5" href="https://blog.lsmcloud.top">BLOG</a>
                            </li>
                        
                    
            
                
                    <li class="drawer-navbar-item text-base my-1.5 flex justify-center items-center">
                        <a class="rounded-3xl py-1.5 px-5 hover:border hover:!text-primary active:!text-primary group has-dropdown" 
                        href="#" onClick="return false;">
                            
                                
                                    <i class="fa-regular fa-link"></i>
                                
                                LINKS&nbsp;<i class="group-hover:rotate-180 transition-transform fa-solid fa-chevron-down"></i>
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                              
                        
                            <li class="text-base flex justify-center items-center hover:underline active:underline hover:underline-offset-1 rounded-3xl">
                                <a class="py-0.5" target="_blank" rel="noopener" href="https://blog.wuct.site/">添添崽</a>
                            </li>
                        
                    
            

        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="main-content-body">

            

            <div class="main-content">

                
                    <div class="post-page-container">
    <div class="article-content-container">

        <div class="article-title">
            
                
                
                <img src="https://files.lsmcloud.top/blog4c70e4b5c92c380ee44d20a62bf58b4d.png" alt="ML2024:weekly report" class="max-w-none"/>
                
                <h1 class="article-title-cover">ML2024:weekly report</h1>
            
            </div>
            
                    
        
        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/avatar.svg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">力崽！</span>
                        
                            <span class="author-label">Lv4</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2024-03-07 20:56:34</span>
        <span class="mobile">2024-03-07 20:56:34</span>
        <span class="hover-info">Created</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2024-07-03 08:15:30</span>
            <span class="mobile">2024-07-03 08:15:30</span>
            <span class="hover-info">Updated</span>
        </span>
    

    
        <span class="article-categories article-meta-item">
            <i class="fa-regular fa-folders"></i>&nbsp;
            <ul>
                
                
                    
                        
                        <li>
                            <a href="/categories/ML/">ML</a>&nbsp;
                        </li>
                    
                    
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/ML/">ML</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        


        <div class="article-content markdown-body">
            <h1 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h1><table>
<thead>
<tr>
<th>Process</th>
<th>Progress</th>
</tr>
</thead>
<tbody><tr>
<td>Basic Knowledge</td>
<td>了解高斯过程(Gaussian Process)与高斯过程回归</td>
</tr>
<tr>
<td>Few-shot learning</td>
<td>Reading Literature Review <br>Generalizing from a Few Examples: A Survey on Few-Shot Learning并阅读其中提到的一些论文</td>
</tr>
<tr>
<td>Ideas</td>
<td></td>
</tr>
<tr>
<td>Thesis Research</td>
<td></td>
</tr>
<tr>
<td>Interest</td>
<td></td>
</tr>
</tbody></table>
<h2 id="Gaussion-Process-Regression"><a href="#Gaussion-Process-Regression" class="headerlink" title="Gaussion Process Regression"></a>Gaussion Process Regression</h2><h3 id="Gaussion-Process"><a href="#Gaussion-Process" class="headerlink" title="Gaussion Process"></a>Gaussion Process</h3><p><a class="link" target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/29846048">svd分解 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<ol>
<li>协方差矩阵svd分解</li>
</ol>
<h2 id="Few-shot-learning"><a href="#Few-shot-learning" class="headerlink" title="Few-shot learning"></a>Few-shot learning</h2><p>至少这篇综述的作者将few-shot learning的最大问题归结为“无法找到一个可靠的经验风险最小化”，并依据逼近最佳经验风险最小化的方法将few-shot learning的研究分为三大方向：通过利用先验知识丰富数据集的Data方向，通过提供更加精准的先验假设减小假设空间的Model方向，通过训练时使用更有针对性的算法逼近最佳假设的Algorithm方向</p>
<blockquote>
<p>2.3.2 Unreliable Empirical Risk Minimizer. In general, Eest(H, I ) can be reduced by having a larger number of examples [17, 18, 41]. Thus, when there is sufficient training data with supervised information (i.e., I is large), the empirical risk minimizer hI can provide a good approximation R(hI ) to the best possible R(h∗) for h’s in H . However, in FSL, the number of available examples I is small. The empirical risk RI (h) may then be far from being a good approximation of the expected risk R(h), and the resultant empirical risk minimizer hI overfits. Indeed, this is the core issue of FSL supervised learning, i.e., the empirical risk minimizer hI is no longer reliable. Therefore, FSL is much harder. A comparison of learning with sufficient and few training samples is shown in Figure 1.</p>
</blockquote>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog2334f4df521747812b0dbb5eb0ab642f.png"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog34a2437b62d69c1b4640f6433df666c1.png"></p>
<h3 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h3><h4 id="Transforming-Samples-from-D-train"><a href="#Transforming-Samples-from-D-train" class="headerlink" title="Transforming Samples from $D_{train}$"></a>Transforming Samples from <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="5.718ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 2527.4 840.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g><g data-mml-node="TeXAtom" transform="translate(861,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(361,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(812,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1341,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1686,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></svg></mjx-container></h4><p>M. G. Miller, N. E. Matsakis, and P. A. Viola, “Learning from one example through shared densities on transforms,” in <em>Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)</em>, Hilton Head Island, SC, USA: IEEE Comput. Soc, 2000, pp. 464–471. doi: <a class="link" target="_blank" rel="noopener" href="https://doi.org/10.1109/CVPR.2000.855856">10.1109/CVPR.2000.855856 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>.</p>
<p>通过在讲原训练集里千奇百怪的手写数字进行图像变换求各个类别中的最小熵来提高数据集的质量，最终提升了分类器的水平</p>
<p>@inproceedings{Kwitt16a,<br>  author    = {R.<del>Kwitt and S.</del>Hegenbart and M.~Niethammer},<br>  title     = {One-Shot Learning of Scene Locations via Feature Trajectory Transfer},<br>  booktitle = {CVPR},<br>  year      = 2016} </p>
<p>描述了一个数据集不完全的场景：对于一片海滩，绝大多数都是风和日丽的照片，下雨天的图片很少，这会导致机器识别率降低，通过模型学习原有图片库上的特征，得到一个转换器</p>
<p>这篇文章的Methodology部分看不懂，</p>
<p>作者将xi定义为：</p>
<blockquote>
<p>Each image Ii is assigned to one of C scene locations (categories) with label yi ∈ [C]† and represented by a D-dimensional feature vector xi ∈ X ⊂ RD.</p>
</blockquote>
<p>我认为xi是表示第i张图片的D维矩阵，同时作者提到每个图片还有一个人工标注的“瞬态属性”向量，大抵是反应这张图片收到大雾、风雨、黑夜等情况干扰的严重程度？</p>
<blockquote>
<p>Additionally, each image is annotated with a vector of transient attribute strengths ai ∈RA+, where AT denotes the set of attributes and A = |AT |.</p>
</blockquote>
<p>作者表示他们使用高斯过程回归模型来预测，</p>
<blockquote>
<p>For a given scene location, we wish to estimate the path γk : R+ → X for every attribute in AT . In our case, we rely on a simple linear model to represent this path. Formally, lets ﬁx the scene location c and let Sc = {i : yi = c} be the index set of the M = |Sc| images from this location. The model, for the k-th attribute, can then be written as</p>
<p>xi = wk · ai[k] + bk + ǫk</p>
</blockquote>
<p>我这里不是很明白这个式子是通过ai合成xi，还是在用xi，ai求wk，qk？我感觉更像是后种</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blogc381365264df89ecaa7e4a53822f03cf.png"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blogbd3620ce03a0c52974ced0aac942103c.png"></p>
<h1 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2"></a>Week 2</h1><table>
<thead>
<tr>
<th>Process</th>
<th>Progress</th>
</tr>
</thead>
<tbody><tr>
<td>Basic Knowledge</td>
<td>学习基本的图像处理，包括霍夫变换，灰度矩阵，Rasterization 光栅化等</td>
</tr>
<tr>
<td>Few-shot learning</td>
<td>Reading Literature Review <br>Generalizing from a Few Examples: A Survey on Few-Shot Learning并阅读其中提到的一些论文</td>
</tr>
<tr>
<td>Ideas</td>
<td></td>
</tr>
<tr>
<td>Thesis Research</td>
<td>SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes（cvpr 2024）</td>
</tr>
<tr>
<td>Interest</td>
<td></td>
</tr>
</tbody></table>
<h1 id="Thesis-Research"><a href="#Thesis-Research" class="headerlink" title="Thesis Research"></a>Thesis Research</h1><p><strong>LAA-Net: Localized Artifact Attention Network for High-Quality Deepfakes Detection （cvpr 2024 source code haven’t been uploaded）</strong></p>
<p><em>一开始我以为这个方法能够甄别大模型生成的图片，但是看了文章所举的例子好像只能检测一张原图哪里可能被ps过，就失去了兴趣</em></p>
<p><strong>SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes（cvpr 2024）</strong></p>
<p><strong>3D Gaussian Splatting for Real-Time Radiance Field Rendering （cvpr 2023 best-paper award）</strong></p>
<p><em>最近关于Gaussian Splatting的文章似乎比较多，我个人有点感兴趣</em></p>
<h2 id="图形学中的基本变换"><a href="#图形学中的基本变换" class="headerlink" title="图形学中的基本变换"></a>图形学中的基本变换</h2><p><a class="link" target="_blank" rel="noopener" href="https://www.zhihu.com/tardis/zm/art/96717729?source_id=1003">图形学中的基本变换 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h2 id="MVP变换"><a href="#MVP变换" class="headerlink" title="MVP变换"></a>MVP变换</h2><p><a class="link" target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/552252893">观察矩阵的推导 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link" target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%BD%90%E6%AC%A1%E5%9D%90%E6%A0%87">齐次坐标 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link" target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/551648397">mvp变换 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h2 id="Rasterazation-光栅化"><a href="#Rasterazation-光栅化" class="headerlink" title="Rasterazation 光栅化"></a>Rasterazation 光栅化</h2><p><a class="link" target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/449289345">光栅化 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link" target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/450540827">光栅化 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><p>输入：一组静态图像和通过sfm分析后生成的有关图像的稀疏点阵</p>
<p><a class="link" target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Structure_from_motion">structure from motion <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>由于得到的点阵十分稀疏，所以很难估计法线，因此作者选择了不需要法线的3d gaussians</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blogbc3d1914c94ec384a877ad2c582f3c9c.png"></p>
<p>这个3d状态下的Gussian可以看做一个3d椭球，因此作者采用不是立方体或者锥体的表示形式，而是采用了椭球</p>
<p>椭球需要颜色和透明度信息，这里采用了球谐函数拟合颜色信息</p>
<p>这些椭球会被投影到二维平面，进行光栅化</p>
<h1 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3"></a>Week 3</h1><table>
<thead>
<tr>
<th>Process</th>
<th>Progress</th>
</tr>
</thead>
<tbody><tr>
<td>Basic Knowledge</td>
<td></td>
</tr>
<tr>
<td>Few-shot learning</td>
<td></td>
</tr>
<tr>
<td>Ideas</td>
<td></td>
</tr>
<tr>
<td>Thesis Research</td>
<td>SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes（cvpr 2024）<br>3D Gaussian Splatting for Real-Time Radiance Field Rendering</td>
</tr>
<tr>
<td>Interest</td>
<td></td>
</tr>
</tbody></table>
<h1 id="3D-Gaussian-Splatting-for-Real-Time-Radiance-Field-Rendering"><a href="#3D-Gaussian-Splatting-for-Real-Time-Radiance-Field-Rendering" class="headerlink" title="3D Gaussian Splatting for Real-Time Radiance Field Rendering"></a>3D Gaussian Splatting for Real-Time Radiance Field Rendering</h1><h2 id="Naive-Thoughts"><a href="#Naive-Thoughts" class="headerlink" title="Naive Thoughts"></a>Naive Thoughts</h2><ul>
<li>能否使用更加复杂的网络达到更好的效果？Resnet?</li>
<li>能够使用更加复杂的溅射模型表示更细粒度的3d信息？球谐函数溅射？</li>
<li>能否使用类似corpas的手段减少模型预测需要的图片样本？</li>
<li>Large model for filling the blank space? (Someone already started, see: <a class="link" target="_blank" rel="noopener" href="https://dreamgaussian.github.io/">dreamgaussian <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>)</li>
<li>Gaussian模型渲染的结果太大了，可能难以用于游戏、网页等场景（个人猜测），如何通过一些手段在不怎么降低精度的同时减小大小，比如移除不必要的渲染，尝试用更少的guassian，用更复杂的模型进行溅射，平滑化？</li>
</ul>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><h3 id="使用Gaussian模型表示世界"><a href="#使用Gaussian模型表示世界" class="headerlink" title="使用Gaussian模型表示世界"></a>使用Gaussian模型表示世界</h3><blockquote>
<p>Our representation has similarities to previous methods that use 2D points [Kopanas et al. 2021; Yifan et al. 2019] and assume each point is a small planar circle with a normal.</p>
</blockquote>
<p>作者借鉴2021年发表的一篇文章，这篇文章将每一个点都看做具有法线的小平面圆，但是做法对于极度稀疏的sfm点集不合适，因为预测和优化它们的法线过于困难（我还没详细了解为什么困难），所以作者最后采用了不要法线的几何模型：</p>
<p>3维高斯</p>
<h3 id="可微渲染-Differentiable-rendering-重要性与难点，以及为什么3维高斯是一个很棒的可微渲染基础"><a href="#可微渲染-Differentiable-rendering-重要性与难点，以及为什么3维高斯是一个很棒的可微渲染基础" class="headerlink" title="可微渲染 Differentiable rendering: 重要性与难点，以及为什么3维高斯是一个很棒的可微渲染基础"></a>可微渲染 Differentiable rendering: 重要性与难点，以及为什么3维高斯是一个很棒的可微渲染基础</h3><p><a class="link" target="_blank" rel="noopener" href="https://blog.qarnot.com/article/an-overview-of-differentiable-rendering">可微渲染 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>不论是通过图片获得3d模型，还是通过3d模型渲染2d图像，引入深度神经网络都是十分诱人的，但是要引入神经网络，以3d模型渲染2d图像来说，需要保证能找到这样一个渲染：</p>
<p><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="8.696ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 3843.6 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g><g data-mml-node="mo" transform="translate(781.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1837.6,0)"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mo" transform="translate(2596.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2985.6,0)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mo" transform="translate(3454.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></p>
<p>其中<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="1.061ex" height="1.618ex" role="img" focusable="false" viewBox="0 -705 469 715"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g></svg></mjx-container>代表了空间坐标、相机位置、光线、材料等，I是渲染出的图片</p>
<p>如果R是一个函数Loss，我们就通过一个可微的损失函数，通过</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.602ex;" xmlns="http://www.w3.org/2000/svg" width="7.253ex" height="4.749ex" role="img" focusable="false" viewBox="0 -1391 3206 2099"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(566,0)"><g data-mml-node="mi"><path data-c="4C" d="M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(313,-686)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g></g><rect width="1456" height="60" x="120" y="220"></rect></g><g data-mml-node="mfrac" transform="translate(1696,0)"><g data-mml-node="mrow" transform="translate(220,676)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g></g><g data-mml-node="mrow" transform="translate(237.5,-686)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g><rect width="1270" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p>进行反向传播和梯度下降操作，从而将这个渲染过程加入到神经网络中</p>
<h4 id="3维高斯、基于点的渲染与可微渲染"><a href="#3维高斯、基于点的渲染与可微渲染" class="headerlink" title="3维高斯、基于点的渲染与可微渲染"></a>3维高斯、基于点的渲染与可微渲染</h4><p>目前最流行（<em>至少作者这么说</em>）的渲染方式是基于点渲染 「<em>其他的方式还有votex-based（基于体积的），Mesh-based（基于网的）我还没有详细了解这些方法</em>」，输入是点云，输出是渲染的结果</p>
<p>但是基于点的方法最严重的缺陷在于它是严格不连续的，因此想进行可微渲染就十分麻烦，于是就出现了所谓的溅射“splatting”，它是指不再用一个“点”（<em>不知道最原始的点云里面的点有没有大小？</em>）而是用大于一个像素点的基元来代替点，比如圆、椭圆（上面作者引用的Kopanas的论文就采用了使用法线来表示方向的椭圆）、椭球（作者的3D Guassian模型渲染出来就像个椭球）等来表示（<em>我还没想明白为啥溅射能解决点云严格不连续的问题，我能理解这个基元是可微的，但是基元和基元之间怎么办，难道是连续的吗？</em>）</p>
<h4 id="Example：NeRF——基于体渲染公式将MLP引入三维重建"><a href="#Example：NeRF——基于体渲染公式将MLP引入三维重建" class="headerlink" title="Example：NeRF——基于体渲染公式将MLP引入三维重建"></a>Example：NeRF——基于体渲染公式将MLP引入三维重建</h4><p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog8f1d5e214f3bb30557bb5e610daf6c38.png"></p>
<p>模型输入：</p>
<p>一个五维向量：前三维代表世界坐标系下点的坐标，后两维代表球坐标系表示的点的观察角度（代码中实际并不是这样，首先为了刺激模型，作者还引入了由sin和cos函数计算的高维数据，同时观察角度使用的也不是球坐标系）</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog292d4eb954649a20c1a2898ff545fec9.png"></p>
<p>NeRF采用的并不是基于点的渲染，而是基于体积的渲染，采用公式：</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog04eee0d65ea708f4ad63715e6c7b18b3.png"></p>
<p>这个公式表示对于射线<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.02ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 451 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container>(其中<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.097ex" height="1.023ex" role="img" focusable="false" viewBox="0 -441 485 452"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g></g></g></svg></mjx-container>是原点，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="1.176ex" height="1.593ex" role="img" focusable="false" viewBox="0 -694 520 704"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g></svg></mjx-container>是射线的方向，每个t唯一对应着射线上的一个点)，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="6.649ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 2939 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g><g data-mml-node="mo" transform="translate(571,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(960,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1411,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1800,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(2161,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2550,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>代表着t点的密度，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="8.52ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 3765.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mo" transform="translate(433,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(822,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1273,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1662,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(2023,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2412,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2856.7,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(3376.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>代表着t点在空间中在<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="1.176ex" height="1.593ex" role="img" focusable="false" viewBox="0 -694 520 704"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g></g></svg></mjx-container>视角下直接观察的颜色，由于射线上有无数多的t点，最后渲染而成的2d图像上的点应当是这些<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="0.817ex" height="1.441ex" role="img" focusable="false" viewBox="0 -626 361 637"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g></svg></mjx-container>点按某种方式累和成的结果，同时除了透明度和点本身的颜色会影响这个点在累和中的效果外，射线到达此处的光强也是影响因素之一，也即<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="4.17ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1843 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mo" transform="translate(704,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1093,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(1454,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>.</p>
<p>从<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="4.278ex" height="1.773ex" role="img" focusable="false" viewBox="0 -626 1890.7 783.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(600,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1066,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1595,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></svg></mjx-container>到<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="3.452ex" height="2.084ex" role="img" focusable="false" viewBox="0 -626 1525.9 921"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(550,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1079,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></svg></mjx-container>进行积分，就相当于将从视线距相机最近处到距相机最远处的所有点的效果累和在一起，形成二维图像上的点</p>
<p>其中，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="3.052ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1349 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g><g data-mml-node="mo" transform="translate(571,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mo" transform="translate(960,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="2.74ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1211 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mo" transform="translate(433,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mo" transform="translate(822,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>是我们通过神经网络训练得到的函数，NeRF采用的基本神经网络是全连接的，也即<code>kerras.layer.Dense</code></p>
<p>射线<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="3.597ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1590 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(451,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(840,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(1201,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>的求取：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_rays</span>(<span class="params">H, W, focal, c2w</span>):</span><br><span class="line">    i, j = tf.meshgrid(tf.<span class="built_in">range</span>(W, dtype=tf.float32), tf.<span class="built_in">range</span>(H, dtype=tf.float32), indexing=<span class="string">'xy'</span>)</span><br><span class="line">    dirs = tf.stack([(i-W*<span class="number">.5</span>)/focal, -(j-H*<span class="number">.5</span>)/focal, -tf.ones_like(i)], -<span class="number">1</span>)</span><br><span class="line">    rays_d = tf.reduce_sum(dirs[..., np.newaxis, :] * c2w[:<span class="number">3</span>,:<span class="number">3</span>], -<span class="number">1</span>)</span><br><span class="line">    rays_o = tf.broadcast_to(c2w[:<span class="number">3</span>,-<span class="number">1</span>], tf.shape(rays_d))</span><br><span class="line">    <span class="keyword">return</span> rays_o, rays_d</span><br></pre></td></tr></table></figure></div>

<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog768e5de85c0755129abb89731acbdc0b.png"></p>
<p>为了让神经网络获得高频信号，NeRF作者发明了Position Encoding，通过一组sin cos函数将低频输入转换为高频信号（<em>这个思想内核我还没有理解清楚</em>）</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blogd78bd307e49b906218f2c1be78938db0.png"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog9b61b388ade93946238c22103332be2d.png"></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_nerf_model</span>(<span class="params">D=<span class="number">8</span>, W=<span class="number">256</span>, input_ch=<span class="number">3</span>, input_ch_views=<span class="number">3</span>, output_ch=<span class="number">4</span>, skips=[<span class="number">4</span>], use_viewdirs=<span class="literal">False</span></span>):</span><br><span class="line"></span><br><span class="line">    relu = tf.keras.layers.ReLU()</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">dense</span>(<span class="params">W, act=relu</span>): <span class="keyword">return</span> tf.keras.layers.Dense(W, activation=act)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'MODEL'</span>, input_ch, input_ch_views, <span class="built_in">type</span>(</span><br><span class="line">        input_ch), <span class="built_in">type</span>(input_ch_views), use_viewdirs)</span><br><span class="line">    input_ch = <span class="built_in">int</span>(input_ch)</span><br><span class="line">    input_ch_views = <span class="built_in">int</span>(input_ch_views)</span><br><span class="line"></span><br><span class="line">    inputs = tf.keras.Input(shape=(input_ch + input_ch_views))</span><br><span class="line">    inputs_pts, inputs_views = tf.split(inputs, [input_ch, input_ch_views], -<span class="number">1</span>)</span><br><span class="line">    inputs_pts.set_shape([<span class="literal">None</span>, input_ch])</span><br><span class="line">    inputs_views.set_shape([<span class="literal">None</span>, input_ch_views])</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(inputs.shape, inputs_pts.shape, inputs_views.shape)</span><br><span class="line">    outputs = inputs_pts</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(D):</span><br><span class="line">        outputs = dense(W)(outputs)</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> skips:</span><br><span class="line">            outputs = tf.concat([inputs_pts, outputs], -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> use_viewdirs:</span><br><span class="line">        alpha_out = dense(<span class="number">1</span>, act=<span class="literal">None</span>)(outputs)</span><br><span class="line">        bottleneck = dense(<span class="number">256</span>, act=<span class="literal">None</span>)(outputs)</span><br><span class="line">        inputs_viewdirs = tf.concat(</span><br><span class="line">            [bottleneck, inputs_views], -<span class="number">1</span>)  <span class="comment"># concat viewdirs</span></span><br><span class="line">        outputs = inputs_viewdirs</span><br><span class="line">        <span class="comment"># The supplement to the paper states there are 4 hidden layers here, but this is an error since</span></span><br><span class="line">        <span class="comment"># the experiments were actually run with 1 hidden layer, so we will leave it as 1.</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>):</span><br><span class="line">            outputs = dense(W//<span class="number">2</span>)(outputs)</span><br><span class="line">        outputs = dense(<span class="number">3</span>, act=<span class="literal">None</span>)(outputs)</span><br><span class="line">        outputs = tf.concat([outputs, alpha_out], -<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        outputs = dense(output_ch, act=<span class="literal">None</span>)(outputs)</span><br><span class="line"></span><br><span class="line">    model = tf.keras.Model(inputs=inputs, outputs=outputs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></div>

<p>具体的训练过程：</p>
<pre class="mermaid">stateDiagram-v2
    相片像素 --&gt; 相机坐标+视角
    相机坐标+视角 --&gt; 世界坐标+视角
    世界坐标+视角 --&gt; 输入mlp网络
    输入mlp网络 --&gt; 预测空间密度与颜色
    预测空间密度与颜色 --&gt; 使用体渲染公式得到图像
    使用体渲染公式得到图像 --&gt; 与测试图像比较获得loss
    与测试图像比较获得loss --&gt; 根据loss进行反向传播</pre>

<h4 id="Gaussian-Splatting"><a href="#Gaussian-Splatting" class="headerlink" title="Gaussian Splatting"></a>Gaussian Splatting</h4><p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog639a1ec8ee8f6f9c81736fd7bcbc9db7.png"></p>
<p>sfm提供的点被初始化，提供一些Gaussian椭球，然后对高斯椭球对特定的方向进行投影得到2D高斯分布（看起来就像一个个椭圆），对这些椭圆进行光栅化，得到2d图像，使用距离和D-SSIM构造一个损失，通过反向传播进行优化，这里的Adaptive Density Control 用于进一步改善3d Gaussian的分布。</p>
<h5 id="对高斯椭球进行投影"><a href="#对高斯椭球进行投影" class="headerlink" title="对高斯椭球进行投影"></a>对高斯椭球进行投影</h5><p>作者基本参考这篇文章：EWA volume splatting</p>
<p>首先一个中心为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="1.138ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 503 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g></g></g></svg></mjx-container>，分布为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="2.389ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1056 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g></g></g></svg></mjx-container>三维的高斯模型可以进行仿射变换、卷积变换，还可以沿着某一方向做积分得到二维高斯分布（投影的关键），投影得到<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="3.129ex" height="2.702ex" role="img" focusable="false" viewBox="0 -944.5 1383 1194.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mover"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="mi" transform="translate(1089,477.1) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>也非常容易，只需要在原来的协防差矩阵中去掉积分的那个变量对应的行和列即可</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog55aeb014492454a61c54aee007ec3d96.png"></p>
<p>最后可以得出这个公式(<em>我还没细看数学原理</em>)：</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blogea48567194d0bd9b332a71d12244124b.png"></p>
<p>其中W对<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="2.389ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1056 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g></g></g></svg></mjx-container>进行视口变换，J对<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="2.389ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1056 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g></g></g></svg></mjx-container>进行投影变换（为了将投影变换变成仿射型的定义，这里还采用了泰勒展开和雅各布矩阵（<em>还没细看</em>））</p>
<h5 id="Back-probackation"><a href="#Back-probackation" class="headerlink" title="Back probackation"></a>Back probackation</h5><p>同时为了更好的适配梯度下降，作者没有采用协方差矩阵的标准定义（因为协方差矩阵必须是半正定的，而半正定矩阵这个条件很容易被梯度下降过程破坏），最后作者还是采用了更像椭球溅射的表示，用一个缩放矩阵<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.459ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 645 727"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g></g></g></svg></mjx-container>和旋转矩阵<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.048ex;" xmlns="http://www.w3.org/2000/svg" width="1.717ex" height="1.593ex" role="img" focusable="false" viewBox="0 -683 759 704"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g></g></g></svg></mjx-container>来表示对高斯椭球的微调。在代码实现中，这两个矩阵被分别存储在一个3维向量s和一个四元数q中，基于此，作者提供了对每个参数的链式梯度下降公式</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blogc0336c63d1d90f824cb8d345258e7990.png"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog7638221aefd7974be18de4d527c2721f.png"></p>
<h5 id="Adaptive-Density-Control"><a href="#Adaptive-Density-Control" class="headerlink" title="Adaptive Density Control"></a>Adaptive Density Control</h5><p>反向传播可以更新高斯椭球的形状、大小、透明度和颜色，但是高斯椭球的数量、位置等信息无法直接通过反向传播更新，作者额外构建了Adaptive Density Control 机制实现对这些信息的更新</p>
<p>对高斯椭球的移除实现上每100轮做一次，遍历所有的高斯椭球，移除那些<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.448ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 640 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g></g></g></svg></mjx-container>值接近0的</p>
<p>对于添加，反向传播的参数能看出一些端倪，比如一个高斯椭球有关位置<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="3.296ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 1457 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(988,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g></g></svg></mjx-container>变量的梯度比较大，这就意味着指向该pos的地方需要一个高斯椭球，这是我们可以clone原来的高斯椭球并直接放到pos梯度指向的位置去</p>
<p>同时一些地方可能存在一个奇大无比的高斯椭球并且出现了过拟合的情况，这时就要在该区域添加高斯椭球，作者采用的方式时将原本的高斯椭球通过一个超参数变小，然后克隆两份</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blogd6dda93add91a3851fdeafac3ce5ba44.png"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog82d2ed4fb8476547a58f57447b5f1759.png"></p>
<h5 id="高速光栅化（超越NeRf的关键）Fast-Differentiable-Rasterizer-for-Gaussians"><a href="#高速光栅化（超越NeRf的关键）Fast-Differentiable-Rasterizer-for-Gaussians" class="headerlink" title="高速光栅化（超越NeRf的关键）Fast Differentiable Rasterizer for Gaussians"></a>高速光栅化（超越NeRf的关键）Fast Differentiable Rasterizer for Gaussians</h5><p><strong>关键：Tile based, Pre sort Gaussian</strong></p>
<p>NeRF需要对每一个像素构建一个射线，每一个射线进行一大堆采样</p>
<p>总体来说，经典的点云可微渲染是这样的：</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blogfe3b707deb7c56d86509266f5274f493.png"></p>
<p><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="2.009ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 888 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g></g></g></svg></mjx-container>集合是覆盖在该像素点前的2d高斯云，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="1.719ex" height="1.357ex" role="img" focusable="false" viewBox="0 -442 760 599.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(466,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>是颜色<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="1.937ex" height="1.355ex" role="img" focusable="false" viewBox="0 -441 856 598.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(562,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>是该2d高斯的不透明度，渲染的图像也是通过一系列2d高斯效果的叠加实现，与NeRF最大的区别在于NeRF需要高昂的空间采样成本</p>
<p>![](/Users/lyl/Desktop/Screenshot 2024-04-02 at 18.55.44.png)</p>
<p>tile based rendering 基于图块的渲染</p>
<p>作者将整个屏幕空间分成了16<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0.02ex;" xmlns="http://www.w3.org/2000/svg" width="1.76ex" height="1.09ex" role="img" focusable="false" viewBox="0 -491 778 482"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g></g></g></svg></mjx-container>16个tiles，然后对每个tile找到会影响它的那些Gaussian（只取相交置信区间为99%的那些高斯球体）</p>
<p>然后根据每个高斯球体覆盖的tiles实例化它们，同时用一个类似hashtable的结构进行存储，键值记录了空间深度和tile ID</p>
<p>接下来根据键值对guassian椭球进行排序，排序算法使用Radix sort，这种排序算法可以利用GPU进行高速排序</p>
<p><strong>GPU Radix sort</strong></p>
<p>![](/Users/lyl/Desktop/Screenshot 2024-04-02 at 19.29.25.png)</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/bloge1bbe6759419d8aeaf6405683c20ec76.png"></p>
<p>只需要完成这一次排序，后续的渲染都可以依据此进行</p>
<p>完成排序后，对于每个tile都可以构建一个list，记录针对该tile从前往后的guassian list</p>
<p>开始渲染，首先对于每个tile启动一个线程池，将前面构建的高斯椭球表加载到共享内存中，然后针对每一个像素（<em>我在想这里能不能并行？</em>）从前往后遍历每个tile的list，当<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.448ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 640 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g></g></g></svg></mjx-container>累积到每个值即可停止（很多搞NeRF的人也是这么优化的）</p>
<p>这个高速渲染的过程不仅加速了渲染，也加速了反向传播的过程(<em>还没细看</em>)</p>
<h1 id="Week-5"><a href="#Week-5" class="headerlink" title="Week 5"></a>Week 5</h1><table>
<thead>
<tr>
<th>Task</th>
<th>Progress</th>
</tr>
</thead>
<tbody><tr>
<td>Learning the Basics for Gussian Splatting and Generation Models</td>
<td>learning Basic VAE, GANs</td>
</tr>
<tr>
<td>3D gaussian splatting reconstructions for Human Body</td>
<td></td>
</tr>
<tr>
<td>Other interesting works for 3D gaussian</td>
<td>DreamGaussian</td>
</tr>
</tbody></table>
<h2 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h2><h3 id="autoencoder"><a href="#autoencoder" class="headerlink" title="autoencoder"></a>autoencoder</h3><p>最原始的想法是通过Encoder寻找一个将原始图像压缩后的latent，并且确保可以通过一个decoder从这个latent生成相同类型的图像</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blogb5ed3d8fc6f7667b63bc062c41f96250.png"></p>
<h3 id="variational-autoencoder"><a href="#variational-autoencoder" class="headerlink" title="variational autoencoder"></a>variational autoencoder</h3><p>但是仅仅得到一个固定的向量latent十分无聊，因为这个latent并不能很好的反应input x之间的关系，例如两个类似的图像，它们得到的latent可能完全不一样，也不能对它进行特征合成之类的操作</p>
<p>variational autoencoder得到的并不是一个直接的latent，而是由参数<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="1.061ex" height="1.618ex" role="img" focusable="false" viewBox="0 -705 469 715"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g></svg></mjx-container>描述的一个概率分布（一般是高斯分布），相似的图像在这里被映射到相似的概率分布，这些概率分布可以进行合成或者其他操作</p>
<p>(<em>我想这里我还得更加深入的看看，目前只是简单听了下UC Berkeley CS 198-126,还没看论文</em>)</p>
<h3 id="vector-Quantised-variational-autoencoder"><a href="#vector-Quantised-variational-autoencoder" class="headerlink" title="vector Quantised-variational autoencoder"></a>vector Quantised-variational autoencoder</h3><p>基于高斯分布latent的vae，Encoder输出的是一个参数化的分布，但是对于一些任务，离散的latent会更加合适（<em>比如NLP方向，不过我还没细想为啥是latent，我能想象到decoder的output应该是离散化的，因为词语没法连续，但是为什么latent也要是离散的？</em>）</p>
<p>vq-vae采用了codebook和聚类的想法，将Encoder输出的那些非法的，不在codebook中的向量通过近邻算法聚类到相应的codebook中的类别去</p>
<p>（<em>codebook中的类别要如何安排、损失和反向传播要如何进行这些问题还没有研究</em>）</p>
<h2 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h2><h3 id="Arch"><a href="#Arch" class="headerlink" title="Arch"></a>Arch</h3><p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog22abc5c2ac59e86854e7fc3b0d4ae4c4.png"></p>
<h3 id="Cross-Entropy"><a href="#Cross-Entropy" class="headerlink" title="Cross Entropy"></a>Cross Entropy</h3><p>熵是用真实分布和真实编码计算平均编码长度，交叉熵是用真实分布（我们需要在具体任务中自行定义什么是真实分布）和预测编码计算平均编码长度</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog2c6435e31785ce63003d347afa58efd6.png"></p>
<p>交叉熵与熵的差被叫做KL散度，我们可以利用<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="15.142ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 6692.6 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)"></path></g><g data-mml-node="mn" transform="translate(1311,-241.4) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1714.6,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(1714.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2103.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(2675.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3342.3,0)"><path data-c="2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mi" transform="translate(4398.1,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(5192.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(6192.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container>证明KL散度始终大于0.</p>
<p><a class="link" target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/370428/why-is-the-cross-entropy-always-more-than-the-entropy?newreg=d9c23f643cf24c79b6c90842a1259a7c">See here <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>从而证明交叉熵始终大于等于熵（相等条件：预测分布等于真实分布），基于此可以构造各种各样的损失函数</p>
<p>Gan所采用的损失函数就是交叉熵（的负数），其中生成模型G尝试将这个损失最小化（负数绝对值越大，意味着D模型分类得越糟糕），而D模型则不断尝试将这个损失最大化</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog8c62b9e718a373705a6dbdc1e7afa686.png"></p>
<h3 id="Conditional-Gan"><a href="#Conditional-Gan" class="headerlink" title="Conditional Gan"></a>Conditional Gan</h3><p>有时候我们可能有更高的生成要求，比如生成特定的数字或者特定的汉字，如果我们只是把一大堆数字图片和标签丢给Generator让Generator学习，而Discriminator又只能拿到图片的话，最后Generator可能会把9学习成6，而Discriminator没有办法阻止这一点</p>
<p>于是我们进一步改进，让Discriminator也能拿到标签，这样当D看到一个G生成的一个非常真是的6但是却打上了9的标签时能够及时识别为fake，这样G就不得不认真的分类学习了</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blogb53aa7dcbb0a6a502a4dc6ef9faba99b.png"></p>
<h3 id="Gan-问题"><a href="#Gan-问题" class="headerlink" title="Gan 问题"></a>Gan 问题</h3><ol>
<li>如果D模型太强，交叉熵接近0，权重在反向传播时也接近0，G模型不知道怎么调整自己来继续和D模型比赛，直接摆烂睡大觉</li>
<li>mode collapse，G发现有一张图片特别能迷惑D，于是为了取胜，G之后越来越倾向于输出这张图片，最后甚至只输出这张图片</li>
<li>损失不收敛，模型D和模型G会不断的竞争，损失也可能不断的摇摆，无法确定什么时候两个模型已经足够好，并且两个模型都有过拟合的风险</li>
</ol>
<h3 id="Improving-GANs"><a href="#Improving-GANs" class="headerlink" title="Improving GANs"></a>Improving GANs</h3><p>我们可以稍微调整损失函数为</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog9db73672ecc82c8ee99207db52940deb.png"></p>
<p>这样的损失函数在D模型完全判断正确时给出一个超大的loss，拍着G的屁股让它大踏步的改生成策略</p>
<h1 id="Week-6"><a href="#Week-6" class="headerlink" title="Week 6"></a>Week 6</h1><table>
<thead>
<tr>
<th>Papper</th>
<th>Core Idea</th>
</tr>
</thead>
<tbody><tr>
<td>HUGS: Human Gaussian Splats</td>
<td>使用SMPL模型进行初始化，在训练中的高斯球云可以偏离这个初始化以便于适应衣服、头发等内容，使用三个MLP神经网络分别预测高斯椭球的future triplane中的颜色、透明度、缩放、旋转和LBS权重，从而对人体不同的动作和视角进行合成</td>
</tr>
<tr>
<td>Gaussian Shell Maps for Efficient 3D Human Generation</td>
<td>同样采用了SMPL进行初始化，不同的是采用了Multi Shell技术，将人体理解为一层一层向外包裹的Shell，同时通过GANS网络训练一层一层shell，使其与真是图像越来越接近，这种设计可以灵活的更换不同的shell层，从而实现给人体更换发型、服装等特性</td>
</tr>
</tbody></table>
<h2 id="HUGS-Human-Gaussian-Splats"><a href="#HUGS-Human-Gaussian-Splats" class="headerlink" title="HUGS: Human Gaussian Splats"></a>HUGS: Human Gaussian Splats</h2><p>HUGS将人体和环境都基于高斯球云进行表示，并使用SMPL模型初始化人体的高斯球云，为了更好的拟合SMPL模型中没有的头发、服饰等特征，高斯球云可以在后续训练中适当偏离SMPL模型。同时高斯椭球的颜色、不透明度、缩放、旋转、Linear Blend Skinning 权重等特征通过feature triplane（三平面特征）进行表征，通过训练三个MLP模型对feature triplane进行预测，并将预测得到的颜色球谐函数、缩放等属性用于构建人体，LBS权重则用于驱使高斯球云组成不同的人体形态，从而实现新动作的合成。</p>
<h2 id="Gaussian-Shell-Maps-for-Efficient-3D-Human-Generation"><a href="#Gaussian-Shell-Maps-for-Efficient-3D-Human-Generation" class="headerlink" title="Gaussian Shell Maps for Efficient 3D Human Generation"></a>Gaussian Shell Maps for Efficient 3D Human Generation</h2><p>GSM结合了3D 高斯和基于CNN的生成式网络，核心思想是将3D高斯锚定到一系列基于SMPL模型生成的壳(Shell)中，并通过生成模型生成对应的shell map，并作为对应Gaussian的颜色、透明度等特征的来源，同时引入GANs网络对渲染结果进行优化，并针对人体专门提供了甄别手足、面部的Discriminator。通过将高斯球体与shell基于重心坐标一一锚定，变化高斯球云可以通过首先变换Shell mesh，再查询高斯球体在变换后的shell mesh中对应的顶点来获取变换后的位置。</p>
<h2 id="GauHuman-Articulated-Gaussian-Splatting-from-Monocular-Human-Videos"><a href="#GauHuman-Articulated-Gaussian-Splatting-from-Monocular-Human-Videos" class="headerlink" title="GauHuman: Articulated Gaussian Splatting from Monocular Human Videos"></a>GauHuman: Articulated Gaussian Splatting from Monocular Human Videos</h2><p>GauHuman同样基于SMPL模型进行初始化，并且同样引入MLP模型对LBS权重进行预测，与HUGS不同的是，GauHuman并没有使用feature triplane来表示高斯球体的颜色、缩放等特征，（这句我不能确定）<em>而是仍然将这些信息存储直接在高斯球体中，这进一步提高了渲染效率</em>，同时为了避免直接使用MLP模型预测LBS权重带来的时间开销和低质量的渲染效果，GauHuman引入两个针对SMPL LBS权重进行细化的MLP模型，其中<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.355ex;" xmlns="http://www.w3.org/2000/svg" width="6.556ex" height="1.901ex" role="img" focusable="false" viewBox="0 -683 2897.6 840.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mi" transform="translate(1051,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="msub" transform="translate(1802,0)"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(714,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g></g></svg></mjx-container>用于细化SMPL模型中的pose参数<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="1.061ex" height="1.618ex" role="img" focusable="false" viewBox="0 -705 469 715"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g></g></g></svg></mjx-container>，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="10.414ex" height="2.213ex" role="img" focusable="false" viewBox="0 -683 4603.2 978"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mi" transform="translate(1051,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="msub" transform="translate(1802,0)"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(485,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(1035,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(1585,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(2054,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(2520,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g></g></g></svg></mjx-container>用于细化LBS权重偏移。同时GauHuman改进了Adaptive Density Control过程，通过引入KL散度将高斯球体间的距离也纳入了Density Control的考虑指标，从而实现更好的训练效果。</p>
<h2 id="GaussianAvatar-Towards-Realistic-Human-Avatar-Modeling-from-a-Single-Video-via-Animatable-3D-Gaussians"><a href="#GaussianAvatar-Towards-Realistic-Human-Avatar-Modeling-from-a-Single-Video-via-Animatable-3D-Gaussians" class="headerlink" title="GaussianAvatar: Towards Realistic Human Avatar Modeling from a Single Video via Animatable 3D Gaussians"></a>GaussianAvatar: Towards Realistic Human Avatar Modeling from a Single Video via Animatable 3D Gaussians</h2><p>GaussianAvatar同样使用了SMPL模型进行初始化，对于输入的单目视频中特定的一帧所对应的SMPL模型，GaussianAvatar首先对该SMPL模型采样得到一个UV positional map I，并传递给一个pose encoder以得到一个Pose Feture，由于单目视频带来的数据偏差，仅仅通过这个Pose Feature进行训练很容易导致模型对某些常见帧的过拟合，GaussianAvatar还引入了一个Optimizable Feature Tensor来学习粗略的动作表征以增强泛化性，二者整合后，由一个训练好的AutoDecoder解码获取高斯球体颜色、缩放等性质，最后将SMPL模型的LBS权重应用到人体模型中，实现动作变换。</p>
<h1 id="Week-7"><a href="#Week-7" class="headerlink" title="Week 7"></a>Week 7</h1><p>框架 （技术分类，应用分类）</p>
<p>领域意义(Gaussian) 现有工作分类 每类展开 每类文章的特点，参考已有综述</p>
<p>略读，感兴趣的可以精读</p>
<p>综述应当压缩</p>
<p>输入输出，解决的问题，功能；现有方法的问题；怎么做的</p>
<p>摘要（任务），Introduction（现在的问题），Method（实现），（实验部分略过），related work（可以略过），appendix（一般是推导和补充）</p>
<p><em>这周被软工III的大作业压得喘不过气，主要是之前水得太狠了，只能邻近ddl的时候一通胡赶，所以这周的进展很小…</em></p>
<h2 id="3DGS目前主要的应用分类"><a href="#3DGS目前主要的应用分类" class="headerlink" title="3DGS目前主要的应用分类"></a>3DGS目前主要的应用分类</h2><h3 id="Simultaneous-Localization-and-Mapping-SLAM"><a href="#Simultaneous-Localization-and-Mapping-SLAM" class="headerlink" title="Simultaneous Localization and Mapping (SLAM)"></a>Simultaneous Localization and Mapping (SLAM)</h3><p>主要是帮助快速建立一个当前环境的模型表示，对于智能机器人、自动驾驶设备有非常重要的作用</p>
<p>3dgs作为一个新的3d表示形式，其各向异性可以更好的描述场景，通过改进Adaptive density control，有机会实现对于现实环境实现更好的映射，同时3d高斯的计算加速也有助于更高效的场景建立</p>
<h3 id="Dynamic-Scene-Modeling"><a href="#Dynamic-Scene-Modeling" class="headerlink" title="Dynamic Scene Modeling"></a>Dynamic Scene Modeling</h3><p>动态场景建模，反映到我目前在看的人体主要有两个方面，一个是3D人体的重建及对于固定动作的动画化，另一个则是合成能做出全新动作的人体，后者比前者要求更高的泛化性。</p>
<h3 id="AI-Generated-Content-AIGC"><a href="#AI-Generated-Content-AIGC" class="headerlink" title="AI-Generated Content (AIGC)"></a>AI-Generated Content (AIGC)</h3><p>3dgs为***to 3d提供了新的3d场景表示，相较于NeRF的隐式表示，3D高斯显式的表示场景，更适合作为生成模型的生成目标，同时3dgs作为场景表示也更由于过去基于DreamFusion工作使用的Mesh+Texture的结构，反映到人体，人体模型的3d生成也是一个常见方向</p>
<h2 id="人体"><a href="#人体" class="headerlink" title="人体"></a>人体</h2><p>一种分类是</p>
<p>身体、头部、头发和手部</p>
<p>对于身体又可以进一步分为full body modeling，同时按训练来源可以分为多角度视频和单目视频，</p>
<p>我目前计划的分类</p>
<pre class="mermaid">mindmap
    root((分类))
        按部位分
            人体整体
                GSMs
            头部
            头发和手部
        按目标分*有一点点不合适的就是几乎所有重建工作都有提到动画化
            人体重建
                多目重建：
                ASH:特色是引入了通过UV参数化，将高斯椭球锚定到可变形的网格上，高斯椭球的参数可以在二维纹理空间中学习，从动作捕捉器获取的骨骼运动信息到动态化参数的高斯椭球的过程就被简化成了2维图像到2维图像的转换任务。
                Animatable Gaussians:特色是首先从多角度的图片学习一个从SMPL模型衍生而来的参数化模板，并通过将模板正交投影到正面和背面两个视图来在二维空间中学习高斯椭球的参数化，这两个与姿势相关的参数化视图则通过styleUNet生成模型生成
                单目重建：
                GSMs:特色是引入了multi shell based scaffold, 通过styleGAN2生成shell map获得3DGS的属性，并针对头部、手部、足部提供专门的discrminater提高，同时3DGS提供的显示表征提供了便利的编辑，可以在多个实例之间互换服装
                HUGS:特色是使用三平面表征，并通过MLP模型预测高斯椭球的性质和人体的LBS weight
                GauHuman:（与HUGs比较起来说）特色是引入了两个MLP微调模型为SMPL模型的LBS权重和姿态参数进行微调而非直接使用MLP进行参数预测，同时通过引入KL散度等改进了prune/split/clone过程
                GaussianAvatar:特色是通过将姿态动作和特征属性解耦为两个不同的特征向量，通过encoder和decoder架构获得标准空间下人体模型
            动态人体*deformation
                HUGS通过MLP预测LBS权重，再配合提供的Joint Configuration进行LBS变形可以实现全新动作的合成
                GSMs通过首先变换shell map并查询高斯椭球在mesh中关联的顶点变换后的位置来完成变形
            人体生成
                ASH通过给定骨架姿态，变形人体模版，将相应高斯椭球锚定到变形模版的顶点上，并配合可动画化的纹理实现动作合成</pre>



<p><em>我在想要不要把这些文章人体重建的过程大致抽象出来，因为他们都好像，但是又怕写错 :(</em></p>
<h1 id="Week-8"><a href="#Week-8" class="headerlink" title="Week 8"></a>Week 8</h1><p>3D高斯泼溅所带来的高速渲染和显示表征为人体重建、动画化、人体生成任务提供了实时渲染和进一步优化细节和运动控制的机会。使用3D高斯溅射作为3D人体相关任务的基元并学习得到的显示表征的人体相较于使用神经网络辐射场（NeRF）学习得到的隐式表征的人体在渲染速度和泛化性上都有巨大的提升。最近的工作主要聚焦于利用3D高斯泼溅来重建得到可以实时渲染的虚拟人体或头像等，同时实现更精确的动作控制和新动作的合成，此外3D高斯泼溅与生成模型结合，生成高质量的人体模型也取得了一些突破。</p>
<p>对于人体整体的重建，HuGS提出了基于多角度视频利用3D高斯泼溅生成人体的方法，同时提出了一个从粗到细的人体动画化过程，首先使用LBS合成新的人体动作，而对于动作变换中非线性的部分，比如松弛服装在运动中的变换，HuGS提出了一个浅层神经网络进行捕捉和局部的变形改善。</p>
<p>HUGS使用单目视频即可训练，并使用三平面特征来表征高斯，高斯的特征(<em>这里有疑问！</em>)由三个分别负责预测颜色与不透明度、位置和旋转参数、LBS权重的MLP神经网络预测得到，这种方式方式相较于直接参数化单个高斯能够更好的避免过拟合风险，提供了更好的泛化性，能更好的完成全新动作合成的任务。</p>
<p>GauHuman则使用MLP模型对SMPL中的LBS权重偏移进行预测，同时使用另一个MLP模型对姿态进行进一步细化，避免直接使用MLP模型预测LBS权重可能带来的时间开销和低质量渲染。同时GauHuman还通过引入KL散度和改进合并操作来改进3D gaussian splatting原本方法中的分裂、克隆、合并过程。</p>
<p>GaussianAvatar结合了动态外观网络和可优化张量，从给定的SMPL模型帧采样点的位置并据此通过一个姿态编码器获得姿态特征张量，另外提供一个可优化外观特征张量来学习人体的外貌特点，这两个特征向量通过一个高斯参数阶码器得到标准空间下高斯的各个参数。</p>
<p>3DGS-Avatar指出HUGS、GauHuman等方法虽然达成了高速的渲染，但为此牺牲了对服装随着不同姿态产生的非刚性变形的拟合。3DGS-Avatar将变形分为非刚性变形和刚性变形两步来完成，同时通过一个能够考虑到光照效应和局部变形的小型MLP网络解码颜色，从而在渲染速度和渲染质量之间达到较好的平衡。</p>
<p>为了解决直接从3D空间学习高斯参数带来的计算困扰，一些方法尝试将问题空间从3维投影到2维，以降低问题的复杂度，同时便于利用已经相对完善的二维网络进行参数学习。</p>
<p><em>（我不确定GSMs属不属于这一类，GSMs也是通过生成shell map来参数化高斯的，并且用的也是“适合2维空间的”CNN模型，不过GSMs的作者并没有提到这一点，不过看起来GSMs应该归到生成一类）</em></p>
<p>ASH提出首先通过一个变形网络生成一个与运动关联的模板网格，基于此预测和运动相关的纹理映射，生成的纹理映射通过位置阶码器和外观解码器为高斯提供参数，这样模型可以在纹理空间学习高斯的参数而不是在3D空间中直接学习。</p>
<p>类似的，Animatable Gaussians通过将标准空间当中的模板网格人体投影到人体正面和人体背面两个方向，从而在这两个2D空间中学习高斯参数。同时Animatable Gaussians提出利用主成分分析（PCA）将全新的姿态驱动信号投影到训练过的姿态空间中以获得针对新姿势生成的更好泛化性。</p>
<p>除了人体整体的重建和动画化，3DGS为人体头部的重建与动画化也带来了较大的进展，GaussianAvatars通过将FLAME网格和高斯泼溅结合来取得更好的渲染效果，高斯泼溅的主要用途是对FLAME网格无法精确描绘的细节或没有跟踪的元素进行补偿。初始化时FLAME网格上的每一个三角形都被放置一个高斯，并在训练过程中进行优化，同时为了在自适应密度控制中保持可控性，GaussianAvatars通过独特的继承机制确保每一个高斯都与FLAME网格中的一个三角形相关联，当对FLAME网格进行动画化时，每一个高斯也相应做出变形。</p>
<p>GaussianAvatars虽然取得了很好的重构效果和动画化，但是训练时并没有和照明信息解耦，Relightable Gaussian Codec Avatars<em>（这篇工作感觉涉及到比较晦涩的关于球谐函数和球谐光照的知识，我感觉我一下子搞不定:(）</em>。</p>
<p>Gaussian Head Avatar指出直接使用FLAME网格和LBS进行面部变形这种相对简单的线性操作很难表征精细的面部表情，相对的，Gaussian Head Avatar提出使用一个MLP网络直接通过输入表情相关参数来预测高斯在从中性表情到目标表情之间的位移来实现高达2K分辨率的头部图像渲染。</p>
<p>在人体生成方面，</p>
<p>Gaussian Shell Maps(GSMs)则通过壳式结构结合了CNN生成模型和3D高斯泼溅，一系列壳式网格基于SMPL模型适当的膨胀或收缩，CNN生成模型为这些壳式网格生成纹理映射，这些纹理信息进一步确定了锚定到网格上的高斯的属性。这种壳式表征可以更好的表示SMPL模型中不包含的服装、头发等特征。同时高斯泼溅的显式表示和壳式结构层次性的表征为编辑人体提供了很大的便利，可以很方便的交换生成模型之间不同壳的属性，实现为人体模型更换发型和服装的需求。</p>
<h1 id="Week9"><a href="#Week9" class="headerlink" title="Week9"></a>Week9</h1><table>
<thead>
<tr>
<th>Task</th>
<th>Achievements</th>
</tr>
</thead>
<tbody><tr>
<td>复现3dgs</td>
<td>目前已经跑通，在进行code review，因为我本身pytorch基础很差，所以得边看边学</td>
</tr>
<tr>
<td>generative  model</td>
<td>学习transformer架构</td>
</tr>
<tr>
<td>few-shot reconstruction</td>
<td></td>
</tr>
<tr>
<td>综述</td>
<td>补齐另外两篇综述中</td>
</tr>
</tbody></table>
<h2 id="单词向量空间"><a href="#单词向量空间" class="headerlink" title="单词向量空间"></a>单词向量空间</h2><p><em>应该是是最直接，最古早的文本编码思想了</em></p>
<p>基本想法是给定一个文本，用一个向量表示该文本的“语义”，向量的每一维对应一个单词，其数值为该单词在该文本中出现的频数或权值</p>
<p>基本假设是文本中所有单词的出现情况表示了文本的语义内容</p>
<p>我们的基本空间是全体文本<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.873ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 828 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g></g></g></svg></mjx-container>和全体文本中的所有单词<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="2.371ex" height="1.595ex" role="img" focusable="false" viewBox="0 -683 1048 705"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g></g></svg></mjx-container>，它们可以共同组成矩阵<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.928ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 852 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g></g></g></svg></mjx-container></p>
<p>最早常用的权值叫 单词频率-逆文本频率</p>
<p>其中单词频率指这个单词在目标文本中的频率，即</p>
<p><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -1.251ex;" xmlns="http://www.w3.org/2000/svg" width="10.985ex" height="3.619ex" role="img" focusable="false" viewBox="0 -1046.6 4855.3 1599.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="msub" transform="translate(704,0)"><g data-mml-node="mi"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="TeXAtom" transform="translate(676,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(345,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2243.1,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(3298.8,0)"><g data-mml-node="mrow" transform="translate(258.8,548.1) scale(0.707)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="msub" transform="translate(361,0)"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(345,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(220,-345) scale(0.707)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="msub" transform="translate(361,0)"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></g><rect width="1316.4" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<p>逆文本频率指的是这个单词在全部文本的多少篇文本中出现过的倒数取log</p>
<p><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -1.108ex;" xmlns="http://www.w3.org/2000/svg" width="14.128ex" height="3.334ex" role="img" focusable="false" viewBox="0 -983.5 6244.6 1473.4"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g><g data-mml-node="mi" transform="translate(504,0)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g><g data-mml-node="mi" transform="translate(1332,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mo" transform="translate(2358.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(3414.6,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(4692.6,0)"><path data-c="2061" d=""></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4859.2,0)"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(314.4,485) scale(0.707)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(520,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-345) scale(0.707)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="msub" transform="translate(520,0)"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><rect width="1145.4" height="60" x="120" y="220"></rect></g></g></g></g></svg></mjx-container></p>
<p>即这个单词越是只在这个文本中出现，就越能代表这个文本，自然重要度也就越高</p>
<p>乘起来就是<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.666ex;" xmlns="http://www.w3.org/2000/svg" width="9.154ex" height="2.211ex" role="img" focusable="false" viewBox="0 -683 4046.3 977.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mi" transform="translate(704,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mi" transform="translate(1453,0)"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g><g data-mml-node="mi" transform="translate(1957,0)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g><g data-mml-node="msub" transform="translate(2785,0)"><g data-mml-node="mi"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="TeXAtom" transform="translate(676,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(345,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></g></g></svg></mjx-container>了</p>
<p>度量两个文本的相似度可以用余弦</p>
<p><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -1.308ex;" xmlns="http://www.w3.org/2000/svg" width="20.902ex" height="3.255ex" role="img" focusable="false" viewBox="0 -860.6 9238.7 1438.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(469,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(814,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1692,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(1990,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(2519,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2970,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3315,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="msub" transform="translate(3676,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(345,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g><g data-mml-node="mo" transform="translate(5062.1,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(6117.8,0)"><g data-mml-node="mrow" transform="translate(809.7,548.1) scale(0.707)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(899,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="msub" transform="translate(1177,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-370) scale(0.707)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mo" transform="translate(278,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msub" transform="translate(556,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1455,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mo" transform="translate(1733,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mo" transform="translate(2011,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msub" transform="translate(2289,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(3235.3,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mo" transform="translate(3513.3,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g></g><rect width="2880.8" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></p>
<h2 id="word-embedding"><a href="#word-embedding" class="headerlink" title="word embedding"></a>word embedding</h2><p>如果我们有10000个单词，我们可能会想用一个长度10000的向量来表示单词，只要是哪个单词对应的编号就位1，其他为全0</p>
<p>但是这样我们无法得到各个单词之间的相关性，我们希望能有一种无监督的方法，自然地帮助我们找到单词之间的关系</p>
<p>两种很棒的无监督方式是</p>
<ol>
<li>聚类式</li>
<li>生成对抗式</li>
</ol>
<p>word embedding更类似于后者</p>
<p>我们可以训练一个函数<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="1.244ex" height="2.059ex" role="img" focusable="false" viewBox="0 -705 550 910"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g></g></g></svg></mjx-container>，这个函数用一个中心单词预测周边单词出现的概率</p>
<p>这个结构就好像：</p>
<p>输入是one-hot编码的单词，一个神经网络将one-hot单词编码到隐藏维度，隐藏维度接上softmax就是每个单词出现在下一个的概率</p>
<p>因为one-hot就是只有一个维度为1的向量，所以相当于选出了隐藏层权重矩阵的一行，也就是隐藏层的权重矩阵就是我们的wordvec单词表了！假设我们有十亿个单词，隐藏层的维度是300，我们就相当于将十亿维的one-hot表示压缩成了300词向量表示，而且还获得了语义信息。</p>
<h2 id="position-embedding"><a href="#position-embedding" class="headerlink" title="position embedding"></a>position embedding</h2><h1 id="Sparse-reconstruction-Few-shot-amp-3DGS"><a href="#Sparse-reconstruction-Few-shot-amp-3DGS" class="headerlink" title="Sparse reconstruction (Few-shot) & 3DGS"></a>Sparse reconstruction (Few-shot) &amp; 3DGS</h1><h2 id="Encoder-Decoder-style"><a href="#Encoder-Decoder-style" class="headerlink" title="Encoder-Decoder style"></a>Encoder-Decoder style</h2><p><em>感觉主要利用Decoder提供的先验知识进行单图重建</em></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog479b3c7215166f00f00bfd1100c58976.png"></p>
<p>一个点云decoder预测basic point cloud，一个triplane decoder预测高斯属性</p>
<h2 id="Predicting-Supervise-Information"><a href="#Predicting-Supervise-Information" class="headerlink" title="Predicting Supervise Information"></a>Predicting Supervise Information</h2><p><em>感觉主要利用depth model提供的深度先验知识</em></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blogbaf6e3e8cb80d6bc5f5b89b89c4a6e4f.png"></p>
<h2 id="Generative-amp-GAN-style"><a href="#Generative-amp-GAN-style" class="headerlink" title="Generative & GAN style"></a>Generative &amp; GAN style</h2><p><em>主要利用生成模型来“想象”这个输入在其他视角下是什么样子的，从而实现数据增量</em></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blogfff66128cfe7073a3755e06611b96a56.png"></p>
<h1 id="Week-10"><a href="#Week-10" class="headerlink" title="Week 10"></a>Week 10</h1><table>
<thead>
<tr>
<th>Task</th>
<th>Achievements</th>
</tr>
</thead>
<tbody><tr>
<td>复现3dgs</td>
<td>目前已经跑通，在进行code review，因为我本身pytorch基础很差，所以得边看边学</td>
</tr>
<tr>
<td>generative  model</td>
<td>学习transformer架构</td>
</tr>
<tr>
<td>few-shot reconstruction</td>
<td>review cvpr 2020 best paper</td>
</tr>
<tr>
<td>综述</td>
<td>整理综述，列出重要方法</td>
</tr>
</tbody></table>
<h2 id="Gaussian-Shadow-Casting-for-Neural-Characters"><a href="#Gaussian-Shadow-Casting-for-Neural-Characters" class="headerlink" title="Gaussian Shadow Casting for Neural Characters"></a>Gaussian Shadow Casting for Neural Characters</h2><p>这是我目前看得比较莫名奇妙的文章,这篇文章首先把训练视频经过NeRF得到一张密度分布图，将密度分布图转换成人体高斯集合，并提出一种针对高斯集合的光线追踪法，基于此计算人体的阴影</p>
<p>我不能理解的就是为啥他非要通过nerf输出的密度分布图来重建高斯图呢？用smpl模型初始化然后通过学习一个pose，调整好pose以后将smpl模型转换成高斯不是更爽么，还是因为那个nerf模型能够顺便帮他把法线和反照率预测出来而原本的高斯方法不行所以他才一定要用nerf呢？</p>
<h1 id="cvpr-2020-best-paper：Unsupervised-Learning-of-Probably-Symmetric-Deformable-3D-Objects-from-Images-in-the-Wild"><a href="#cvpr-2020-best-paper：Unsupervised-Learning-of-Probably-Symmetric-Deformable-3D-Objects-from-Images-in-the-Wild" class="headerlink" title="cvpr 2020 best paper：Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild"></a>cvpr 2020 best paper：Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild</h1><p>这篇工作将“对称性”这个先验用得很妙</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blogbdfe569634cc660de5c5816d65ac2b12.png"></p>
<p>重建一个物体，需要深度和反照率，</p>
<p>这篇工作提出了一个pipeline，首先判断一张照片中，有哪些像素可能是3D空间中的对称关系，而这些有对称关系的像素，他们的反照率和深度信息应当是相近的，而非对称像素不受这个约束，于是损失就成为了：<br><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blogf2573a4682c75e9919fc365700467765.png"></p>
<p>其中<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.292ex" height="1ex" role="img" focusable="false" viewBox="0 -431 571 442"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g></g></g></svg></mjx-container>和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.92ex" height="1.742ex" role="img" focusable="false" viewBox="0 -759 848.5 770"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g><g data-mml-node="mo" transform="translate(604,363) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path></g></g></g></g></svg></mjx-container>是将图像翻转分别预测的对称置信度，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="4.035ex" height="2.156ex" role="img" focusable="false" viewBox="0 -759 1783.3 953"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g><g data-mml-node="mo" transform="translate(504,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(948.7,0)"><g data-mml-node="mi"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g><g data-mml-node="mo" transform="translate(590.2,363) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path></g></g></g></g></svg></mjx-container>分别是翻转后学习构造的图像，损失函数会基于<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.292ex" height="1ex" role="img" focusable="false" viewBox="0 -431 571 442"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g></g></g></svg></mjx-container>置信度要求<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.14ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 504 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g></g></g></svg></mjx-container>和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.888ex" height="1.717ex" role="img" focusable="false" viewBox="0 -759 834.7 759"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g><g data-mml-node="mo" transform="translate(590.2,363) scale(0.707)"><path data-c="2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path></g></g></g></g></svg></mjx-container>尽可能相近。</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2 4 </span><br><span class="line">0 1 1 1</span><br><span class="line">1 1 1 0</span><br></pre></td></tr></table></figure></div>

<h1 id="Week-11"><a href="#Week-11" class="headerlink" title="Week 11"></a>Week 11</h1><p>这周主要是进一步了解Encoder-Decoder style的泛化性工作，我重点选择了</p>
<p><strong>AGG: Amortized Generative 3D Gaussians for Single Image to 3D</strong>和<strong>Triplane Meets Gaussian Splatting: Fast and Generalizable Single-View 3D Reconstruction with Transformers</strong>这两篇文章</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog479b3c7215166f00f00bfd1100c58976.png"></p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/bloge38fccd4324b0215f46b20b15294ce19.png"></p>
<p>两种方法都使用了混合式的中间表征来对物体的形状和纹理分别表示和重建，triplaneMeetsGaussian额外引入了triplane的隐式表示来增强泛化性，针对triplane再提供一层decoder预测高斯属性，避免直接使用decoder预测高斯属性时导致的问题。</p>
<p>两篇文章都使用transformer进行encoder和decoder的设计，我在想encoder和decoder的训练过程是否有可能改进</p>
<ol>
<li>文本监督 文本+图像 one-shot 调研风险</li>
<li>MAMBA 目前还没有看到 mamba的引入 效果堪忧</li>
</ol>
<h1 id="Week-12"><a href="#Week-12" class="headerlink" title="Week 12"></a>Week 12</h1><p>这周主要在进行综述文章的翻译和补充工作，我之前还没有写过英文论文，因此进度比之前用中文缓了一些，争取周三完成我的部分</p>
<h2 id="关于文本监督引入图像重建的可能性"><a href="#关于文本监督引入图像重建的可能性" class="headerlink" title="关于文本监督引入图像重建的可能性"></a>关于文本监督引入图像重建的可能性</h2><p>调研上我目前还没有看到关于文本和图像作为联合输入进行重建的文章</p>
<p>学长说这可能是一个应用点，但是最大的问题在于数据集上，很多时候可能需要使用CLIP来标注图片，这样数据的质量就堪忧了</p>
<h2 id="MAMBA的引入"><a href="#MAMBA的引入" class="headerlink" title="MAMBA的引入"></a>MAMBA的引入</h2><p>和学长进行了交流，学长说他已经就mamba替换transformer做过尝试，发现训练效率有比较大的下降，风险比较大</p>
<h1 id="Week-13"><a href="#Week-13" class="headerlink" title="Week 13"></a>Week 13</h1><p>按照身体部位来给人体重建的文章分类未免也太蠢了，我打算试试按照技术分类，这样显得更聪明，但也有风险，作为一个菜鸟，我很担心我对这些技术的理解有偏差呢</p>
<table>
<thead>
<tr>
<th>Research</th>
<th>pose-dependent deformation</th>
<th>novel pose animation</th>
<th>fast training</th>
<th>real-time rendering</th>
<th>monocular input</th>
<th>Super-resolution</th>
<th>Implementation</th>
</tr>
</thead>
<tbody><tr>
<td>HuGS</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>Coarse to fine</td>
</tr>
<tr>
<td>*GPS-Gaussian</td>
<td>- (No need)</td>
<td>No</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>Yes</td>
<td>Depth information estimated &amp; guided</td>
</tr>
<tr>
<td>HUGS</td>
<td>No</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>Triplane decoding</td>
</tr>
<tr>
<td>GaussianAvatar</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes *0.5-6h single 3090</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>UV map feature tensor</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>*GPS-Gaussian等不使用SMPL模型的方法或许不能在此之列，因为他们行事不必受到SMPL模型的限制</p>
<p>未来可能的方向：</p>
<p>引入关于服装的物理先验知识来辅助完成服装被动画化时的变形</p>
<h1 id="Week-14"><a href="#Week-14" class="headerlink" title="Week 14"></a>Week 14</h1><h2 id="泛化性生成"><a href="#泛化性生成" class="headerlink" title="泛化性生成"></a>泛化性生成</h2><p>泛化性网络 2d视频-&gt;6d xyz+t</p>
<p>聚焦泛化性 （gaussian，带有生成性质的不是重点）</p>
<p>同时用服务器复现代码，形成统一认识</p>
<p>泛化性方向gaussian可能没有效果好，泛化性下大家不看时间看精度</p>
<p>dynamic 先不用看，先看泛化性</p>
<p>nerf 4d泛化复现</p>
<p>泛化性高斯+综述 ppt记录 新文章 复现开源文章</p>
<table>
<thead>
<tr>
<th>任务</th>
<th>进展</th>
</tr>
</thead>
<tbody><tr>
<td>泛化性的复现</td>
<td>复现MVSplat</td>
</tr>
<tr>
<td>动画化的学习</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<h2 id="目前主要的任务"><a href="#目前主要的任务" class="headerlink" title="目前主要的任务"></a>目前主要的任务</h2><p>我目前聚焦泛化性，主要对MVSplat和pixelSplat进行复现</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://files.lsmcloud.top/blog3e7a6b6c5289374968fb1841f7af786f.png"></p>
<p>而这整体的pipeline是相似的，MVSplat使用Multi-view transformer获得基于单目视频上下文相关的feature，通过cost volume存储监督信息，并查询，最后通过Unet获得高斯元的具体参数，这里方法的最大特点是十分依赖初始化，由于gaussian splatting 中的clone和purne过程不是直接可微的，所以往往初始化后点的数量是固定的，实际上很难出现巨大的改变。</p>
<p>+放出来结果</p>
<h1 id="Week-18"><a href="#Week-18" class="headerlink" title="Week 18"></a>Week 18</h1><h2 id="MonoNerf"><a href="#MonoNerf" class="headerlink" title="MonoNerf"></a>MonoNerf</h2><table>
<thead>
<tr>
<th>论文</th>
<th>目的</th>
</tr>
</thead>
<tbody><tr>
<td>Attention is all you need</td>
<td>了解transformer架构</td>
</tr>
<tr>
<td>Self-Calibrating 4D Novel View Synthesis from Monocular Videos Using Gaussian Splatting</td>
<td>与目标工作相近</td>
</tr>
<tr>
<td>Diffusion4D: Fast Spatial-temporal Consistent 4D Generation via Video Diffusion Models</td>
<td>4d生成</td>
</tr>
<tr>
<td>3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting</td>
<td>这里面Non-rigid Module有些没看懂，得问一问</td>
</tr>
<tr>
<td>A taxonomy and evaluation of dense two-frame stereo correspondence algorithms</td>
<td>了解cost volume流程</td>
</tr>
</tbody></table>
<p>复现结果</p>
<p><video src="/Users/lyl/Desktop/1gpusBalloon2_novelviewtime_080000_rgbs_00.mp4"></video></p>
<p><video src="/Users/lyl/Desktop/1gpusBalloon2_novelviewtime_080000_rgbs_d_00.mp4"></video></p>
<p>明确量化结果</p>
<h2 id="pipeline"><a href="#pipeline" class="headerlink" title="pipeline"></a>pipeline</h2><p>![Screenshot 2024-06-30 at 17.29.33](/Users/lyl/Library/Application Support/typora-user-images/Screenshot 2024-06-30 at 17.29.33.png)</p>
<h2 id="迁移计划"><a href="#迁移计划" class="headerlink" title="迁移计划"></a>迁移计划</h2><p>如何使用光流对高斯进行监督</p>
<p>泛化性（学长的意思是不再按照mvsplat的流程来做，主要原因是使用的人太多，并且渲染速度（训练速度？）比较慢）</p>
<p>![Screenshot 2024-06-30 at 17.41.18](/Users/lyl/Library/Application Support/typora-user-images/Screenshot 2024-06-30 at 17.41.18.png)</p>
<h2 id="目前此领域相近的文章"><a href="#目前此领域相近的文章" class="headerlink" title="目前此领域相近的文章"></a>目前此领域相近的文章</h2><p><a class="link" target="_blank" rel="noopener" href="https://arxiv.org/pdf/2406.01042">Self-Calibrating 4D Novel View Synthesis from Monocular Videos Using Gaussian Splatting <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>![Screenshot 2024-06-30 at 20.38.46](/Users/lyl/Library/Application Support/typora-user-images/Screenshot 2024-06-30 at 20.38.46.png)</p>
<p>代码</p>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul>
        <li><strong>Title:</strong> ML2024:weekly report</li>
        <li><strong>Author:</strong> 力崽！</li>
        <li><strong>Created at
                :</strong> 2024-03-07 20:56:34</li>
        
            <li>
                <strong>Updated at
                    :</strong> 2024-07-03 08:15:30
            </li>
        
        <li>
            <strong>Link:</strong> https://blog.lsmcloud.top/2024/03/07/ML2024-weekly-report/
        </li>
        <li>
            <strong>
                License:
            </strong>
            
            This work is licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0</a>.
            

        </li>
    </ul>
</div>

            </div>
        

        
            <ul class="post-tags-box">
                
                    <li class="tag-item">
                        <a href="/tags/ML/">#ML</a>&nbsp;
                    </li>
                
            </ul>
        

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                        rel="prev"
                        href="/2024/04/25/%E5%9B%9B%E5%85%83%E6%95%B0%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"
                        >
                            <span class="left arrow-icon flex justify-center items-center">
                                <i class="fa-solid fa-chevron-left"></i>
                            </span>
                            <span class="title flex justify-center items-center">
                                <span class="post-nav-title-item">四元数与计算机图形学</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                        rel="next"
                        href="/2024/03/06/%E5%86%8D%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E7%BB%87%E7%BB%93%E6%9E%84/"
                        >
                            <span class="title flex justify-center items-center">
                                <span class="post-nav-title-item">再习计算机组织结构</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex justify-center items-center">
                                <i class="fa-solid fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        


        
    </div>

    
        <div class="toc-content-container">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">On this page</div>
        <div class="page-title">ML2024:weekly report</div>
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-1"><span class="nav-text">Week 1</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Gaussion-Process-Regression"><span class="nav-text">Gaussion Process Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Gaussion-Process"><span class="nav-text">Gaussion Process</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Few-shot-learning"><span class="nav-text">Few-shot learning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Data"><span class="nav-text">Data</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-2"><span class="nav-text">Week 2</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Thesis-Research"><span class="nav-text">Thesis Research</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%BE%E5%BD%A2%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8F%98%E6%8D%A2"><span class="nav-text">图形学中的基本变换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MVP%E5%8F%98%E6%8D%A2"><span class="nav-text">MVP变换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Rasterazation-%E5%85%89%E6%A0%85%E5%8C%96"><span class="nav-text">Rasterazation 光栅化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="nav-text">算法流程</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-3"><span class="nav-text">Week 3</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3D-Gaussian-Splatting-for-Real-Time-Radiance-Field-Rendering"><span class="nav-text">3D Gaussian Splatting for Real-Time Radiance Field Rendering</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Naive-Thoughts"><span class="nav-text">Naive Thoughts</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Method"><span class="nav-text">Method</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8Gaussian%E6%A8%A1%E5%9E%8B%E8%A1%A8%E7%A4%BA%E4%B8%96%E7%95%8C"><span class="nav-text">使用Gaussian模型表示世界</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%AF%E5%BE%AE%E6%B8%B2%E6%9F%93-Differentiable-rendering-%E9%87%8D%E8%A6%81%E6%80%A7%E4%B8%8E%E9%9A%BE%E7%82%B9%EF%BC%8C%E4%BB%A5%E5%8F%8A%E4%B8%BA%E4%BB%80%E4%B9%883%E7%BB%B4%E9%AB%98%E6%96%AF%E6%98%AF%E4%B8%80%E4%B8%AA%E5%BE%88%E6%A3%92%E7%9A%84%E5%8F%AF%E5%BE%AE%E6%B8%B2%E6%9F%93%E5%9F%BA%E7%A1%80"><span class="nav-text">可微渲染 Differentiable rendering: 重要性与难点，以及为什么3维高斯是一个很棒的可微渲染基础</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-5"><span class="nav-text">Week 5</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#VAE"><span class="nav-text">VAE</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#autoencoder"><span class="nav-text">autoencoder</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#variational-autoencoder"><span class="nav-text">variational autoencoder</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#vector-Quantised-variational-autoencoder"><span class="nav-text">vector Quantised-variational autoencoder</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GAN"><span class="nav-text">GAN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Arch"><span class="nav-text">Arch</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cross-Entropy"><span class="nav-text">Cross Entropy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Conditional-Gan"><span class="nav-text">Conditional Gan</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Gan-%E9%97%AE%E9%A2%98"><span class="nav-text">Gan 问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Improving-GANs"><span class="nav-text">Improving GANs</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-6"><span class="nav-text">Week 6</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#HUGS-Human-Gaussian-Splats"><span class="nav-text">HUGS: Human Gaussian Splats</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Gaussian-Shell-Maps-for-Efficient-3D-Human-Generation"><span class="nav-text">Gaussian Shell Maps for Efficient 3D Human Generation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GauHuman-Articulated-Gaussian-Splatting-from-Monocular-Human-Videos"><span class="nav-text">GauHuman: Articulated Gaussian Splatting from Monocular Human Videos</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GaussianAvatar-Towards-Realistic-Human-Avatar-Modeling-from-a-Single-Video-via-Animatable-3D-Gaussians"><span class="nav-text">GaussianAvatar: Towards Realistic Human Avatar Modeling from a Single Video via Animatable 3D Gaussians</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-7"><span class="nav-text">Week 7</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3DGS%E7%9B%AE%E5%89%8D%E4%B8%BB%E8%A6%81%E7%9A%84%E5%BA%94%E7%94%A8%E5%88%86%E7%B1%BB"><span class="nav-text">3DGS目前主要的应用分类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Simultaneous-Localization-and-Mapping-SLAM"><span class="nav-text">Simultaneous Localization and Mapping (SLAM)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dynamic-Scene-Modeling"><span class="nav-text">Dynamic Scene Modeling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AI-Generated-Content-AIGC"><span class="nav-text">AI-Generated Content (AIGC)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%BA%E4%BD%93"><span class="nav-text">人体</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-8"><span class="nav-text">Week 8</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week9"><span class="nav-text">Week9</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%95%E8%AF%8D%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4"><span class="nav-text">单词向量空间</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#word-embedding"><span class="nav-text">word embedding</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#position-embedding"><span class="nav-text">position embedding</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Sparse-reconstruction-Few-shot-amp-3DGS"><span class="nav-text">Sparse reconstruction (Few-shot) &amp; 3DGS</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Encoder-Decoder-style"><span class="nav-text">Encoder-Decoder style</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Predicting-Supervise-Information"><span class="nav-text">Predicting Supervise Information</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Generative-amp-GAN-style"><span class="nav-text">Generative &amp; GAN style</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-10"><span class="nav-text">Week 10</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Gaussian-Shadow-Casting-for-Neural-Characters"><span class="nav-text">Gaussian Shadow Casting for Neural Characters</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#cvpr-2020-best-paper%EF%BC%9AUnsupervised-Learning-of-Probably-Symmetric-Deformable-3D-Objects-from-Images-in-the-Wild"><span class="nav-text">cvpr 2020 best paper：Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-11"><span class="nav-text">Week 11</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-12"><span class="nav-text">Week 12</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B3%E4%BA%8E%E6%96%87%E6%9C%AC%E7%9B%91%E7%9D%A3%E5%BC%95%E5%85%A5%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA%E7%9A%84%E5%8F%AF%E8%83%BD%E6%80%A7"><span class="nav-text">关于文本监督引入图像重建的可能性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MAMBA%E7%9A%84%E5%BC%95%E5%85%A5"><span class="nav-text">MAMBA的引入</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-13"><span class="nav-text">Week 13</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-14"><span class="nav-text">Week 14</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B3%9B%E5%8C%96%E6%80%A7%E7%94%9F%E6%88%90"><span class="nav-text">泛化性生成</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%AE%E5%89%8D%E4%B8%BB%E8%A6%81%E7%9A%84%E4%BB%BB%E5%8A%A1"><span class="nav-text">目前主要的任务</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-18"><span class="nav-text">Week 18</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#MonoNerf"><span class="nav-text">MonoNerf</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pipeline"><span class="nav-text">pipeline</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%81%E7%A7%BB%E8%AE%A1%E5%88%92"><span class="nav-text">迁移计划</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%AE%E5%89%8D%E6%AD%A4%E9%A2%86%E5%9F%9F%E7%9B%B8%E8%BF%91%E7%9A%84%E6%96%87%E7%AB%A0"><span class="nav-text">目前此领域相近的文章</span></a></li></ol></li></ol>

    </div>
</div>
        </div>
    
</div>



                

            </div>

            

        </div>

        <div class="main-content-footer">
            <footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color">
    <div class="info-container py-3 text-center">
        
            <div class="customize-info my-1">春江花月，照人生无穷；弦音流转，听山河入梦</div>
        
        <div class="text-center">
            &copy;
            
              <span>2023</span>
              -
            
            2024&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">力崽！</a>
        </div>
        
            <script data-swup-reload-script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="relative text-center lg:absolute lg:right-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-right">
                
                    <span id="busuanzi_container_site_uv" class="lg:!block">
                        <span class="text-sm">VISITOR COUNT</span>
                        <span id="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="lg:!block">
                        <span class="text-sm">TOTAL PAGE VIEWS</span>
                        <span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left">
            <span class="lg:block text-sm">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a></span>
            <span class="text-sm lg:block">THEME&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.4.4</a></span>
        </div>
        
        
            <div>
                Blog up for <span class="odometer" id="runtime_days" ></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec
            </div>
        
        
            <script data-swup-reload-script>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="article-tools-list">
        <!-- TOC aside toggle -->
        
            <li class="right-bottom-tools page-aside-toggle">
                <i class="fa-regular fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-side-tools-container">
        <div class="side-tools-container">
    <ul class="hidden-tools-list">
        <li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center">
            <i class="fa-regular fa-magnifying-glass-plus"></i>
        </li>

        <li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center">
            <i class="fa-regular fa-magnifying-glass-minus"></i>
        </li>

        <li class="right-bottom-tools tool-expand-width flex justify-center items-center">
            <i class="fa-regular fa-expand"></i>
        </li>

        <li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center">
            <i class="fa-regular fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center">
            <i class="fa-regular fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="visible-tools-list">
        <li class="right-bottom-tools toggle-tools-list flex justify-center items-center">
            <i class="fa-regular fa-cog fa-spin"></i>
        </li>
        
            <li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    

</main>


    
<script src="/js/libs/Swup.min.js"></script>

<script src="/js/libs/SwupSlideTheme.min.js"></script>

<script src="/js/libs/SwupScriptsPlugin.min.js"></script>

<script src="/js/libs/SwupProgressPlugin.min.js"></script>

<script src="/js/libs/SwupScrollPlugin.min.js"></script>

<script>
    const swup = new Swup({
        plugins: [
            new SwupScriptsPlugin({
                optin: true,
            }),
            new SwupProgressPlugin(),
            new SwupScrollPlugin({
                offset: 80,
            }),
            new SwupSlideTheme({
                mainElement: ".main-content-body",
            }),
        ],
        containers: ["#swup"],
    });

    swup.hooks.on("page:view", () => {
        Global.refresh();
    });

    // if (document.readyState === "complete") {
    //
    // } else {
    //     document.addEventListener("DOMContentLoaded", () => init());
    // }
</script>






<script src="/js/utils.js" type="module"></script>

<script src="/js/main.js" type="module"></script>

<script src="/js/layouts/navbarShrink.js" type="module"></script>

<script src="/js/tools/scrollTopBottom.js" type="module"></script>

<script src="/js/tools/lightDarkSwitch.js" type="module"></script>

<script src="/js/layouts/categoryList.js" type="module"></script>





    
<script src="/js/tools/codeBlock.js"></script>




    
<script src="/js/layouts/lazyload.js"></script>




    
<script src="/js/tools/runtime.js"></script>

    
<script src="/js/libs/odometer.min.js"></script>

    
<link rel="stylesheet" href="/assets/odometer-theme-minimal.css">




  
<script src="/js/libs/Typed.min.js"></script>

  
<script src="/js/plugins/typed.js"></script>




    
<script src="/js/libs/mermaid.min.js"></script>

    
<script src="/js/plugins/mermaid.js"></script>





<div class="post-scripts" data-swup-reload-script>
    
        
<script src="/js/libs/anime.min.js"></script>

        
<script src="/js/tools/tocToggle.js" type="module"></script>

<script src="/js/layouts/toc.js" type="module"></script>

<script src="/js/plugins/tabs.js" type="module"></script>

    
</div>


</body>
</html>
